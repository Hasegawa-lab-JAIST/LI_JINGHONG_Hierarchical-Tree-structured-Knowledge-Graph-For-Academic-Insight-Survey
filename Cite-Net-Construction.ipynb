{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# from time import process_time, sleep\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import InMemoryDataset, download_url\n",
        "import networkx as nx\n",
        "from networkx.algorithms import community\n",
        "from torch_geometric.utils import to_networkx\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.data import Data\n",
        "from pyvis.network import Network\n",
        "import string\n",
        "from colorama import Fore\n",
        "import termtables as tt\n",
        "string.punctuation\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "d_conclusion=pd.read_csv('Insight_dataset.csv',index_col=0)\n",
        "d_conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Citation net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Edge dataframe\n",
        "columns = ['sourceNodeId','targetNodeId','cite_info','relationshipType','flag']\n",
        "d_edges=pd.DataFrame(columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert data to edge dataframe\n",
        "count=0\n",
        "for i in range(len(d_conclusion)):\n",
        "    try:\n",
        "        List=eval(d_conclusion['ref_paper_id'][i])\n",
        "        # cite_dic=eval(d_conclusion['cite_text'][i])\n",
        "        count=count+1\n",
        "    except:\n",
        "        continue\n",
        "    for j in List:\n",
        "        if j in list(d_conclusion['corpusid']):\n",
        "            d_edges_append=pd.DataFrame(data=[[d_conclusion['corpusid'][i],j,str(List),'cites',count]], columns=columns)\n",
        "            d_edges=pd.concat([d_edges, d_edges_append], ignore_index=True, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "d_edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "d_edges.to_csv('d_edges.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Corpus_id_list of papers \n",
        "total_id=list(set(d_edges['sourceNodeId']))\n",
        "total_id.extend(list(set(d_edges['targetNodeId'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(set(total_id)))\n",
        "total_id=list(set(total_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Corpus_id -> index -> add content \n",
        "re_num={}\n",
        "for i in range (len(total_id)):\n",
        "    content={}\n",
        "    content['num']=i\n",
        "    content['type']=1\n",
        "    for j in range(len(d_conclusion)):\n",
        "        if d_conclusion['corpusid'][j]==total_id[i]:\n",
        "            # content['author-date']=total[total_id[i]]\n",
        "            content['title']=d_conclusion['paper-title'][j]\n",
        "            content['pdfurl']=d_conclusion['pdfurl'][j]\n",
        "            content['conclusion']=d_conclusion['Content'][j]\n",
        "            content['Solved']=d_conclusion['Solved'][j]\n",
        "            content['Unsolved']=d_conclusion['Unsolved/FW'][j]\n",
        "\n",
        "            if 'a survey' in content['title'] or 'A survey' in content['title'] or 'a Survey' in content['title'] or 'A Survey' in content['title']:\n",
        "                content['type']=0\n",
        "            else:\n",
        "                content['type']=1\n",
        "            \n",
        "            # print('true')\n",
        "            break\n",
        "        \n",
        "    re_num[total_id[i]]=content\n",
        "re_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "with open(\"Net-content.json\",\"w\", encoding='utf-8') as f: \n",
        "    f.write(json.dumps(re_num,ensure_ascii=True))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of Source,Target\n",
        "list_source=[]\n",
        "list_target=[]\n",
        "for i in range(len(d_edges)):\n",
        "    if d_edges['sourceNodeId'][i]==d_edges['targetNodeId'][i]:\n",
        "        continue\n",
        "   \n",
        "    list_source.append(re_num[d_edges['sourceNodeId'][i]]['num'])\n",
        "    list_target.append(re_num[d_edges['targetNodeId'][i]]['num'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Network \n",
        "class Demo_Data(InMemoryDataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "    #file\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return ['some_file_1', 'some_file_2', ...]\n",
        "   \n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['data.pt']\n",
        "    # download from website\n",
        "    # def download(self):\n",
        "    #     # Download to `self.raw_dir`.\n",
        "    #     download_url(url, self.raw_dir)\n",
        "        ...\n",
        "    #data generate\n",
        "    def process(self):\n",
        "        # Read data into huge `Data` list.\n",
        "        # Read data into huge `Data` list.\n",
        "        # building\n",
        "        \n",
        "        start=0\n",
        "        end=len(list_source)\n",
        "        \n",
        "        Edge_index = torch.tensor([list_source,\n",
        "                                   list_target], dtype=torch.long)\n",
        "        \n",
        "        # s=list_source[start:end].copy()\n",
        "        # s.extend(list_target[start:end])\n",
        "        print(len(re_num))\n",
        "        \n",
        "        # node_num=len(set(s))\n",
        "\n",
        "        # node feature\n",
        "        sample_feature=[0]*len(re_num)\n",
        "        X = torch.tensor(np.array(sample_feature).reshape(-1, 1).tolist(), dtype=torch.float)\n",
        "        # node label\n",
        "        # Y = torch.tensor([0,1,0],dtype=torch.float)\n",
        "        \n",
        "        #building\n",
        "        # data = Data(x=X, edge_index=Edge_index, y=Y)\n",
        "        data = Data(x=X,edge_index=Edge_index)\n",
        "        \n",
        "        # put in datalist\n",
        "        data_list = [data]\n",
        "\n",
        "        if self.pre_filter is not None:\n",
        "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "            data_list = [self.pre_transform(data) for data in data_list]\n",
        "\n",
        "        data, slices = self.collate(data_list)\n",
        "        data.num_nodes = len(re_num)\n",
        "        torch.save((data, slices), self.processed_paths[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = Demo_Data(\"Demo_Data_All\")\n",
        "data=dataset[0]\n",
        "dataset.get_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display \n",
        "G = to_networkx(data, to_undirected=False)# Directed\n",
        "degrees = [val for (node, val) in G.degree()]\n",
        "display(pd.DataFrame(pd.Series(degrees).describe()).transpose().round(2))\n",
        "print(len(degrees))\n",
        "print(sum(degrees))\n",
        "plt.figure(figsize=(10, 6))\n",
        "# plt.hist(degrees, bins=100)\n",
        "# plt.hist(degrees, range(0,10))\n",
        "plt.hist(degrees, range(0,50),rwidth=0.5,align=\"left\")\n",
        "\n",
        "plt.xlabel(\"node degree\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Number of citations\n",
        "ancestors={}\n",
        "ancestors_num=[]\n",
        "for i in G.nodes:\n",
        "    # print(i)\n",
        "    # print(nx.ancestors(G, i))\n",
        "    ancestors[i]=len(nx.ancestors(G, i))\n",
        "    ancestors_num.append(len(nx.ancestors(G, i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Papers of top 10 Citations\n",
        "r_node_list=[]\n",
        "while i<=10: \n",
        "    print('rank:',i)\n",
        "    r_node=ancestors_num.index(sorted(ancestors_num,reverse=True)[0])\n",
        "    print('high_contribution_node_num:',r_node)\n",
        "    r_node_list.append(r_node)\n",
        "    print('number of cited:',len(nx.ancestors(G, r_node)))\n",
        "    print('cited_by:',nx.ancestors(G, r_node))\n",
        "    G.nodes[r_node]['color']='deeppink'\n",
        "    G.nodes[r_node]['shape']='triangle'\n",
        "    G.nodes[r_node]['size']=35\n",
        "    ancestors_num[r_node]=0 # clear\n",
        "    i=i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Make graph - total \n",
        "word_node_num=len(total_id)\n",
        "for i in re_num:\n",
        "    #paper node shape,word,edge\n",
        "    if re_num[i]['type']==0:\n",
        "        G.nodes[re_num[i]['num']]['shape']='star'\n",
        "        G.nodes[re_num[i]['num']]['color']='chocolate'\n",
        "        # G.nodes[re_num[i]['num']]['label']='S'+str(re_num[i]['num'])\n",
        "        G.nodes[re_num[i]['num']]['size']=50\n",
        "\n",
        "    #paper label title\n",
        "    try:\n",
        "        # G.nodes[re_num[i]['num']]['label']=re_num[i]['author-date']\n",
        "        G.nodes[re_num[i]['num']]['title']=re_num[i]['title']+'\\n'+re_num[i]['pdfurl']+'\\n'+str(re_num[i]['num'])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "    word_node_num=word_node_num+4\n",
        "\n",
        "net = Network(notebook=True, cdn_resources='in_line',directed=True,bgcolor='#fffefe')\n",
        "net.from_nx(G)\n",
        "net.toggle_physics(False)\n",
        "net.show_buttons()\n",
        "net.show('Cite_net_total.html')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gnn_citations",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
