,corpusid,paper-title,section-title,Sentence,Label,pdf-url
0,209202200,Published as a conference paper at ICLR 2020 NEURAL MODULE NETWORKS FOR REASONING OVER TEXT,conclusion,we show how to use neural module networks to answer compositional questions requiring symbolic reasoning against natural language text.,ReSolved,https://export.arxiv.org/pdf/1912.04971v2.pdf
1,209202200,Published as a conference paper at ICLR 2020 NEURAL MODULE NETWORKS FOR REASONING OVER TEXT,conclusion,we define probabilistic modules that propagate uncertainty about symbolic reasoning operations in a way that is end-to-end differentiable.,ReSolved,https://export.arxiv.org/pdf/1912.04971v2.pdf
2,209202200,Published as a conference paper at ICLR 2020 NEURAL MODULE NETWORKS FOR REASONING OVER TEXT,conclusion,"additionally, we show that injecting inductive bias using unsupervised auxiliary losses significantly helps learning.",ReSolved,https://export.arxiv.org/pdf/1912.04971v2.pdf
3,247158312,Combining Modular Skills in Multitask Learning,conclusions,"in this work, we argued that a modular design is crucial to ensure that neural networks can learn from a few examples and generalise robustly across tasks by recombining autonomous facets of knowledge.",ReSolved,https://arxiv.org/pdf/2202.13914v2.pdf
4,247158312,Combining Modular Skills in Multitask Learning,conclusions,"to this end, we proposed a model where a subset of latent, discrete skills from a fixed inventory is allocated to each task in an end-to-end fashion.",ReSolved,https://arxiv.org/pdf/2202.13914v2.pdf
5,247158312,Combining Modular Skills in Multitask Learning,conclusions,"the task-specific instantiation of a neural network is then obtained by combining efficient parameterisations of the active skills, such as sparse or low-rank adapters.",Neutral,https://arxiv.org/pdf/2202.13914v2.pdf
6,247158312,Combining Modular Skills in Multitask Learning,conclusions,we evaluate the sample efficiency of our model on multitask instruction following through reinforcement learning and its few-shot adaptability on multitask text-to-text generation through supervised learning.,ReSolved,https://arxiv.org/pdf/2202.13914v2.pdf
7,247158312,Combining Modular Skills in Multitask Learning,conclusions,"in both experiments, we surpass competitive baselines where parameters are fully shared, task-specific, combined according to expert knowledge, or generated conditionally on the task.",ReSolved,https://arxiv.org/pdf/2202.13914v2.pdf
8,247158312,Combining Modular Skills in Multitask Learning,conclusions,"finally, we show that our model facilitates interpretability by learning an explicit hierarchy of tasks based on the skills they require.",ReSolved,https://arxiv.org/pdf/2202.13914v2.pdf
9,221971009,SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval,conclusion,"in short, we propose sparta, a novel ranking method, that learns sparse representation for better open-domain qa.",ReSolved,https://www.aclweb.org/anthology/2021.naacl-main.47.pdf
10,221971009,SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval,conclusion,experiments show that the proposed framework achieves the state-of-the-art performance for 4 different open-domain qa tasks in 2 languages and 11 retrieval qa tasks.,ReSolved,https://www.aclweb.org/anthology/2021.naacl-main.47.pdf
11,221971009,SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval,conclusion,this confirm our hypothesis that token-level interaction is superior to sequence-level interaction for better evidence ranking.,ReSolved,https://www.aclweb.org/anthology/2021.naacl-main.47.pdf
12,221971009,SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval,conclusion,"analyses also show the advantages of sparse representation, including interpretability, generalization and efficiency.",ReSolved,https://www.aclweb.org/anthology/2021.naacl-main.47.pdf
13,221971009,SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval,conclusion,our findings also suggest promising future research directions.,Finding,https://www.aclweb.org/anthology/2021.naacl-main.47.pdf
14,221971009,SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval,conclusion,"the proposed method does not support multi-hop reasoning, an important attribute that enables qa systems to answer more complex questions that require collecting multiple evidence passages.",Finding,https://www.aclweb.org/anthology/2021.naacl-main.47.pdf
15,221971009,SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval,conclusion,"also, current method only uses a bag-ofword features for the query.",Neutral,https://www.aclweb.org/anthology/2021.naacl-main.47.pdf
16,221971009,SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval,conclusion,we expect further gain by incorporating word-order information.,Neutral,https://www.aclweb.org/anthology/2021.naacl-main.47.pdf
17,238857091,Zero-Shot Dense Retrieval with Momentum Adversarial Domain Invariant Representations,conclusion and future work,"in this paper, we present modir, a new representation learning method that improves the zero-shot generalization ability of dense retrieval models.",ReSolved,https://www.aclanthology.org/2022.findings-acl.316.pdf
18,238857091,Zero-Shot Dense Retrieval with Momentum Adversarial Domain Invariant Representations,conclusion and future work,we first show that dense retrieval models differ from classification models in that they emphasize locality properties in the representation space.,ReSolved,https://www.aclanthology.org/2022.findings-acl.316.pdf
19,238857091,Zero-Shot Dense Retrieval with Momentum Adversarial Domain Invariant Representations,conclusion and future work,then we present a momentum-based adversarial training method that robustly pushes text encoders to provide a more domain invariant representation space for dense retrieval.,ReSolved,https://www.aclanthology.org/2022.findings-acl.316.pdf
20,238857091,Zero-Shot Dense Retrieval with Momentum Adversarial Domain Invariant Representations,conclusion and future work,"our experiments demonstrate that, compared with ance, a recent sota dr model, modir's improvements are robust overall and significant on datasets where zerodr's evaluation is more accurate.",ReSolved,https://www.aclanthology.org/2022.findings-acl.316.pdf
21,202773198,Answering Complex Open-domain Questions Through Iterative Query Generation,conclusion,"in this paper, we presented golden (gold entity) retriever, an open-domain multi-hop question answering system for scalable multi-hop reasoning.",ReSolved,https://www.aclweb.org/anthology/D19-1261.pdf
22,202773198,Answering Complex Open-domain Questions Through Iterative Query Generation,conclusion,"through iterative reasoning and retrieval, golden retriever greatly improves the recall of gold supporting facts, thus providing the question answering model a much better set of context documents to produce an answer from, and demonstrates competitive performance to the state of the art.",ReSolved,https://www.aclweb.org/anthology/D19-1261.pdf
23,202773198,Answering Complex Open-domain Questions Through Iterative Query Generation,conclusion,"generating natural languages queries for each step of reasoning, golden retriever is also more interpretable to humans compared to previous neural retrieval approaches and affords better understanding and verification of model behavior.",ReSolved,https://www.aclweb.org/anthology/D19-1261.pdf
24,202773198,Answering Complex Open-domain Questions Through Iterative Query Generation,conclusion,we start from the wikipedia dump file containing the introductory paragraphs used in hotpotqa that yang et al.,Neutral,https://www.aclweb.org/anthology/D19-1261.pdf
25,202773198,Answering Complex Open-domain Questions Through Iterative Query Generation,conclusion,"(2018) provide, 10 and add the fields corresponding to wikipedia page titles and the introductory paragraphs (text) into the index.",Neutral,https://www.aclweb.org/anthology/D19-1261.pdf
26,221655732,Multi-Hop Fact Checking of Political Claims,conclusions,"in this paper, we studied the novel task of multi-hop reasoning for fact checking of real-world political claims, which encompasses both evidence retrieval and claim veracity prediction.",ReSolved,https://arxiv.org/pdf/2009.06401v3.pdf
27,221655732,Multi-Hop Fact Checking of Political Claims,conclusions,"we presented politihop, the first political fact checking dataset with annotated evidence sentences.",ReSolved,https://arxiv.org/pdf/2009.06401v3.pdf
28,221655732,Multi-Hop Fact Checking of Political Claims,conclusions,"we compared several models on politihop and found that the multi-hop architecture transformer-xh slightly outperforms bert in most of the settings, especially in terms of evidence retrieval, where bert is easily fooled by named entity overlaps between the claim and evidence sentences.",ReSolved,https://arxiv.org/pdf/2009.06401v3.pdf
29,221655732,Multi-Hop Fact Checking of Political Claims,conclusions,"the performance of transformer-xh is further improved when retrieving more than two evidence sentences and the number of hops larger than one, which corroborates the assumption of the multi-hop nature of the task.",ReSolved,https://arxiv.org/pdf/2009.06401v3.pdf
30,221655732,Multi-Hop Fact Checking of Political Claims,conclusions,"in the first setting, the models are trained for 4 epochs on liar-plus.",Neutral,https://arxiv.org/pdf/2009.06401v3.pdf
31,221655732,Multi-Hop Fact Checking of Political Claims,conclusions,"in the second setting, the models are trained for 8 epochs on politihop.",Neutral,https://arxiv.org/pdf/2009.06401v3.pdf
32,221655732,Multi-Hop Fact Checking of Political Claims,conclusions,"in the third setting, models are trained for 4 epochs on liar-plus, followed by 4 epochs on politihop.",Neutral,https://arxiv.org/pdf/2009.06401v3.pdf
33,221655732,Multi-Hop Fact Checking of Political Claims,conclusions,"in every setting, models are evaluated on the dev set and the model with the best label prediction macro-f1 score is saved, which enables early stopping.",Neutral,https://arxiv.org/pdf/2009.06401v3.pdf
34,221655732,Multi-Hop Fact Checking of Political Claims,conclusions,"for the fourth setting, we pre-train the model for 2 epochs on the fever dataset, followed by 4 epochs on liar-plus, the fine-tune on politihop for 4 epochs.",Neutral,https://arxiv.org/pdf/2009.06401v3.pdf
35,237490850,"Extract, Integrate, Compete: Towards Verification Style Reading Comprehension",conclusion,"in this paper, we present a novel verification style reading comprehension dataset named vgaokao from the chinese language tests of gaokao for chinese native speakers, which embed multiple advanced language understanding skills.",ReSolved,https://arxiv.org/pdf/2109.05149v1.pdf
36,237490850,"Extract, Integrate, Compete: Towards Verification Style Reading Comprehension",conclusion,"to address the challenges in vgaokao, we propose a new extract-integrate-compare approach for complementary evidence retrieval/integration and option discrimination.",ReSolved,https://arxiv.org/pdf/2109.05149v1.pdf
37,237490850,"Extract, Integrate, Compete: Towards Verification Style Reading Comprehension",conclusion,"experiments show that our approach outperforms several strong baselines, with additional merits of efficiency and explainability.",ReSolved,https://arxiv.org/pdf/2109.05149v1.pdf
38,237490850,"Extract, Integrate, Compete: Towards Verification Style Reading Comprehension",conclusion,we believe vgaokao is a challenging test-bed for natural language understanding in chinese and encourage further research in verification style reading comprehensionn.,Neutral,https://arxiv.org/pdf/2109.05149v1.pdf
39,211572557,TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing,conclusion and future work,"in this paper, we present textbrewer, a flexible pytorch-based distillation toolkit for nlp research and applications.",ReSolved,https://www.aclweb.org/anthology/2020.acl-demos.2.pdf
40,211572557,TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing,conclusion and future work,textbrewer provides rich customization options for users to compare different distillation methods and build their strategies.,ReSolved,https://www.aclweb.org/anthology/2020.acl-demos.2.pdf
41,211572557,TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing,conclusion and future work,we have conducted a series of experiments.,Neutral,https://www.aclweb.org/anthology/2020.acl-demos.2.pdf
42,211572557,TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing,conclusion and future work,the results show that the distilled models can achieve state-of-the-art results with simple settings.,ReSolved,https://www.aclweb.org/anthology/2020.acl-demos.2.pdf
43,211572557,TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing,conclusion and future work,textbrewer also has its limitations.,Finding,https://www.aclweb.org/anthology/2020.acl-demos.2.pdf
44,211572557,TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing,conclusion and future work,"for example, its usability in generation tasks such as machine translation has not been tested.",Finding,https://www.aclweb.org/anthology/2020.acl-demos.2.pdf
45,211572557,TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing,conclusion and future work,we will keep adding more examples and tests to expand textbrewer's scope of application.,Finding,https://www.aclweb.org/anthology/2020.acl-demos.2.pdf
46,258078778,Datamator: An Intelligent Authoring Tool for Creating Datamations via Data Query Decomposition,"conclusion, limitations, and future work","in this paper, we presented the authoring tool datamator, developed for creating datamations.",ReSolved,https://export.arxiv.org/pdf/2304.03126v3.pdf
47,258078778,Datamator: An Intelligent Authoring Tool for Creating Datamations via Data Query Decomposition,"conclusion, limitations, and future work","to the best of our knowledge, it is the first tool that supports datamation design and generation.",ReSolved,https://export.arxiv.org/pdf/2304.03126v3.pdf
48,258078778,Datamator: An Intelligent Authoring Tool for Creating Datamations via Data Query Decomposition,"conclusion, limitations, and future work","given a dataset and a question, datamator can automatically decompose the question into a sequence of data analysis operators and generate a datamation based on unit visualization.",ReSolved,https://export.arxiv.org/pdf/2304.03126v3.pdf
49,258078778,Datamator: An Intelligent Authoring Tool for Creating Datamations via Data Query Decomposition,"conclusion, limitations, and future work",datamator also allows the user to modify and edit the generated results.,ReSolved,https://export.arxiv.org/pdf/2304.03126v3.pdf
50,258078778,Datamator: An Intelligent Authoring Tool for Creating Datamations via Data Query Decomposition,"conclusion, limitations, and future work",our user studies showed that datamator is highly rated for generating datamations to explain data analysis processes.,ReSolved,https://export.arxiv.org/pdf/2304.03126v3.pdf
51,258078778,Datamator: An Intelligent Authoring Tool for Creating Datamations via Data Query Decomposition,"conclusion, limitations, and future work",its editing function also showed to be effective in correcting the automatically generated results.,ReSolved,https://export.arxiv.org/pdf/2304.03126v3.pdf
52,256461186,Graph-Induced Transformers for Efficient Multi-Hop Question Answering,conclusions,"this work presented git, the graph-induced transformer that drastically improved mhqa models' sample efficiency and replaces graphs in the models while retaining their performance.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.702.pdf
53,256461186,Graph-Induced Transformers for Efficient Multi-Hop Question Answering,conclusions,our empirical evidences demonstrated that models can enjoy the benefits of connective inductive bias of graphs without additional graph modules in place.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.702.pdf
54,256461186,Graph-Induced Transformers for Efficient Multi-Hop Question Answering,conclusions,the design of git also allowed us to reuse the parameters of plm while incorporating the graph information.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.702.pdf
55,256461186,Graph-Induced Transformers for Efficient Multi-Hop Question Answering,conclusions,future directions of our work may include using git in downstream nlp applications where the graph inductive bias is necessary and dataset is scarce.,Finding,https://www.aclanthology.org/2022.emnlp-main.702.pdf
56,225067629,AQUAMUSE: Automatically Generating Datasets for Query-Based Multi-Document Summarization,conclusion,"we have presented aquamuse, a scalable methodology for constructing new qmds datasets, along with in-depth analyses and baseline experiments to demonstrate properties of one such dataset instance.",ReSolved,https://arxiv.org/pdf/2010.12694v1.pdf
57,225067629,AQUAMUSE: Automatically Generating Datasets for Query-Based Multi-Document Summarization,conclusion,many parts of the approach are configurable providing researchers a rich sandbox for evaluating summarization models under different task conditions.,ReSolved,https://arxiv.org/pdf/2010.12694v1.pdf
58,225067629,AQUAMUSE: Automatically Generating Datasets for Query-Based Multi-Document Summarization,conclusion,"our methodology greatly reduces the cost of data collection by converting a predominantly generative human annotation task (e.g., reading documents and writing succinct summaries) to a discriminative human annotation task (e.g., deciding on sentence-document relevance).",ReSolved,https://arxiv.org/pdf/2010.12694v1.pdf
59,225067629,AQUAMUSE: Automatically Generating Datasets for Query-Based Multi-Document Summarization,conclusion,"while our present work do not propose new methods for query-based summarization, we ran baseline experiments on one specific instance of the aquamuse dataset using a few popular neural approaches re-adapted with query conditioning.",ReSolved,https://arxiv.org/pdf/2010.12694v1.pdf
60,225067629,AQUAMUSE: Automatically Generating Datasets for Query-Based Multi-Document Summarization,conclusion,our experiments demonstrates that there is still much headroom for existing state-of-the-art models and we hope aquamuse will spur further advancements query focused multi-document summarization algorithms.,Finding,https://arxiv.org/pdf/2010.12694v1.pdf
61,254877499,Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions,conclusions,chain-of-thought prompting has significantly improved prompting-based large language models' ability to perform multi-step reasoning.,ReSolved,https://export.arxiv.org/pdf/2212.10509v1.pdf
62,254877499,Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions,conclusions,"in this work, we leveraged this ability to improve retrieval, and in turn improve qa performance for complex knowledge-intensive open-domain tasks in a fewshot setting.",ReSolved,https://export.arxiv.org/pdf/2212.10509v1.pdf
63,254877499,Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions,conclusions,one-step question based retrieval is insufficient for such tasks as what information is needed for later steps is not evident from the question alone.,Neutral,https://export.arxiv.org/pdf/2212.10509v1.pdf
64,254877499,Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions,conclusions,"to address this, we introduced ircot, which uses interleaved chain-of-thought reason-model hpqa br hpqa 2wikimqa mq 2h   table 3 compares reader choice (direct vs cot prompting) for flan-t5-xxl and gpt3.",ReSolved,https://export.arxiv.org/pdf/2212.10509v1.pdf
65,254877499,Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions,conclusions,we find that flan-t5-xxl works better with direct prompting as a reader and gpt3 works better with cot prompting as a reader.,ReSolved,https://export.arxiv.org/pdf/2212.10509v1.pdf
66,254877499,Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions,conclusions,"therefore, for the experiments in the main paper, we go with this choice.",Neutral,https://export.arxiv.org/pdf/2212.10509v1.pdf
67,254877499,Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions,conclusions,note though that the trends discussed in § 5 (ircot qa > oner qa > zeror qa) hold regardless of the choice of the reader.,Neutral,https://export.arxiv.org/pdf/2212.10509v1.pdf
68,247793456,LinkBERT: Pretraining Language Models with Document Links,conclusion,"we presented linkbert, a new language model (lm) pretraining method that incorporates document link knowledge such as hyperlinks.",ReSolved,https://www.aclanthology.org/2022.acl-long.551.pdf
69,247793456,LinkBERT: Pretraining Language Models with Document Links,conclusion,"in both the general domain (pretrained on wikipedia with hyperlinks) and biomedical domain (pretrained on pubmed with citation links), linkbert outperforms previous bert models across a wide range of downstream tasks.",ReSolved,https://www.aclanthology.org/2022.acl-long.551.pdf
70,247793456,LinkBERT: Pretraining Language Models with Document Links,conclusion,"the gains are notably large for multi-hop reasoning, multi-document understanding and few-shot question answering, suggesting that linkbert effectively internalizes salient knowledge through document links.",ReSolved,https://www.aclanthology.org/2022.acl-long.551.pdf
71,247793456,LinkBERT: Pretraining Language Models with Document Links,conclusion,our results suggest that linkbert can be a strong pretrained lm to be applied to various knowledge-intensive tasks.,ReSolved,https://www.aclanthology.org/2022.acl-long.551.pdf
72,245218982,"QuALITY: Question Answering with Long Input Texts, Yes!",conclusion,we introduce the long-document qa dataset quality.,ReSolved,https://www.aclanthology.org/2022.naacl-main.391.pdf
73,245218982,"QuALITY: Question Answering with Long Input Texts, Yes!",conclusion,"this dataset was crowdsourced and validated by humans to ensure that the questions are answerable, unambiguous, and challenging.",ReSolved,https://www.aclanthology.org/2022.naacl-main.391.pdf
74,245218982,"QuALITY: Question Answering with Long Input Texts, Yes!",conclusion,"the quality-hard subset, comprising half the dataset, consists of questions that are unanswerable by annotators working under tight time constraints, helping ensure that skimming and simple search do not yield high performance.",ReSolved,https://www.aclanthology.org/2022.naacl-main.391.pdf
75,245218995,Models in the Loop: Aiding Crowdworkers with Generative Annotation Assistants,discussion and conclusion,"in this work, we introduce generative annotation assistants (gaas) and investigate their potential to aid crowdworkers with creating more effective training data more efficiently.",ReSolved,https://www.aclanthology.org/2022.naacl-main.275.pdf
76,245218995,Models in the Loop: Aiding Crowdworkers with Generative Annotation Assistants,discussion and conclusion,"we perform a thorough analysis of how gaas can be used for improving qa dataset annotation in different settings, including different generative model training data, sampling strategies, and whether to also provide annotators with answer suggestions.",ReSolved,https://www.aclanthology.org/2022.naacl-main.275.pdf
77,245218995,Models in the Loop: Aiding Crowdworkers with Generative Annotation Assistants,discussion and conclusion,we find that gaas are beneficial in both the standard and adversarial data collection settings.,ReSolved,https://www.aclanthology.org/2022.naacl-main.275.pdf
78,245218995,Models in the Loop: Aiding Crowdworkers with Generative Annotation Assistants,discussion and conclusion,"in the standard data collection setting, and under the assumption of no access to adversarially-collected data, gaas with prompts sampled based on likelihood provide annotation speed-ups, while prompts sampled by adversarial performance or uncertainty metrics provide benefits to both the model error rates on the collected data as well as subsequent downstream qa performance.",Neutral,https://www.aclanthology.org/2022.naacl-main.275.pdf
79,245218995,Models in the Loop: Aiding Crowdworkers with Generative Annotation Assistants,discussion and conclusion,"we find that while gaas are effective for improving standard data collection, we still do not approach the performance obtained when using adversarial data collection.",Finding,https://www.aclanthology.org/2022.naacl-main.275.pdf
80,244954717,Does Structure Matter? Leveraging Data-to-Text Generation for Answering Complex Information Needs,conclusion,"traditionally, ir approaches solving complex information needs focused on leveraging multi-turn interactions to provide optimal rankings of candidate documents at each turn.",Neutral,https://arxiv.org/pdf/2112.04344v1.pdf
81,244954717,Does Structure Matter? Leveraging Data-to-Text Generation for Answering Complex Information Needs,conclusion,in this paper we have suggested alternative retrieval models that do not rely on the interactive updating of queries and document rankings as answers.,ReSolved,https://arxiv.org/pdf/2112.04344v1.pdf
82,244954717,Does Structure Matter? Leveraging Data-to-Text Generation for Answering Complex Information Needs,conclusion,"we suggest one such alternative approach can be found using datato-text generation models to generate in a single-turn, a natural language and structured answer.",ReSolved,https://arxiv.org/pdf/2112.04344v1.pdf
83,244954717,Does Structure Matter? Leveraging Data-to-Text Generation for Answering Complex Information Needs,conclusion,experimental evaluation of a planning-based dtt model using the trec car dataset shows the potential of our intuition.,Finding,https://arxiv.org/pdf/2112.04344v1.pdf
84,244954717,Does Structure Matter? Leveraging Data-to-Text Generation for Answering Complex Information Needs,conclusion,we believe that our work opens up novel areas of investigation including answer generation and explanation in conversational systems for ir.,Finding,https://arxiv.org/pdf/2112.04344v1.pdf
85,237737294,Dual-Channel Reasoning Model for Complex Question Answering,conclusion and future work,"in this paper, we propose a dual-channel reasoning architecture for complex question answering.",ReSolved,
86,237737294,Dual-Channel Reasoning Model for Complex Question Answering,conclusion and future work,e dual-channel reasoning architecture is applied to the feature interaction framework and graph-based models to verify its general applicability.,ReSolved,
87,237737294,Dual-Channel Reasoning Model for Complex Question Answering,conclusion and future work,"in the experiments, we show that our models   complexity significantly and consistently outperform the baseline model, especially in supporting fact prediction tasks.",ReSolved,
88,237737294,Dual-Channel Reasoning Model for Complex Question Answering,conclusion and future work,"after more detailed experimental analysis, it is proved that the dual-channel reasoning structure has stronger step-by-step reasoning ability than the single-channel reasoning structure.",ReSolved,
89,237737294,Dual-Channel Reasoning Model for Complex Question Answering,conclusion and future work,"in the future, we believe that the following issue will be worth studying.",Finding,
90,237737294,Dual-Channel Reasoning Model for Complex Question Answering,conclusion and future work,"for the dual-channel reasoning architecture, the interaction strategy between the two channels, such as the soft parameter sharing of the homogeneous neural network components of the two channels, is worthy of further study.",Finding,
91,253370208,Teaching Broad Reasoning Skills for Multi-Step QA by Generating Hard Contexts,conclusions,"despite large lms' impressive reading abilities and the availability of large scale multi-step qa datasets requiring a rich set of reasoning skills, lmbased qa models do not reliably learn to use such skills for answering complex questions.",Neutral,https://www.aclanthology.org/2022.emnlp-main.439.pdf
92,253370208,Teaching Broad Reasoning Skills for Multi-Step QA by Generating Hard Contexts,conclusions,"in this work, we show that the greater control that synthetic contexts offer can be leveraged to create a teaching dataset where models can learn a broad range of reasoning skills in a reliable manner, especially for more complex questions.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.439.pdf
93,254408864,A Comprehensive Survey on Multi-hop Machine Reading Comprehension Approaches,conclusion,"in this study, we focused on the multi-hop mrc approaches.",ReSolved,https://export.arxiv.org/pdf/2212.04072v1.pdf
94,254408864,A Comprehensive Survey on Multi-hop Machine Reading Comprehension Approaches,conclusion,"in this regard, after presenting the multi-hop mrc problem definition, the multi-hop mrc techniques had been explained based on 31 studies from 2018 to 2022.",Neutral,https://export.arxiv.org/pdf/2212.04072v1.pdf
95,254408864,A Comprehensive Survey on Multi-hop Machine Reading Comprehension Approaches,conclusion,"in addition to categorize the approaches based on the main technique, they also were reviewed in detail including the architecture, superiority, and motivations.",Neutral,https://export.arxiv.org/pdf/2212.04072v1.pdf
96,254408864,A Comprehensive Survey on Multi-hop Machine Reading Comprehension Approaches,conclusion,"in the following, a fine-grain comprehension of the approaches and techniques was prepared, and finally, some open issues in this field were discussed.",Neutral,https://export.arxiv.org/pdf/2212.04072v1.pdf
97,252819460,CausalQA: A Benchmark for Causal Question Answering,conclusion,"we constructed webis-causalqa-22, the first large benchmark dataset of 1.1 million causal questionanswer pairs, which serves to advance research in causal question answering.",ReSolved,
98,252819460,CausalQA: A Benchmark for Causal Question Answering,conclusion,"to ensure diversity of questions, we extracted them using seven hand-crafted high-precision lexical rules to capture as many subtypes of causal questions as possible.",ReSolved,
99,252819460,CausalQA: A Benchmark for Causal Question Answering,conclusion,"these rules were derived from a new typology of causal questions, which in turn is based on relevant related work on question typologies.",ReSolved,
100,252819460,CausalQA: A Benchmark for Causal Question Answering,conclusion,"a manual analysis of a sample of questions was used to characterize causal questions in terms of two dimensions: (1) their semantic properties, i.e., according to which element of the causal structure the question is asked (antecedent, consequent, or the causal chain) and (2) their pragmatic interpretation, i.e., the underlying intention or assumed information need of the questioner (e.g., prevention of medical problems).",ReSolved,
101,252819460,CausalQA: A Benchmark for Causal Question Answering,conclusion,"furthermore, a subsequent analysis of the causal questions contained in a search engine log showed that a significant proportion of 5% of question queries are causal.",ReSolved,
102,252819460,CausalQA: A Benchmark for Causal Question Answering,conclusion,"finally, we evaluated the state-of-the-art model unifiedqa on our corpus as an initial baseline for causal question answering.",ReSolved,
103,204852129,Relation Module for Non-answerable Prediction on Reading Comprehension,conclusion,in this work we propose a new relation module that can be applied on any mrc reader and help increase the prediction accuracy on non-answerable questions.,ReSolved,https://arxiv.org/pdf/1910.10843v1.pdf
104,204852129,Relation Module for Non-answerable Prediction on Reading Comprehension,conclusion,we extract high level semantics from multi-head self-attentive pooling.,ReSolved,https://arxiv.org/pdf/1910.10843v1.pdf
105,204852129,Relation Module for Non-answerable Prediction on Reading Comprehension,conclusion,the semantic object pairs are fed into the relation network which makes a guided decision as to whether a question is answerable.,ReSolved,https://arxiv.org/pdf/1910.10843v1.pdf
106,204852129,Relation Module for Non-answerable Prediction on Reading Comprehension,conclusion,"in addition we augment the context vector with plausible answers, allowing us to extract objects focused on the proposed answer span, and differentiate from other objects that are not as relevant in the context.",ReSolved,https://arxiv.org/pdf/1910.10843v1.pdf
107,204852129,Relation Module for Non-answerable Prediction on Reading Comprehension,conclusion,our results on the squad 2.0 dataset using the relation module on both bidaf and bert models show improvements from the relation module.,ReSolved,https://arxiv.org/pdf/1910.10843v1.pdf
108,204852129,Relation Module for Non-answerable Prediction on Reading Comprehension,conclusion,these results prove the effectiveness of our relation module.,ReSolved,https://arxiv.org/pdf/1910.10843v1.pdf
109,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,"this review is devoted to the transient dynamics of perturbations, which is of special interest in theory of astrophysical disks, in particular accretion disks.",ReSolved,https://arxiv.org/pdf/1512.08897v1.pdf
110,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,exponentially growing perturbations do not exist in a homogeneous inviscid keplerian flow provided that there are no conditions for the magneto-rotational instability.,Neutral,https://arxiv.org/pdf/1512.08897v1.pdf
111,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,"nevertheless, observations suggest that also in this case angular momentum should be somehow transported outwards.",Neutral,https://arxiv.org/pdf/1512.08897v1.pdf
112,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,"at least, this implies that there should be some mechanism of energy transfer from the regular rotational motion to hydrodynamical perturbations.",Neutral,https://arxiv.org/pdf/1512.08897v1.pdf
113,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,in spectrally stable flows the transient growth mechanism is responsible for this.,Neutral,https://arxiv.org/pdf/1512.08897v1.pdf
114,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,here it was introduced by a simple example of two-dimensional vortices and it was discussed that the reason for their growth is the shortening of the length of leading spirals by the differential rotation of the flow,Neutral,https://arxiv.org/pdf/1512.08897v1.pdf
115,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,"nonwithstanding their seeming simplicity, those (quasi-)columnar structures exhibit the strongest ability to extract energy from the spectrally stable differentially rotating flows (see [54] about it).",ReSolved,https://arxiv.org/pdf/1512.08897v1.pdf
116,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,"physically, the energy growth of vortices takes place due to their own angular momentum conservation, which in the local limit is expressed by the conservation of their potential vorticity and the existence of the invariant i (see section 2.2).",Neutral,https://arxiv.org/pdf/1512.08897v1.pdf
117,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,here we considered both small-scale (k y ≫ 1) and large-scale (k y ≪ 1) vortices and compared their optimal growth with account for non-zero effective viscosity in the disk,Neutral,https://arxiv.org/pdf/1512.08897v1.pdf
118,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,"importantly, the transient growth of large-scale vortices strongly increases for a super-keplerian rotation, which can be significant in relativistic disks where q > 3/2.",ReSolved,https://arxiv.org/pdf/1512.08897v1.pdf
119,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,"in this paper, special attention was paid to mathematical aspects of non-modal analysis and to methods of optimal perturbations computation.",ReSolved,https://arxiv.org/pdf/1512.08897v1.pdf
120,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,"we have discussed in detail that the transient growth is a consequence of non-normality of the governing dynamical operator of the problem and non-orthogonality of its eigenvectors, i.e. modes of perturbations",Neutral,https://arxiv.org/pdf/1512.08897v1.pdf
121,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,"therefore, the growth of arbitrary perturbations can be adequately studied by calculating not eigenvectors but singular vectors of this operator.",ReSolved,https://arxiv.org/pdf/1512.08897v1.pdf
122,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,we have considered two methods: a matrix and variational one and applied them to the particular problems,ReSolved,https://arxiv.org/pdf/1512.08897v1.pdf
123,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,"the matrix method requires a discrete representation of the dynamical operator, for example, in the basis of its eigenvectors.",Neutral,https://arxiv.org/pdf/1512.08897v1.pdf
124,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,"the variational method is reduced to iterative integration of the system of direct and adjoint equations forward and backward in time, respectively.",Neutral,https://arxiv.org/pdf/1512.08897v1.pdf
125,119104197,Transient dynamics of perturbations in astrophysical disks,conclusion,"we have emphasized that the variational method is more universal and can be applied to study of non-modal dynamics of perturbations in non-stationary flows, as well as to non-linear problems.",ReSolved,https://arxiv.org/pdf/1512.08897v1.pdf
126,57721315,Multi-Style Generative Reading Comprehension,conclusion,this study sheds light on multi-style generative rc.,ReSolved,https://arxiv.org/pdf/1901.02262v2.pdf
127,57721315,Multi-Style Generative Reading Comprehension,conclusion,"our proposed model, masque, is based on multi-source abstractive summarization and learns multi-style answers together.",ReSolved,https://arxiv.org/pdf/1901.02262v2.pdf
128,57721315,Multi-Style Generative Reading Comprehension,conclusion,it achieved stateof-the-art performance on the q&a task and the q&a + nlg task of ms marco 2.1 and the summary task of narrativeqa.,ReSolved,https://arxiv.org/pdf/1901.02262v2.pdf
129,57721315,Multi-Style Generative Reading Comprehension,conclusion,the key to its success is transferring the style-independent nlg capability to the target style by use of the question-passages reader and the conditional pointer-generator decoder.,ReSolved,https://arxiv.org/pdf/1901.02262v2.pdf
130,57721315,Multi-Style Generative Reading Comprehension,conclusion,"in particular, the capability of copying words from the question and passages can be shared among the styles, while the capability of controlling the mixture weights for the generative and copy distributions can be acquired for each style.",Neutral,https://arxiv.org/pdf/1901.02262v2.pdf
131,57721315,Multi-Style Generative Reading Comprehension,conclusion,our future work will involve exploring the potential of our multi-style learning towards natural language understanding.,Finding,https://arxiv.org/pdf/1901.02262v2.pdf
132,235399966,FINQA: A Dataset of Numerical Reasoning over Financial Data,conclusion and future work,"this paper introduces finqa, a new expertannotated qa dataset that aims to tackle numerical reasoning over real-world financial data.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.300.pdf
133,235399966,FINQA: A Dataset of Numerical Reasoning over Financial Data,conclusion and future work,"the questions in finqa pose great challenge for existing models to resolve domain-specific knowledge, as well as to acquire complex numerical reasoning abilities.",Finding,https://www.aclanthology.org/2021.emnlp-main.300.pdf
134,235399966,FINQA: A Dataset of Numerical Reasoning over Financial Data,conclusion and future work,we propose baseline frameworks and con-duct comprehensive experiments and analysis.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.300.pdf
135,235399966,FINQA: A Dataset of Numerical Reasoning over Financial Data,conclusion and future work,the results show that current large pre-trained models still fall far behind the human expert performance.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.300.pdf
136,235399966,FINQA: A Dataset of Numerical Reasoning over Financial Data,conclusion and future work,"this encourages potential future work on developing pre-training tasks for such realistic, complex application domains.",Finding,https://www.aclanthology.org/2021.emnlp-main.300.pdf
137,235399966,FINQA: A Dataset of Numerical Reasoning over Financial Data,conclusion and future work,we believe finqa should serve as a valuable resource for the research community.,Neutral,https://www.aclanthology.org/2021.emnlp-main.300.pdf
138,201058633,Reasoning Over Paragraph Effects in Situations,conclusion,"we present ropes, a new reading comprehension benchmark containing 14,322 questions, which aims to test the ability of systems to apply knowledge from reading text in a new setting.",ReSolved,https://www.aclweb.org/anthology/D19-5808.pdf
139,201058633,Reasoning Over Paragraph Effects in Situations,conclusion,we hope that ropes will aide efforts in tying language and reasoning together for more comprehensive understanding of text.,Neutral,https://www.aclweb.org/anthology/D19-5808.pdf
140,254854559,APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning,conclusion,"in this paper, we proposed apollo, an adaptive pre-trained language model with logical reasoning abilities.",ReSolved,https://export.arxiv.org/pdf/2212.09282v2.pdf
141,254854559,APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning,conclusion,we use a subset of wikipedia sentences for continued pretraining of the model using two self-supervised loss functions.,ReSolved,https://export.arxiv.org/pdf/2212.09282v2.pdf
142,254854559,APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning,conclusion,"the choice of the training dataset and loss functions are guided by the goal to include more reasoning-related sentences and training signals, respectively.",Neutral,https://export.arxiv.org/pdf/2212.09282v2.pdf
143,254854559,APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning,conclusion,"through experiments on two logical reasoning datasets and ablation studies, we demonstrate the effectiveness of our proposed approach.",Neutral,https://export.arxiv.org/pdf/2212.09282v2.pdf
144,254854559,APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning,conclusion,"overall, we show that apollo is a generalized solution to improving logical reasoning in language models.",ReSolved,https://export.arxiv.org/pdf/2212.09282v2.pdf
145,254854559,APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning,limitation,a limitation of this approach is the trade-off between completeness and noise in the training data.,Finding,https://export.arxiv.org/pdf/2212.09282v2.pdf
146,254854559,APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning,limitation,"while our method using keywords to extract text from wikipedia is effective, implication likely contains redundant sentences that cannot improve the model's logical reasoning capability.",Finding,https://export.arxiv.org/pdf/2212.09282v2.pdf
147,254854559,APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning,limitation,a better rule-based or neural model might be able to extract a better corpus with potentially higher computational costs.,Finding,https://export.arxiv.org/pdf/2212.09282v2.pdf
148,254854559,APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning,limitation,"additionally, using pos tagging limits the application of this approach to languages with well-defined pos taggers.",Finding,https://export.arxiv.org/pdf/2212.09282v2.pdf
149,254854559,APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning,limitation,"switching to a more universal semantic tagging system (abzianidze and bos, 2017) can potentially alleviate this.",Finding,https://export.arxiv.org/pdf/2212.09282v2.pdf
150,252846670,Do Question Answering Modeling Improvements Hold Across Benchmarks?,conclusion,this work studies whether qa modeling improvements hold across the diverse landscape of qa benchmarks.,ReSolved,https://export.arxiv.org/pdf/2102.01065v3.pdf
151,252846670,Do Question Answering Modeling Improvements Hold Across Benchmarks?,conclusion,"we develop the notion of concurrence, which quantifies the similarity between benchmarks' rankings of modeling approaches.",ReSolved,https://export.arxiv.org/pdf/2102.01065v3.pdf
152,252846670,Do Question Answering Modeling Improvements Hold Across Benchmarks?,conclusion,"experiments with 32 qa benchmarks and 20 diverse modeling approaches indicate that humanconstructed benchmarks largely have high concurrence amongst themselves, even when their passage and question distributions or linguistic phenomena of focus are very different.",ReSolved,https://export.arxiv.org/pdf/2102.01065v3.pdf
153,252846670,Do Question Answering Modeling Improvements Hold Across Benchmarks?,conclusion,"to better understand how different benchmark attributes affect concurrence, we explore downsampled benchmarks and various programmatically-generated benchmarks, the latter having high concurrence only when they target phenomena that are also useful for better performance on human-constructed benchmarks (e.g., identifying paraphrase and lexical overlap).",ReSolved,https://export.arxiv.org/pdf/2102.01065v3.pdf
154,252846670,Do Question Answering Modeling Improvements Hold Across Benchmarks?,conclusion,"our results indicate that the modeling improvements studied hold broadly, despite years of intense community focus on a small number of benchmarks.",ReSolved,https://export.arxiv.org/pdf/2102.01065v3.pdf
155,173188058,MULTIQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension,conclusions,in this work we performed a thorough empirical investigation of generalization and transfer over 10 rc datasets.,ReSolved,https://arxiv.org/pdf/1905.13453v1.pdf
156,173188058,MULTIQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension,conclusions,we characterized the factors affecting generalization and obtained several state-ofthe-art results by training on 375k examples from 5 rc datasets.,ReSolved,https://arxiv.org/pdf/1905.13453v1.pdf
157,173188058,MULTIQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension,conclusions,"we open source our infrastructure for easily performing experiments on multiple rc datasets, for the benefit of the community.",ReSolved,https://arxiv.org/pdf/1905.13453v1.pdf
158,173188058,MULTIQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension,conclusions,"we highlight several practical take-aways: • pre-training on multiple source rc datasets consistently improves performance on a target rc dataset , even in the presence of bert representations.",ReSolved,https://arxiv.org/pdf/1905.13453v1.pdf
159,173188058,MULTIQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension,conclusions,it also leads to substantial reduction in the number of necessary training examples for a fixed performance.,ReSolved,https://arxiv.org/pdf/1905.13453v1.pdf
160,173188058,MULTIQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension,conclusions,training the high-capacity bert-large representations over multiple rc datasets leads to good performance on all of the trained datasets without having to fine-tune on each dataset separately.,ReSolved,https://arxiv.org/pdf/1905.13453v1.pdf
161,173188058,MULTIQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension,conclusions,"bert representations improve generalization, but their effect is moderate when the source of the context is web snippets compared to wikipedia and newswire.",ReSolved,https://arxiv.org/pdf/1905.13453v1.pdf
162,173188058,MULTIQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension,conclusions,performance over an rc dataset can be improved by retrieving web snippets for all questions and adding them as examples (context augmentation).,Finding,https://arxiv.org/pdf/1905.13453v1.pdf
163,245334850,MuMuQA: Multimedia Multi-Hop News Question Answering via Cross-Media Knowledge Extraction and Grounding,conclusions and future work,"we present a new qa task, mumuqa, along with an evaluation benchmark for multimedia news understanding.",ReSolved,https://arxiv.org/pdf/2112.10728v2.pdf
164,245334850,MuMuQA: Multimedia Multi-Hop News Question Answering via Cross-Media Knowledge Extraction and Grounding,conclusions and future work,"the task is challenging in the requirement of cross-media grounding over images, captions, and news body text.",Neutral,https://arxiv.org/pdf/2112.10728v2.pdf
165,245334850,MuMuQA: Multimedia Multi-Hop News Question Answering via Cross-Media Knowledge Extraction and Grounding,conclusions and future work,"we demonstrate the benefit of using multimedia knowledge extraction, both for generating silver-standard training data and for a pipeline-based multimedia qa system.",ReSolved,https://arxiv.org/pdf/2112.10728v2.pdf
166,245334850,MuMuQA: Multimedia Multi-Hop News Question Answering via Cross-Media Knowledge Extraction and Grounding,conclusions and future work,"the multimedia baselines are still considerably behind human performance, suggesting ample room for improvement.",Finding,https://arxiv.org/pdf/2112.10728v2.pdf
167,245334850,MuMuQA: Multimedia Multi-Hop News Question Answering via Cross-Media Knowledge Extraction and Grounding,conclusions and future work,"future work will incorporate other forms of media in news, such as video and audio, to facilitate information seeking from more comprehensive data sources.",Finding,https://arxiv.org/pdf/2112.10728v2.pdf
168,245334850,MuMuQA: Multimedia Multi-Hop News Question Answering via Cross-Media Knowledge Extraction and Grounding,conclusions and future work,another direction is to infuse the endto-end multimedia qa system with additional input from the grounding and visual attribute extraction systems.,Finding,https://arxiv.org/pdf/2112.10728v2.pdf
169,254853987,Source-Free Domain Adaptation for Question Answering with Masked Self-training,conclusion,"in this paper, we explore the possibility of transferring knowledge for unsupervised domain adaptation on question answering, without access to initial domain data.",ReSolved,https://export.arxiv.org/pdf/2212.09563v1.pdf
170,254853987,Source-Free Domain Adaptation for Question Answering with Masked Self-training,conclusion,"we proposed a novel self-trainingbased approach, mdaqa.",ReSolved,https://export.arxiv.org/pdf/2212.09563v1.pdf
171,254853987,Source-Free Domain Adaptation for Question Answering with Masked Self-training,conclusion,we specially design an attention mask module to automatically keep key knowledge from the source domain and learn to mitigate domain shift between source and target domains.,ReSolved,https://export.arxiv.org/pdf/2212.09563v1.pdf
172,254853987,Source-Free Domain Adaptation for Question Answering with Masked Self-training,conclusion,the module can be easily integrated into existing language models.,ReSolved,https://export.arxiv.org/pdf/2212.09563v1.pdf
173,254853987,Source-Free Domain Adaptation for Question Answering with Masked Self-training,conclusion,our comprehensive experiments on well-known benchmark datasets demonstrate that mdaqa outperforms previous methods by a clear margin.,ReSolved,https://export.arxiv.org/pdf/2212.09563v1.pdf
174,254853987,Source-Free Domain Adaptation for Question Answering with Masked Self-training,conclusion,it can also achieve decent performance even when the available target domain data is highly limited.,ReSolved,https://export.arxiv.org/pdf/2212.09563v1.pdf
175,254853987,Source-Free Domain Adaptation for Question Answering with Masked Self-training,conclusion,this makes mdaqa have a very wide range of application scenarios.,ReSolved,https://export.arxiv.org/pdf/2212.09563v1.pdf
176,254853987,Source-Free Domain Adaptation for Question Answering with Masked Self-training,limitation,"since the use of source-free uda is mostly discussed in the medical field at the moment, ideally, more experiments on medical datasets would be more convincing.",Neutral,https://export.arxiv.org/pdf/2212.09563v1.pdf
177,254853987,Source-Free Domain Adaptation for Question Answering with Masked Self-training,limitation,"however, since available medical qa datasets are extremely limited and hard to access, currently we still conduct experiments on commonly used general-purpose qa datasets.",Finding,https://export.arxiv.org/pdf/2212.09563v1.pdf
178,256846551,STREET: A MULTI-TASK STRUCTURED REASONING AND EXPLANATION BENCHMARK,conclusion,we aim to enable machines to perform multi-step reasoning while explaining their answers.,Neutral,https://export.arxiv.org/pdf/2302.06729v1.pdf
179,256846551,STREET: A MULTI-TASK STRUCTURED REASONING AND EXPLANATION BENCHMARK,conclusion,we believe that teaching machines how to manipulate premises and reach conclusions can be an important step towards true language understanding.,Neutral,https://export.arxiv.org/pdf/2302.06729v1.pdf
180,256846551,STREET: A MULTI-TASK STRUCTURED REASONING AND EXPLANATION BENCHMARK,conclusion,"with that in mind, we introduce street, a new multi-task reasoning and explanation resource covering various forms of reasoning in the context of questionanswering.",ReSolved,https://export.arxiv.org/pdf/2302.06729v1.pdf
181,256846551,STREET: A MULTI-TASK STRUCTURED REASONING AND EXPLANATION BENCHMARK,conclusion,we hope this benchmark will allow for a more systematic evaluation of the reasoning capabilities of natural language systems.,ReSolved,https://export.arxiv.org/pdf/2302.06729v1.pdf
182,256846551,STREET: A MULTI-TASK STRUCTURED REASONING AND EXPLANATION BENCHMARK,conclusion,future avenues of research include exploring the reasoning capabilities and knowledge retrieval and using supervised models trained on multi-step reasoning data to bootstrap unsupervised learning for multi-step reasoning.,Finding,https://export.arxiv.org/pdf/2302.06729v1.pdf
183,258547173,Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework,conclusions,"in this paper, we introduce a verify-and-edit framework for open-domain question-answering.",ReSolved,https://export.arxiv.org/pdf/2305.03268v1.pdf
184,258547173,Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework,conclusions,it is a first attempt to post-edit cot-style reasoning chains for better end-task performance.,ReSolved,https://export.arxiv.org/pdf/2305.03268v1.pdf
185,258547173,Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework,conclusions,"by combining knowledge retrieval with reasoning, the framework edits cots in a natural and conversational way, which enhances prediction factuality.",ReSolved,https://export.arxiv.org/pdf/2305.03268v1.pdf
186,258547173,Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework,conclusions,"combined with google search, the framework also shows a promising direction that combines the open-generation ability of state-of-art llms with the updated facts provided by search engines.",ReSolved,https://export.arxiv.org/pdf/2305.03268v1.pdf
187,258865893,Mixture of Prompt Experts for Generalizable and Interpretable Question Answering,conclusion,"in this work, we proposed the mope framework where we implement a pool of specialized qa models that excel at different reasoning types, and then train a router to select the answer from the best specialized model for questions from different categories.",ReSolved,https://export.arxiv.org/pdf/2305.14628v1.pdf
188,258865893,Mixture of Prompt Experts for Generalizable and Interpretable Question Answering,conclusion,experiments on 12 datasets covering four reasoning types demonstrate that mope achieve better generalizability than all baselines.,ReSolved,https://export.arxiv.org/pdf/2305.14628v1.pdf
189,258865893,Mixture of Prompt Experts for Generalizable and Interpretable Question Answering,conclusion,"more importantly, the inter-expert agreement features in mope offers useful signals for training effective calibrators that improve selective question answering, and also improve human verification of the system's final predictions.",ReSolved,https://export.arxiv.org/pdf/2305.14628v1.pdf
190,258865893,Mixture of Prompt Experts for Generalizable and Interpretable Question Answering,conclusion,"while we focused exclusively on prompt experts, the idea of combining the strengths of diverse specialized models can extend to any type of specialized qa models, even non-neural models such as traditional information retrieval models.",Finding,https://export.arxiv.org/pdf/2305.14628v1.pdf
191,258865893,Mixture of Prompt Experts for Generalizable and Interpretable Question Answering,conclusion,we leave such extensions to future exploration.,Finding,https://export.arxiv.org/pdf/2305.14628v1.pdf
192,225068329,Measuring Association Between Labels and Free-Text Rationales,conclusion,"after demonstrating the weaknesses that pipeline models exhibit for free-text rationalization tasks, we propose two measurements of label-rationale association in self-rationalizing models.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.804.pdf
193,225068329,Measuring Association Between Labels and Free-Text Rationales,conclusion,"we find that on three free-text rationalization datasets for commonsenseqa and snli, models based on t5 exhibit high robustness equivalence and feature importance agreement, demonstrating that they pass a necessary sanity check for generating faithful free-text rationales.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.804.pdf
194,257636734,Logical Reasoning over Natural Language as Knowledge Representation: A Survey,conclusion,"in this paper, we propose a new concept, logical reasoning over natural language as knowledge representation (lrnl), and provide a detailed and up-to-date review of lrnl.",ReSolved,https://export.arxiv.org/pdf/2303.12023v1.pdf
195,257636734,Logical Reasoning over Natural Language as Knowledge Representation: A Survey,conclusion,"moreover, we have introduced the philosophical foundations, advantages of lrnl, benchmarks and methods, challenges, desirable tasks & methods, and the relation of lrnl to related nlp fields",ReSolved,https://export.arxiv.org/pdf/2303.12023v1.pdf
196,257901155,UKP-SQuARE v3: A Platform for Multi-Agent QA Research,conclusions and discussions,"in this work, we have extended ukp-square to support multi-agent models.",ReSolved,https://export.arxiv.org/pdf/2303.18120v2.pdf
197,257901155,UKP-SQuARE v3: A Platform for Multi-Agent QA Research,conclusions and discussions,"in particular, we deployed a routing system, tweac (geigle et al., 2021), a method to combine adapter weights, made (friedman et al., 2021), and a model that combines the prediction of multiple skills, metaqa (puerto et al., 2023).",ReSolved,https://export.arxiv.org/pdf/2303.18120v2.pdf
198,257901155,UKP-SQuARE v3: A Platform for Multi-Agent QA Research,conclusions and discussions,"we have conducted experiments on these three models and unifiedqa (khashabi et al., 2020), a multi-dataset system, to analyze the trade-off between the performance, efficiency, and flexibility of these systems.",ReSolved,https://export.arxiv.org/pdf/2303.18120v2.pdf
199,257901155,UKP-SQuARE v3: A Platform for Multi-Agent QA Research,conclusions and discussions,"we showed that in scenarios where new domains or expertise are often needed, metaqa provides the best tradeoff since its performance is close to the best model, it is compatible with any qa format, cheap to train, and its inference runtime is close to tweac and made using the parallel engine provided by ukp-square.",ReSolved,https://export.arxiv.org/pdf/2303.18120v2.pdf
200,257901155,UKP-SQuARE v3: A Platform for Multi-Agent QA Research,conclusions and discussions,"however, when simple deployment is needed or the model is not expected to be updated, made and unifiedqa might be more appropriate.",Finding,https://export.arxiv.org/pdf/2303.18120v2.pdf
201,215737171,Longformer: The Long-Document Transformer,conclusion and future work,"we present longformer, a transformer-based model that is scalable for processing long documents and that makes it easy to perform a wide range of document-level nlp tasks without chunking/shortening the long input and without complex architecture to combine information across these chunks.",ReSolved,https://arxiv.org/pdf/2004.05150v1.pdf
202,215737171,Longformer: The Long-Document Transformer,conclusion and future work,longformer employs an attention pattern that combines local and global information while also scaling linearly with the sequence length.,ReSolved,https://arxiv.org/pdf/2004.05150v1.pdf
203,215737171,Longformer: The Long-Document Transformer,conclusion and future work,longformer achieves state-of-the-art results on the character-level language modeling tasks of text8 and enwik8.,ReSolved,https://arxiv.org/pdf/2004.05150v1.pdf
204,215737171,Longformer: The Long-Document Transformer,conclusion and future work,"when pretrained, longformer consistently outperforms roberta on long document tasks and sets new state-of-the-art results on wiki-hop and triviaqa.",ReSolved,https://arxiv.org/pdf/2004.05150v1.pdf
205,215737171,Longformer: The Long-Document Transformer,conclusion and future work,"for future work, we would like to explore other attention patterns that are more efficient by dynamically adapting to the input.",Finding,https://arxiv.org/pdf/2004.05150v1.pdf
206,215737171,Longformer: The Long-Document Transformer,conclusion and future work,we also would like to apply our model to other relevant long document tasks such as summarization.,Finding,https://arxiv.org/pdf/2004.05150v1.pdf
207,211258652,Training Question Answering Models From Synthetic Data,conclusion,we build upon existing work in large scale language modeling and question generation to push the quality of synthetic question generation.,ReSolved,https://arxiv.org/pdf/2002.09599v1.pdf
208,211258652,Training Question Answering Models From Synthetic Data,conclusion,"with our best models, we generate large question answering datasets from unlabeled wikipedia documents and finetune a 345 million parameter bert-style model achieving 88.4 em score.",ReSolved,https://arxiv.org/pdf/2002.09599v1.pdf
209,211258652,Training Question Answering Models From Synthetic Data,conclusion,finetuning the resulting model on real squad1.1 data further boosts the em score to 89.4.,ReSolved,https://arxiv.org/pdf/2002.09599v1.pdf
210,211258652,Training Question Answering Models From Synthetic Data,conclusion,this amounts to a 1.7 point improvement over our fully supervised baseline.,ReSolved,https://arxiv.org/pdf/2002.09599v1.pdf
211,211258652,Training Question Answering Models From Synthetic Data,conclusion,"finally, we generate synthetic text from a wikipedia-finetuned gpt-2 model, generate answer candidates and synthetic questions based on those answers, and then train a bert-large model to achieve similar question answering accuracy without directly using any real data at all.",ReSolved,https://arxiv.org/pdf/2002.09599v1.pdf
212,211258652,Training Question Answering Models From Synthetic Data,conclusion,"doing so required us to scale model size for our answer generators, question generators, and filtration models.",Neutral,https://arxiv.org/pdf/2002.09599v1.pdf
213,211258652,Training Question Answering Models From Synthetic Data,conclusion,we hope that better synthetic questions will enable new breakthroughs in question answering systems and related natural language tasks.,Finding,https://arxiv.org/pdf/2002.09599v1.pdf
214,248085193,Augmenting Pre-trained Language Models with QA-Memory for Open-Domain Question Answering,conclusion,"in this paper, we propose a more accurate and efficient architecture to utilize qa-pairs as representation units of knowledge.",ReSolved,https://export.arxiv.org/pdf/2204.04581v3.pdf
215,248085193,Augmenting Pre-trained Language Models with QA-Memory for Open-Domain Question Answering,conclusion,"our proposed model qamat outperforms repaq significantly, while leveraging our less expensive training procedure.",ReSolved,https://export.arxiv.org/pdf/2204.04581v3.pdf
216,248085193,Augmenting Pre-trained Language Models with QA-Memory for Open-Domain Question Answering,conclusion,"furthermore, we show how a qa-backed model can perform compositional reasoning and address more complex queries.",ReSolved,https://export.arxiv.org/pdf/2204.04581v3.pdf
217,248085193,Augmenting Pre-trained Language Models with QA-Memory for Open-Domain Question Answering,conclusion,"in the future, we hope to further close the gap with state-of-the-art documentbased retrieve-and-read models and extend this approach to a broader set of tasks.",Finding,https://export.arxiv.org/pdf/2204.04581v3.pdf
218,201646361,Movie Plot Analysis via Turning Point Identification,conclusions,we proposed the task of turning point identification in screenplays as a means of analyzing their narrative structure.,ReSolved,https://www.aclweb.org/anthology/D19-1180.pdf
219,201646361,Movie Plot Analysis via Turning Point Identification,conclusions,we demonstrated that automatically identifying a sequence of key events and segmenting the screenplay into thematic units is feasible via an end-to-end neural network model.,ReSolved,https://www.aclweb.org/anthology/D19-1180.pdf
220,201646361,Movie Plot Analysis via Turning Point Identification,conclusions,"in future work, we will investigate the usefulness of tps for summarization and question answering.",Finding,https://www.aclweb.org/anthology/D19-1180.pdf
221,201646361,Movie Plot Analysis via Turning Point Identification,conclusions,we will also scale the tripod dataset and move to a multi-modal setting where tps are identified directly in video data.,Finding,https://www.aclweb.org/anthology/D19-1180.pdf
222,221970190,What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams,conclusion,"we present the first open-domain multiple-choice question answering dataset for solving medical problems, medqa, collected from the real-world professional examinations, requiring extensive and advanced domain knowledge to answer questions.",ReSolved,https://arxiv.org/pdf/2009.13081v1.pdf
223,221970190,What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams,conclusion,"this dataset covers three languages: english, simplified chinese, and traditional chinese.",ReSolved,https://arxiv.org/pdf/2009.13081v1.pdf
224,221970190,What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams,conclusion,"together with the question data, we also collect and release a largescale corpus from medical textbooks from which the reading comprehension models can obtain necessary knowledge for answering the questions.",ReSolved,https://arxiv.org/pdf/2009.13081v1.pdf
225,221970190,What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams,conclusion,we implement several state-of-theart methods as baselines to this dataset by cascading two components: document retrieval and reading comprehension.,ReSolved,https://arxiv.org/pdf/2009.13081v1.pdf
226,221970190,What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams,conclusion,and experimental results demonstrate that even current best approach cannot achieve good performance on these data.,ReSolved,https://arxiv.org/pdf/2009.13081v1.pdf
227,221970190,What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams,conclusion,we anticipate more research efforts from the community can be devoted to this dataset so that future openqa models can be strong enough to solve such real-world complex problems.,Finding,https://arxiv.org/pdf/2009.13081v1.pdf
228,248366293,Association for Computational Linguistics,conclusion,"in this paper we present seal, a novel retrieval system that combines an autoregressive language model with a compressed full-text substring index.",ReSolved,https://arxiv.org/pdf/2204.10628v1.pdf
229,248366293,Association for Computational Linguistics,conclusion,such combination allows to constraint the generation of existing ngrams in a corpus and to jointly retrieve all the documents containing them.,ReSolved,https://arxiv.org/pdf/2204.10628v1.pdf
230,248366293,Association for Computational Linguistics,conclusion,"empirically, we show an improvement of more than 10 points in average passage-level r-precision on kilt, and establish new state-of-the-art downstream performance on 4 out 7 datasets when paired with a reader model.",ReSolved,https://arxiv.org/pdf/2204.10628v1.pdf
231,248366293,Association for Computational Linguistics,conclusion,"while our results show that seal could already compete with more established retrieval systems, we believe there is potential in exploring the use of existing (or yet to come) larger autoregressive models.   ",Finding,https://arxiv.org/pdf/2204.10628v1.pdf
232,215828216,ETC: Encoding Long and Structured Data in Transformers,conclusions,"this paper introduced the extended transformer construction, or etc, a novel extension of the original transformer model designed specifically to (1) scale up the input length to sequences longer than 512 tokens (scaling linearly in the size of the input), and (2) allow ingesting structured inputs.",ReSolved,https://arxiv.org/pdf/2004.08483v2.pdf
233,215828216,ETC: Encoding Long and Structured Data in Transformers,conclusions,"etc also allows lifting weights from existing bert models, saving significant computational resources while training.",ReSolved,https://arxiv.org/pdf/2004.08483v2.pdf
234,215828216,ETC: Encoding Long and Structured Data in Transformers,conclusions,"the key ideas that enable etc to achieve these are a new global-local attention mechanism, coupled with relative position encodings.",ReSolved,https://arxiv.org/pdf/2004.08483v2.pdf
235,246996947,SGPT: GPT Sentence Embeddings for Semantic Search,conclusion and future work,"this work presented sgpt building on sbert, we proposed modifications to gpt models to use them as cross-or bi-encoders for semantic search.",ReSolved,https://export.arxiv.org/pdf/2202.08904v5.pdf
236,252199900,Domain Adaptation for Question Answering via Question Classification,conclusion,"in this paper, we propose a novel framework for qa domain adaptation.",ReSolved,https://www.aclanthology.org/2022.coling-1.153.pdf
237,252199900,Domain Adaptation for Question Answering via Question Classification,conclusion,the proposed qc4qa combines question classification with self-supervised adaptation techniques.,ReSolved,https://www.aclanthology.org/2022.coling-1.153.pdf
238,252199900,Domain Adaptation for Question Answering via Question Classification,conclusion,qc4qa leverages question classes to reduce domain discrepancies and resemble target data distribution in training.,ReSolved,https://www.aclanthology.org/2022.coling-1.153.pdf
239,252199900,Domain Adaptation for Question Answering via Question Classification,conclusion,"different from existing works, qc4qa achieves superior performance by introducing a simple question classifier and incorporating the question class information in the training objective.",ReSolved,https://www.aclanthology.org/2022.coling-1.153.pdf
240,252199900,Domain Adaptation for Question Answering via Question Classification,conclusion,we demonstrate the efficiency and effectiveness of qc4qa compared to state-of-the-art approaches by achieving a substantially better performance on multiple datasets.,ReSolved,https://www.aclanthology.org/2022.coling-1.153.pdf
241,232075995,Published as a conference paper at ICLR 2021 LEARNING REASONING PATHS OVER SEMANTIC GRAPHS FOR VIDEO-GROUNDED DIALOGUES,conclusion,"we proposed pdc, a novel approach to learning a reasoning path over dialogue turns for videogrounded dialogues.",ReSolved,https://export.arxiv.org/pdf/2103.00820v2.pdf
242,232075995,Published as a conference paper at ICLR 2021 LEARNING REASONING PATHS OVER SEMANTIC GRAPHS FOR VIDEO-GROUNDED DIALOGUES,conclusion,"our approach exploits the compositional semantics in each dialogue turn to construct a semantic graph, which is then used to derive an optimal path for feature propagation.",ReSolved,https://export.arxiv.org/pdf/2103.00820v2.pdf
243,232075995,Published as a conference paper at ICLR 2021 LEARNING REASONING PATHS OVER SEMANTIC GRAPHS FOR VIDEO-GROUNDED DIALOGUES,conclusion,our experiments demonstrate that our model can learn to retrieve paths that are most relevant to the current question.,ReSolved,https://export.arxiv.org/pdf/2103.00820v2.pdf
244,232075995,Published as a conference paper at ICLR 2021 LEARNING REASONING PATHS OVER SEMANTIC GRAPHS FOR VIDEO-GROUNDED DIALOGUES,conclusion,"we hope our approach can motivate further study to investigate reasoning over multiple turns, especially in complex settings with interconnected dialogue flows (sun et al., 2019).",Finding,https://export.arxiv.org/pdf/2103.00820v2.pdf
245,234334701,REPT: Bridging Language Models and Machine Reading Comprehension via Retrieval-Based Pre-training,conclusion and future work,"in this paper, we present a novel pre-training approach, rept, to bridge the gap between pretrained language models and machine reading comprehension through retrieval-based pre-training.",ReSolved,https://arxiv.org/pdf/2105.04201v2.pdf
246,234334701,REPT: Bridging Language Models and Machine Reading Comprehension via Retrieval-Based Pre-training,conclusion and future work,"specifically, we design two retrieval-based pretraining tasks equipped with self-supervised learning, namely surrounding sentences prediction (ssp) and retreval based masked language modeling (rmlm), to enhance plms with the capability of evidence extraction for mrc.",ReSolved,https://arxiv.org/pdf/2105.04201v2.pdf
247,234334701,REPT: Bridging Language Models and Machine Reading Comprehension via Retrieval-Based Pre-training,conclusion and future work,the experiments over five different datasets validate the effectiveness of our proposed method.,ReSolved,https://arxiv.org/pdf/2105.04201v2.pdf
248,234334701,REPT: Bridging Language Models and Machine Reading Comprehension via Retrieval-Based Pre-training,conclusion and future work,"in the future, we plan to extend the proposed pre-training approach to the more challenging open-domain settings.",Finding,https://arxiv.org/pdf/2105.04201v2.pdf
249,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,conclusion,we conduct an extensive evaluation of the robustness of different model and adaptation methods on 15 distribution shifts in question answering.,ReSolved,https://export.arxiv.org/pdf/2210.12517v1.pdf
250,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,conclusion,our in-depth analysis suggests several concrete directions for future work: improving the in-distribution performance of icl methods and understanding why different few-shot fine-tuning methods yield the squadshifts wiki dataset is derived from the same data source (wikipedia) as squad.,Finding,https://export.arxiv.org/pdf/2210.12517v1.pdf
251,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,conclusion,"as a result, models lie closer to the y = x diagonal than on other distribution shifts.",Neutral,https://export.arxiv.org/pdf/2210.12517v1.pdf
252,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,conclusion,progress on squad is a weaker indicator for progress on searchqa for fully fine-tuned models and few-shot fine-tuned models.,ReSolved,https://export.arxiv.org/pdf/2210.12517v1.pdf
253,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,conclusion,we find that zero-shot and icl models are less robust than fine-tuned and few-shot models with the exception of larger language models.,ReSolved,https://export.arxiv.org/pdf/2210.12517v1.pdf
254,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,conclusion,"on the squad→drop distribution shift, we observe that progress beyond 70 f1 on squad yields quick progress on drop for fine-tuned models.",ReSolved,https://export.arxiv.org/pdf/2210.12517v1.pdf
255,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,experimenting with different in-distribution datasets.,Neutral,https://export.arxiv.org/pdf/2210.12517v1.pdf
256,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,we choose squad as a representative in-distribution dataset since it is one of the largest and most popular qa datasets.,ReSolved,https://export.arxiv.org/pdf/2210.12517v1.pdf
257,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,one limitation of squad is that the training set is mainly collected from wikipedia articles which may not be optimal for building a qa model that generalizes to many domains.,Finding,https://export.arxiv.org/pdf/2210.12517v1.pdf
258,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,future work could explore the robustness of models trained on datasets from other domains for increased coverage.specialized modeling methods.,Finding,https://export.arxiv.org/pdf/2210.12517v1.pdf
259,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,our work does not evaluate models with task or data specific components.,Finding,https://export.arxiv.org/pdf/2210.12517v1.pdf
260,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,"as an example andor et al. (2019) improved performance on drop (dua et al., 2019) by using arithmetic programs to improve a model's mathematical reasoning.",Neutral,https://export.arxiv.org/pdf/2210.12517v1.pdf
261,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,evaluating the robustness of methods like these are an exciting area for future investigations.few-shot gpt evaluations.,Finding,https://export.arxiv.org/pdf/2210.12517v1.pdf
262,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,our results indicate that large gpt models fine-tuned on a smaller number of samples are more robust to distribution shifts compared to other few-shot fine-tuned models that use a prompt or span prediction.,ReSolved,https://export.arxiv.org/pdf/2210.12517v1.pdf
263,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,"however, gpt-2 xl and gpt-neo, which both have more than one billion parameters, are larger than all few-shot models we evaluate.",ReSolved,https://export.arxiv.org/pdf/2210.12517v1.pdf
264,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,future work could examine the impact of architecture on this trend by evaluating other models with more than a billion parameters like t5.multiple fine-tuning runs.,Finding,https://export.arxiv.org/pdf/2210.12517v1.pdf
265,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,for fine-tuned models we include a single data-point for each model.,Neutral,https://export.arxiv.org/pdf/2210.12517v1.pdf
266,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,"however, previous work (phang et al., 2018;dodge et al., 2020) has shown that different data ordering and weight initialization can lead to large variance in model performance.",Neutral,https://export.arxiv.org/pdf/2210.12517v1.pdf
267,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,"we evaluate the robustness of roberta large models fine-tuned with different data ordering and initialization for the span prediction head (devlin et al., 2019).",ReSolved,https://export.arxiv.org/pdf/2210.12517v1.pdf
268,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,we find that on average the robustness of these models does not differ substantially.,ReSolved,https://export.arxiv.org/pdf/2210.12517v1.pdf
269,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,further investigation into the effect of random seeds on robustness would improve our understanding of the robustness of individual data points.,Finding,https://export.arxiv.org/pdf/2210.12517v1.pdf
270,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,"as at most other universities, notre dame's students run a number of news media outlets.",Neutral,https://export.arxiv.org/pdf/2210.12517v1.pdf
271,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,"the nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals.",Neutral,https://export.arxiv.org/pdf/2210.12517v1.pdf
272,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,question: how many student news papers are found at notre dame?,Neutral,https://export.arxiv.org/pdf/2210.12517v1.pdf
273,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,"answer:  a sample from squad with the input formatting used for fine-tuning decoder-only models, incontext learning, and zero-shot inference.",Neutral,https://export.arxiv.org/pdf/2210.12517v1.pdf
274,253098080,Exploring The Landscape of Distributional Robustness for Question Answering Models,limitations,"a sample from squad with the input formatting used for fine-tuning decoder-only models, incontext learning, and zero-shot inference.",Neutral,https://export.arxiv.org/pdf/2210.12517v1.pdf
275,248447769,Molecular Characterization of Salmonella Typhimurium and E. coli O157:H7 Isolated from Ready-to-eat Chicken Meat,conclusion,this study has indicated presence of sdia and fimh genes in salmonella typhimurium and e. coli o157:h7 respectively isolated from ready to eat chicken meats from public eateries in ibadan.,ReSolved,https://journaljpri.com/index.php/JPRI/article/download/36132/68318
276,252872925,Improving Question Answering with Generation of NQ-like Questions,conclusion and future work,we clearly observe from the results that adding filtered nq-like questions from the qb data has given a boost over using only nq questions.,ReSolved,https://export.arxiv.org/pdf/2210.06599v1.pdf
277,252872925,Improving Question Answering with Generation of NQ-like Questions,conclusion and future work,"in finer detail, we observe that questions from the last sentence of the qb are of higher quality than from intermediate sentences and therefore provide a higher boost to performance even with less sam-ples.",ReSolved,https://export.arxiv.org/pdf/2210.06599v1.pdf
278,252872925,Improving Question Answering with Generation of NQ-like Questions,conclusion and future work,"even by simply adding questions generated from last sentence, we increase the exact match accuracy by nearly 2 points.",ReSolved,https://export.arxiv.org/pdf/2210.06599v1.pdf
279,252872925,Improving Question Answering with Generation of NQ-like Questions,conclusion and future work,we also observe that the bleu score of answers generated from quality controlled nq like system is 16 points more than the bleu score of the baseline qb system for the rag system and by 13 points for the drqa system.,ReSolved,https://export.arxiv.org/pdf/2210.06599v1.pdf
280,252872925,Improving Question Answering with Generation of NQ-like Questions,conclusion and future work,this shows that our algorithm to generate nq-like questions has been effective in improving the quality of the training dataset.,ReSolved,https://export.arxiv.org/pdf/2210.06599v1.pdf
281,247475874,E-KAR : A Benchmark for Rationalizing Natural Language Analogical Reasoning,conclusion and discussion,"in this work, we propose a first-of-its-kind benchmark e-kar (in both chinese and english) for explainable analogical reasoning, which sets a concrete playground and evaluation benchmark to boost the development of human-like analogical reasoning algorithms.",ReSolved,https://www.aclanthology.org/2022.findings-acl.311.pdf
282,247475874,E-KAR : A Benchmark for Rationalizing Natural Language Analogical Reasoning,conclusion and discussion,the e-kar benchmark is featured by its rich coverage in knowledge and welldesigned free-text explanations to rationalize the analogical reasoning process.,ReSolved,https://www.aclanthology.org/2022.findings-acl.311.pdf
283,247475874,E-KAR : A Benchmark for Rationalizing Natural Language Analogical Reasoning,conclusion and discussion,preliminary experiments show that this benchmark provides a rather difficult challenge for prevailing language models.,Neutral,https://www.aclanthology.org/2022.findings-acl.311.pdf
284,255186555,DEMONSTRATE-SEARCH-PREDICT: Composing retrieval and language models for knowledge-intensive NLP,conclusion,"for a long time, the dominant paradigm for building models in ai has centered around multiplication of tensor representations, and in the deep learning era this has given rise to highly modular (layer-wise) designs that allow for fast development and wide exploration.",Neutral,https://export.arxiv.org/pdf/2212.14024v2.pdf
285,255186555,DEMONSTRATE-SEARCH-PREDICT: Composing retrieval and language models for knowledge-intensive NLP,conclusion,"however, these design paradigms require extensive domain expertise, and even experts face substantial challenges when it comes to combining different pretrained components into larger systems.",Neutral,https://export.arxiv.org/pdf/2212.14024v2.pdf
286,237347226,"Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation for Few-shot Learning",conclusion,"we present the continual learning of few-shot learners (clif) challenge to simulate the scenario where a learner continually accumulate (generalizable) knowledge over a sequence of nlp tasks, while retaining its performance on the seen tasks.",ReSolved,https://export.arxiv.org/pdf/2104.08808v4.pdf
287,237347226,"Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation for Few-shot Learning",conclusion,"we propose evaluation protocols to study the performance of existing continual learning algorithm, and present our method bihnet-reg.",ReSolved,https://export.arxiv.org/pdf/2104.08808v4.pdf
288,237347226,"Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation for Few-shot Learning",conclusion,"we demonstrate the potentials of building a nlp system that, through continual training, can perform more tasks and also become more efficient in mastering new tasks.",ReSolved,https://export.arxiv.org/pdf/2104.08808v4.pdf
289,237347226,"Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation for Few-shot Learning",conclusion,future works include extending our work to task agnostic scenarios where the distribution of data may shift continuously and studying algorithms for continual refinement of large-scale pre-trained models with emerging unlabeled data.,Finding,https://export.arxiv.org/pdf/2104.08808v4.pdf
290,222140958,Context Modeling with Evidence Filter for Multiple Choice Question Answering,conclusions,we propose evidence filter to alleviate the effect of unrelated sentences and enhance the saliency of evidences potentially without human efforts.,ReSolved,https://arxiv.org/pdf/2010.02649v1.pdf
291,222140958,Context Modeling with Evidence Filter for Multiple Choice Question Answering,conclusions,results on openbookqa indicate the effectiveness of our method.,ReSolved,https://arxiv.org/pdf/2010.02649v1.pdf
292,222140958,Context Modeling with Evidence Filter for Multiple Choice Question Answering,conclusions,our future work is to enhance the evidence filter by more complex components.,Finding,https://arxiv.org/pdf/2010.02649v1.pdf
293,5106665,A Model for Processing Temporal References in Chinese,conclusions and future work,the issues of mapping linguistic patterns to temporal relations are addressed in the paper.,ReSolved,
294,5106665,A Model for Processing Temporal References in Chinese,conclusions and future work,these mapping is preconditioned on the temporal indicators and achieved on a set of pre-de ned rules.,ReSolved,
295,5106665,A Model for Processing Temporal References in Chinese,conclusions and future work,the mapping mechanism was validated.,Neutral,
296,5106665,A Model for Processing Temporal References in Chinese,conclusions and future work,"on 7429 sentences describing temporal relevance, we achieved 92.77% accuracy in average.",ReSolved,
297,5106665,A Model for Processing Temporal References in Chinese,conclusions and future work,"these relations will be useful to for information extraction, information retrieval and questionanswering application.",ReSolved,
298,5106665,A Model for Processing Temporal References in Chinese,conclusions and future work,once the corresponding frames have been instantiated and their slots lled after temporal natural language processing.,ReSolved,
299,5106665,A Model for Processing Temporal References in Chinese,conclusions and future work,"the related temporal concepts will be linked together according to their chronological orders, to be applied as the knowledge to ful ll users' queries.",ReSolved,
300,236486104,Team JARS: DialDoc Subtask 1 -Improved Knowledge Identification with Supervised Out-of-Domain Pretraining,conclusion,our submission to the dialdoc subtask 1 performs continual pretraining of a transformer-based encoder on out-of-domain qa datasets.,ReSolved,https://www.aclanthology.org/2021.dialdoc-1.13.pdf
301,236486104,Team JARS: DialDoc Subtask 1 -Improved Knowledge Identification with Supervised Out-of-Domain Pretraining,conclusion,"experiments with different qa datasets suggest that conversational qa datasets like coqa and quac are highly beneficial as their setup is substantially similar to doc2dial, the downstream dataset of interest.",ReSolved,https://www.aclanthology.org/2021.dialdoc-1.13.pdf
302,236486104,Team JARS: DialDoc Subtask 1 -Improved Knowledge Identification with Supervised Out-of-Domain Pretraining,conclusion,our final submission ensembles two albert-xl models independently pretrained on coqa and quac and achieves an f1-score of 70.9% and em-score of 53.5% on the competition test-set.,ReSolved,https://www.aclanthology.org/2021.dialdoc-1.13.pdf
303,258547350,Can In-context Learners Learn a Reasoning Concept from Demonstrations?,conclusion,this work introduces a task of conceptual few-shot learning that reflects on in-context learners' ability to learn to apply a specific reasoning concept that can be informative for prediction.,ReSolved,https://export.arxiv.org/pdf/2212.01692v3.pdf
304,258547350,Can In-context Learners Learn a Reasoning Concept from Demonstrations?,conclusion,we assess a set of recent in-context learners for this ability over a set of concepts extracted from human explanations.,ReSolved,https://export.arxiv.org/pdf/2212.01692v3.pdf
305,247518809,Ask to Understand: Question Generation for Multi-hop Question Answering,conclusion,"in this paper, inspired by human cognitive behavior, we believe that asking questions is an important indication to testify whether the model truly understands the input text.",Neutral,https://arxiv.org/pdf/2203.09073v1.pdf
306,247518809,Ask to Understand: Question Generation for Multi-hop Question Answering,conclusion,"therefore, we propose a qg module to solve multi-hop qa task in an interpretable manner.",ReSolved,https://arxiv.org/pdf/2203.09073v1.pdf
307,247518809,Ask to Understand: Question Generation for Multi-hop Question Answering,conclusion,"based on the traditional qa module, the addition of the qg module could effectively improve the natural language understanding capability and bring superior and robust performance through asking questions.",ReSolved,https://arxiv.org/pdf/2203.09073v1.pdf
308,247518809,Ask to Understand: Question Generation for Multi-hop Question Answering,conclusion,"moreover, we quantitatively analyze interpretability provided by sub-questions via human evaluation, and further clarify the interpretability via attention visualization.",ReSolved,https://arxiv.org/pdf/2203.09073v1.pdf
309,247518809,Ask to Understand: Question Generation for Multi-hop Question Answering,conclusion,"at last, we verify that the sub-questions obtained by the qg method are better in terms of linguistic fluency, consistency, and diversity than those obtained by the qd method.",ReSolved,https://arxiv.org/pdf/2203.09073v1.pdf
310,258587884,Automatic Evaluation of Attribution by Large Language Models,conclusion,the paper explores the challenging problem of evaluating attribution by llms.,ReSolved,https://export.arxiv.org/pdf/2305.06311v1.pdf
311,258587884,Automatic Evaluation of Attribution by Large Language Models,conclusion,"specifically, the paper investigates two approaches for automatic evaluation: prompting llms and fine-tuning smaller lms.",ReSolved,https://export.arxiv.org/pdf/2305.06311v1.pdf
312,258587884,Automatic Evaluation of Attribution by Large Language Models,conclusion,the evaluation is tested on a set of manually curated test examples from a generative search engine and simulated test examples from qa.,ReSolved,https://export.arxiv.org/pdf/2305.06311v1.pdf
313,258587884,Automatic Evaluation of Attribution by Large Language Models,conclusion,the results highlight both promising signals and remaining challenges for the automatic evaluation of attribution by llms.,ReSolved,https://export.arxiv.org/pdf/2305.06311v1.pdf
314,258587884,Automatic Evaluation of Attribution by Large Language Models,conclusion,the insights gained from this study and the provided testbed and modeling methodology can inspire future studies on this important problem.,Neutral,https://export.arxiv.org/pdf/2305.06311v1.pdf
315,258587884,Automatic Evaluation of Attribution by Large Language Models,limitations,the current version of attributionscore is primarily trained on a simulated or repurposed error dataset from similar tasks.,Neutral,https://export.arxiv.org/pdf/2305.06311v1.pdf
316,258587884,Automatic Evaluation of Attribution by Large Language Models,limitations,"however, this dataset still has gaps compared to the real attribution scenario.",Neutral,https://export.arxiv.org/pdf/2305.06311v1.pdf
317,258587884,Automatic Evaluation of Attribution by Large Language Models,limitations,"to strengthen the generalizability of attributionscore and improve consistency with human judgment, we plan to collect and annotate more error cases from other generative search engines besides new bing.",ReSolved,https://export.arxiv.org/pdf/2305.06311v1.pdf
318,258587884,Automatic Evaluation of Attribution by Large Language Models,limitations,these additional cases will be used to further fine-tune and evaluate attributionscore.,Neutral,https://export.arxiv.org/pdf/2305.06311v1.pdf
319,252715485,Decomposed Prompting : A MODULAR APPROACH FOR SOLVING COMPLEX TASKS,conclusion,"we proposed a new approach, decomposed prompting, to solve complex tasks using few-shot prompts, by decomposing them into a prompting program built out of simpler sub-tasks.",ReSolved,https://export.arxiv.org/pdf/2210.02406v1.pdf
320,252715485,Decomposed Prompting : A MODULAR APPROACH FOR SOLVING COMPLEX TASKS,conclusion,"drawing inspiration from software libraries, our decomposer and shared sub-tasks are designed in a modular fashion: they use their own few-shot prompts, allowing one to independently optimize each prompt, decompose a sub-task further if necessary, or even seamlessly replace it with a symbolic system.",ReSolved,https://export.arxiv.org/pdf/2210.02406v1.pdf
321,252715485,Decomposed Prompting : A MODULAR APPROACH FOR SOLVING COMPLEX TASKS,conclusion,"we show that decomposed prompting outperforms prior work on four different tasks and generalization settings, establishing it as an effective few-shot paradigm for solving complex tasks.",ReSolved,https://export.arxiv.org/pdf/2210.02406v1.pdf
322,248496232,Don't Blame the Annotator: Bias Already Starts in the Annotation Instructions,conclusions and discussion,"we identify a prominent source of bias in crowdsourced nlu datasets, called instruction bias, which originates in annotation instructions written by dataset creators.",ReSolved,https://www.aclanthology.org/2023.eacl-main.130.pdf
323,248496232,Don't Blame the Annotator: Bias Already Starts in the Annotation Instructions,conclusions and discussion,"we study this bias in 14 nlu benchmarks, showing that instruction examples used to create nlu benchmarks often exhibit clear patterns that are propagated by annotators to the collected data.",ReSolved,https://www.aclanthology.org/2023.eacl-main.130.pdf
324,248496232,Don't Blame the Annotator: Bias Already Starts in the Annotation Instructions,conclusions and discussion,"in addition, we investigate the effect of instruction bias on model performance, showing that instruction patterns can lead to overestimated performance as well as limit the ability of models to generalize to other task examples.",ReSolved,https://www.aclanthology.org/2023.eacl-main.130.pdf
325,259096138,Gotta: Generative Few-shot Question Answering by Prompt-based Cloze Data Augmentation,conclusion and future work,"in this work, we propose to incorporate the cloze task to improve neural machine question answering with a few training examples.",ReSolved,https://export.arxiv.org/pdf/2306.04101v1.pdf
326,259096138,Gotta: Generative Few-shot Question Answering by Prompt-based Cloze Data Augmentation,conclusion and future work,the key idea is to identify and mask the informative entities in the passage and make the model predict them correctly.,ReSolved,https://export.arxiv.org/pdf/2306.04101v1.pdf
327,259096138,Gotta: Generative Few-shot Question Answering by Prompt-based Cloze Data Augmentation,conclusion and future work,"through empirical experimental studies on various qa benchmarks and different few-shot settings, we show that the cloze task indeed benefits the qa task due to its commonalities.",ReSolved,https://export.arxiv.org/pdf/2306.04101v1.pdf
328,259096138,Gotta: Generative Few-shot Question Answering by Prompt-based Cloze Data Augmentation,conclusion and future work,we find different ways of incorporating the cloze task improve the qa task while prompt-tuning brings the most.,ReSolved,https://export.arxiv.org/pdf/2306.04101v1.pdf
329,259096138,Gotta: Generative Few-shot Question Answering by Prompt-based Cloze Data Augmentation,conclusion and future work,"looking forward, it is of interest to explore qa-dedicated pre-training and ways of pipelining pretraining and prompt-tuning for downstream few-shot qa needs.",Finding,https://export.arxiv.org/pdf/2306.04101v1.pdf
330,246638887,E M E R G I N G T R E N D S Emerging Trends: SOTA-Chasing,conclusions/recommendations,"many papers are sota-chasing, and more will do so in the future.",Finding,
331,246638887,E M E R G I N G T R E N D S Emerging Trends: SOTA-Chasing,conclusions/recommendations,sota-chasing comes with many costs.,Neutral,
332,246638887,E M E R G I N G T R E N D S Emerging Trends: SOTA-Chasing,conclusions/recommendations,we discussed three costs:,Neutral,
333,237420912,FewshotQA: A simple framework for few-shot learning of question answering tasks using pre-trained text-to-text models,conclusion,we present an effective few-shot question answering (qa) system that combines the use of pre-trained text-to-text models and a fine-tuning framework aligned with their pre-training counterpart.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.491.pdf
334,237420912,FewshotQA: A simple framework for few-shot learning of question answering tasks using pre-trained text-to-text models,conclusion,"through experimental studies on various qa benchmarks and few-shot configurations, we show that this system can produce significant gains including in scenarios where the training data is extremely scarce (an absolute gain of 34 f1 points on average in comparison to the current standard of the fine-tuning framework).",ReSolved,https://www.aclanthology.org/2021.emnlp-main.491.pdf
335,237420912,FewshotQA: A simple framework for few-shot learning of question answering tasks using pre-trained text-to-text models,conclusion,we also present extensions to multilingual and larger model settings and show that the gains translate well to these settings (eg:-up to an absolute 40 f1 point gain in comparison to xlm-roberta + a span-selection objective).,ReSolved,https://www.aclanthology.org/2021.emnlp-main.491.pdf
336,237420912,FewshotQA: A simple framework for few-shot learning of question answering tasks using pre-trained text-to-text models,conclusion,"through ablation studies, we study the impact of model size, fine-tuning objectives, inputoutput design and illustrate the factors leading to such strong gains.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.491.pdf
337,237420912,FewshotQA: A simple framework for few-shot learning of question answering tasks using pre-trained text-to-text models,conclusion,"for future, as our framework doesn't explicitly enforce the answer to be a span in the input text, it'd be interesting to consider its applications to generative qa tasks.",Finding,https://www.aclanthology.org/2021.emnlp-main.491.pdf
338,258959022,Plug-and-Play Document Modules for Pre-trained Models 5 Beijing Key Laboratory of Big Data Management and Analysis Methods,conclusion,"in this paper, we explore a new paradigm, which aims to represent documents as pluggable modules for ptms.",ReSolved,https://export.arxiv.org/pdf/2305.17660v1.pdf
339,258959022,Plug-and-Play Document Modules for Pre-trained Models 5 Beijing Key Laboratory of Big Data Management and Analysis Methods,conclusion,"in this setting, we can get rid of encoding the same document multiple times for different tasks.",Neutral,https://export.arxiv.org/pdf/2305.17660v1.pdf
340,258959022,Plug-and-Play Document Modules for Pre-trained Models 5 Beijing Key Laboratory of Big Data Management and Analysis Methods,conclusion,the extensive experiments prove that our proposed plugd can significantly reduce the computational cost and effectively inject document knowledge into ptms to improve performance.,ReSolved,https://export.arxiv.org/pdf/2305.17660v1.pdf
341,258959022,Plug-and-Play Document Modules for Pre-trained Models 5 Beijing Key Laboratory of Big Data Management and Analysis Methods,conclusion,"in the future, we will explore more effective plugin learning tasks and further attempt to represent knowledge graphs, and figures as plugins to provide knowledge for ptms.",Finding,https://export.arxiv.org/pdf/2305.17660v1.pdf
342,258436815,"Huatuo-26M, a Large-scale Chinese Medical QA Dataset",conclusion,"in this paper, we propose the largest chinese medical qa dataset to date, consisting of 26 million medical qa pairs, expanding the size of existing datasets by more than 2 orders of magnitude.",ReSolved,https://export.arxiv.org/pdf/2305.01526v1.pdf
343,258436815,"Huatuo-26M, a Large-scale Chinese Medical QA Dataset",conclusion,"at the same time, we benchmark many existing works based on the data set and found that these methods still have a lot of room for improvement in medical qa scenarios.",ReSolved,https://export.arxiv.org/pdf/2305.01526v1.pdf
344,258436815,"Huatuo-26M, a Large-scale Chinese Medical QA Dataset",conclusion,we also demonstrate the possible uses of the dataset in practice.,ReSolved,https://export.arxiv.org/pdf/2305.01526v1.pdf
345,258436815,"Huatuo-26M, a Large-scale Chinese Medical QA Dataset",conclusion,the experimental results show that the dataset contains rich medical knowledge that can be very helpful to existing datasets and tasks.,ReSolved,https://export.arxiv.org/pdf/2305.01526v1.pdf
346,258436815,"Huatuo-26M, a Large-scale Chinese Medical QA Dataset",conclusion,"we hope that the huatuo-26m dataset can not only help promote the research of medical qa, but also practically help doctors and patients.",ReSolved,https://export.arxiv.org/pdf/2305.01526v1.pdf
347,251718892,Locate Then Ask: Interpretable Stepwise Reasoning for Multi-hop Question Answering,conclusion,"in this paper, we study the task of multi-hop question answering and propose to stepwise locate the single-hop supporting sentences and generate more fact-grounded single-hop questions for better interpretable multi-hop reasoning.",ReSolved,https://www.aclanthology.org/2022.coling-1.142.pdf
348,251718892,Locate Then Ask: Interpretable Stepwise Reasoning for Multi-hop Question Answering,conclusion,we present a stepwise reasoning framework to incorporate both single-hop supporting sentence identification and the corresponding single-hop question generation for each intermediate step until inferring a final result.,ReSolved,https://www.aclanthology.org/2022.coling-1.142.pdf
349,251718892,Locate Then Ask: Interpretable Stepwise Reasoning for Multi-hop Question Answering,conclusion,"it employs a pre-trained simple question generator and takes the identified single-hop supporting sentences as base to generate the single-hop question, which obviates the necessity of constructed supervision and helps generate more fact-based single-hop questions.",ReSolved,https://www.aclanthology.org/2022.coling-1.142.pdf
350,251718892,Locate Then Ask: Interpretable Stepwise Reasoning for Multi-hop Question Answering,conclusion,it utilizes a unified reader to jointly learn both intermediate hop reasoning and final hop inference for better fault tolerance.,ReSolved,https://www.aclanthology.org/2022.coling-1.142.pdf
351,251718892,Locate Then Ask: Interpretable Stepwise Reasoning for Multi-hop Question Answering,conclusion,experimental results validate the general effectiveness and interpretability of our stepreasoner.,ReSolved,https://www.aclanthology.org/2022.coling-1.142.pdf
352,256461282,Explainable Question Answering based on Semantic Graph by Global Differentiable Learning and Dynamic Adaptive Reasoning,conclusion,we take a step forward in constructing the explainable method for multi-hop question answering by proposing two effective improvements.,Neutral,https://www.aclanthology.org/2022.emnlp-main.356.pdf
353,256461282,Explainable Question Answering based on Semantic Graph by Global Differentiable Learning and Dynamic Adaptive Reasoning,conclusion,the global differentiable learning strategy learns optimal reasoning paths by exploring latent probability space to alleviate the problem of semantic space mismatch and error propagation.,Neutral,https://www.aclanthology.org/2022.emnlp-main.356.pdf
354,256461282,Explainable Question Answering based on Semantic Graph by Global Differentiable Learning and Dynamic Adaptive Reasoning,conclusion,the dynamic adaptive reasoner improves generalization to unseen sub-questions.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.356.pdf
355,256461282,Explainable Question Answering based on Semantic Graph by Global Differentiable Learning and Dynamic Adaptive Reasoning,conclusion,our method successfully learns the intermediate reasoning process and shows better interpretability.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.356.pdf
356,256461282,Explainable Question Answering based on Semantic Graph by Global Differentiable Learning and Dynamic Adaptive Reasoning,limitations,question decomposition is the pre-stage of building interpretable models.,Neutral,https://www.aclanthology.org/2022.emnlp-main.356.pdf
357,256461282,Explainable Question Answering based on Semantic Graph by Global Differentiable Learning and Dynamic Adaptive Reasoning,limitations,"to the best of our knowledge, there is only one largescale question decomposition dataset (wolfson et al., 2020), and the performance of existing automatic decomposition models is far below human performance.",Neutral,https://www.aclanthology.org/2022.emnlp-main.356.pdf
358,256461282,Explainable Question Answering based on Semantic Graph by Global Differentiable Learning and Dynamic Adaptive Reasoning,limitations,inaccurate question decomposition leads to errors in reasoning.,Neutral,https://www.aclanthology.org/2022.emnlp-main.356.pdf
359,256461282,Explainable Question Answering based on Semantic Graph by Global Differentiable Learning and Dynamic Adaptive Reasoning,limitations,"therefore, exploring better question decomposition techniques is a challenging and rewarding direction. existing interpretable models (min et al., 2019;jiang and bansal, 2019;ding et al., 2019;khot et al., 2021;wolfson et al., 2020), including our approach, focus on solving complex questions, ignoring a simple question with a complex context that requires a deep understanding of the context to reason out the answer. the dynamic adaptive reasoner introduces a small number of additional parameters in the router, which can increase the computational cost.",Neutral,https://www.aclanthology.org/2022.emnlp-main.356.pdf
360,256461282,Explainable Question Answering based on Semantic Graph by Global Differentiable Learning and Dynamic Adaptive Reasoning,limitations,a more efficient parameter-free routing approach can be explored in the future.,Finding,https://www.aclanthology.org/2022.emnlp-main.356.pdf
361,253244513,Natural Language Deduction with Incomplete Information,conclusion,"in this work, we tackle the generation of missing premise statements in textual reasoning through the use of abduction.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.564.pdf
362,253244513,Natural Language Deduction with Incomplete Information,conclusion,"we introduce a new system capable of abductive and deductive step generation, which yields inferred missing premises while building a proof showing its reasoning.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.564.pdf
363,253244513,Natural Language Deduction with Incomplete Information,conclusion,"furthermore, we propose a novel validation method that reduces hallucination and other common failure modes in end-to-end and stepwise searches.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.564.pdf
364,253244513,Natural Language Deduction with Incomplete Information,conclusion,"future work can improve our system by scaling up the models used, plus using additional notions of validation as discussed in the error analysis.",Finding,https://www.aclanthology.org/2022.emnlp-main.564.pdf
365,253244513,Natural Language Deduction with Incomplete Information,conclusion,we believe our overall framework can be a promising foundation for future reasoning systems.,Finding,https://www.aclanthology.org/2022.emnlp-main.564.pdf
366,253244513,Natural Language Deduction with Incomplete Information,limitations,"end-to-end models are able to produce a single generation per example reducing the time complexity for sufficiently small sets of premises.step-by-step models like our search procedure in this work are capable of handling sets of any size of premises for the search, but do increase the execution time per example, especially when using validators that require doing generation themselves.",Neutral,https://www.aclanthology.org/2022.emnlp-main.564.pdf
367,253244513,Natural Language Deduction with Incomplete Information,limitations,"nevertheless, validators do reduce the total time required for running a set of examples due to their ability of pruning the search space and thus removing numerous heuristic and generation calls.",Neutral,https://www.aclanthology.org/2022.emnlp-main.564.pdf
368,253244513,Natural Language Deduction with Incomplete Information,limitations,"with better heuristics and validators it may be possible to reduce the time complexity further, but that is left for future work.both the entailmentbank and enwn dataset were written in english and capture relatively limited domains of textual reasoning.",Finding,https://www.aclanthology.org/2022.emnlp-main.564.pdf
369,253244513,Natural Language Deduction with Incomplete Information,limitations,different languages might introduce easier lexical patterns for abstraction though and could be a promising path forward.,Finding,https://www.aclanthology.org/2022.emnlp-main.564.pdf
370,253244513,Natural Language Deduction with Incomplete Information,limitations,"we believe adgv and its variants should work on non-english languages, but testing this was left to future work.enwn draws on everyday ethical scenarios because this was a domain we found fruitful to exhibit the kind of reasoning our system can do",Finding,https://www.aclanthology.org/2022.emnlp-main.564.pdf
371,253244513,Natural Language Deduction with Incomplete Information,limitations,"however, we do not follow in the steps of delphi (jiang et al., 2021) in making any claims about its ability to make systems ethical or say anything about ""values"" encoded in pre-trained models.",Neutral,https://www.aclanthology.org/2022.emnlp-main.564.pdf
372,253244513,Natural Language Deduction with Incomplete Information,limitations,"we do not support its use as part of any user-facing system at this time.step signaturestep typex, x → y d deductive x, y d → y d deductive g, x → ya abductive g, y d → ya abductive ya, x → ya abductive ya, y d → ya abductive table 6: a list of possible input statement types each step model can take.",Neutral,https://www.aclanthology.org/2022.emnlp-main.564.pdf
373,253244513,Natural Language Deduction with Incomplete Information,limitations,"x refers to a premise, y d refers to an intermediate deductive conclusion, g refers to the goal, and y a refers to an abductive hypothesis.",Neutral,https://www.aclanthology.org/2022.emnlp-main.564.pdf
374,253244513,Natural Language Deduction with Incomplete Information,limitations,"note that the deductive model can accept inputs in any order but the abductive model cannot, as the abduction operation is not commutative.",Neutral,https://www.aclanthology.org/2022.emnlp-main.564.pdf
375,253244513,Natural Language Deduction with Incomplete Information,limitations,"also note that deductive outputs can be used as inputs to abductive steps, but not the other way around; allowing deductive steps to accept abductive generations could result in vacuous proofs.",Neutral,https://www.aclanthology.org/2022.emnlp-main.564.pdf
376,255545881,Mind Reasoning Manners: Enhancing Type Perception for Generalized Zero-shot Logical Reasoning over Text,conclusion and future work,"to study the zero-shot capability of the logical reasoning models, we propose the first benchmark for the generalized zero-shot logical reasoning, named zslr.",ReSolved,https://export.arxiv.org/pdf/2301.02983v1.pdf
377,255545881,Mind Reasoning Manners: Enhancing Type Perception for Generalized Zero-shot Logical Reasoning over Text,conclusion and future work,it includes six splits sampled with three strategies and two metrics to comprehensively evaluate the performances.,ReSolved,https://export.arxiv.org/pdf/2301.02983v1.pdf
378,255545881,Mind Reasoning Manners: Enhancing Type Perception for Generalized Zero-shot Logical Reasoning over Text,conclusion and future work,"also, we propose a model taco to enhance the reasoning type perception through the heuristic input reconstruction and the type-aware contrastive learning.",ReSolved,https://export.arxiv.org/pdf/2301.02983v1.pdf
379,255545881,Mind Reasoning Manners: Enhancing Type Perception for Generalized Zero-shot Logical Reasoning over Text,conclusion and future work,"also, we conduct extensive experiments on the zero-shot splits, full-data setting as well as other dataset.",ReSolved,https://export.arxiv.org/pdf/2301.02983v1.pdf
380,255545881,Mind Reasoning Manners: Enhancing Type Perception for Generalized Zero-shot Logical Reasoning over Text,conclusion and future work,superior results illustrate the effectiveness and generalization capability of the proposed modules.,ReSolved,https://export.arxiv.org/pdf/2301.02983v1.pdf
381,253157925,DyREx: Dynamic Query Representation for Extractive Question Answering,conclusion,"in this paper, we propose dyrex, a method to dynamically compute query representations to calculate the start and end positions of answer spans in extractive question answering.",ReSolved,https://export.arxiv.org/pdf/2210.15048v1.pdf
382,253157925,DyREx: Dynamic Query Representation for Extractive Question Answering,conclusion,"our approach consistently outperforms the dominant approach on a wide range of qa datasets, and the gain is even more significant in a few-shot scenario.",ReSolved,https://export.arxiv.org/pdf/2210.15048v1.pdf
383,253157925,DyREx: Dynamic Query Representation for Extractive Question Answering,conclusion,"in future work, it would be interesting to adapt dyrex for multi-span extraction tasks such as named entity recognition and keyphrase extraction.",Finding,https://export.arxiv.org/pdf/2210.15048v1.pdf
384,240353952,Discourse Comprehension: A Question Answering Framework to Represent Sentence Connections,conclusion,we present dcqa that connects pieces in a document via open-ended questions and full-sentence answers.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.806.pdf
385,240353952,Discourse Comprehension: A Question Answering Framework to Represent Sentence Connections,conclusion,dcqa is collected via a new paradigm that regards the main purpose of a new sentence as an answer to a free-form question evoked earlier in the context.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.806.pdf
386,240353952,Discourse Comprehension: A Question Answering Framework to Represent Sentence Connections,conclusion,"consequently, this paradigm yields both discourse and semantic links across all sentences in a document.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.806.pdf
387,240353952,Discourse Comprehension: A Question Answering Framework to Represent Sentence Connections,conclusion,"dcqa is introduced with the goal of providing a more scalable data collection paradigm, also as initial resource, for answering open-ended questions for discourse comprehension.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.806.pdf
388,240353952,Discourse Comprehension: A Question Answering Framework to Represent Sentence Connections,conclusion,our experiments showed that dcqa provides valuable supervision for such tasks.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.806.pdf
389,252407569,Dynamic Relevance Graph Network for Knowledge-Aware Question Answering,conclusion,"in this paper, we propose a novel dynamic relevance graph network (drgn) architecture for commonsense question answering given an external source of knowledge in the form of a knowledge graph.",ReSolved,https://www.aclanthology.org/2022.coling-1.116.pdf
390,252407569,Dynamic Relevance Graph Network for Knowledge-Aware Question Answering,conclusion,"our model learns the graph node representation while a) exploits the existing relations in kg, b) re-scales the importance of the neighbor nodes in the graph based on training a dynamic relevance matrix, c) establishes direct connections between graph nodes based on measuring the relevance scores of the nodes dynamically during training.",ReSolved,https://www.aclanthology.org/2022.coling-1.116.pdf
391,252407569,Dynamic Relevance Graph Network for Knowledge-Aware Question Answering,conclusion,the dynamic relevance edges help in finding the chain of reasoning when there are missing edges in the original kg.,ReSolved,https://www.aclanthology.org/2022.coling-1.116.pdf
392,252407569,Dynamic Relevance Graph Network for Knowledge-Aware Question Answering,conclusion,our quantitative and qualitative analysis shows that the proposed approach facilitates answering the complex questions that need multiple hops of reasoning.,ReSolved,https://www.aclanthology.org/2022.coling-1.116.pdf
393,252407569,Dynamic Relevance Graph Network for Knowledge-Aware Question Answering,conclusion,"furthermore, since drgn uses the relevance between the question node and graph entities, it exploits the richer semantic context of the question in graph reasoning which leads to improvements in the performance on the negative questions.",ReSolved,https://www.aclanthology.org/2022.coling-1.116.pdf
394,252407569,Dynamic Relevance Graph Network for Knowledge-Aware Question Answering,conclusion,"our proposed approach shows competitive performance on two qa benchmarks, including commonsenseqa and openbookqa.",ReSolved,https://www.aclanthology.org/2022.coling-1.116.pdf
395,89838681,Detection of non specific toll-like receptor 3 in the marine and freshwater fishes,conclusion,the results of phylogenetic analysis showed that the tlr3 gene of the catfish was closely related to i. punctatus and c. batracus as well as some freshwater fish and seawater.,ReSolved,
396,250729995,ScienceQA: a novel resource for question answering on scholarly articles,conclusion and future work,"in this paper, we present scienceqa, a novel dataset for benchmark evaluation of methods in the mrc (qa and qg in particular) task on scholarly articles.",ReSolved,
397,250729995,ScienceQA: a novel resource for question answering on scholarly articles,conclusion and future work,"the dataset is created semi-automatically, consisting of over 100k triples of context-question-answer.",ReSolved,
398,250729995,ScienceQA: a novel resource for question answering on scholarly articles,conclusion and future work,the developed qa system could provide valuable evidence in managing the vast number of scholarly submissions.,ReSolved,
399,250729995,ScienceQA: a novel resource for question answering on scholarly articles,conclusion and future work,"we offer a baseline and two more models, viz., (i). vanilla bert, (ii). science bert (i.e., scib-ert), and (iii). combination of bert and bi-daf.",ReSolved,
400,250729995,ScienceQA: a novel resource for question answering on scholarly articles,conclusion and future work,our proposed models are competitive compared to the existing state-of-the-art models.,ReSolved,
401,250729995,ScienceQA: a novel resource for question answering on scholarly articles,conclusion and future work,our future works would include:,Finding,
402,222272049,Case Study: Deontological Ethics in NLP,conclusion,two principles of deontological ethics-namely the generalization principle and respect for autonomy via informed consent-can be used to decide if an action is ethical.,Finding,https://www.aclweb.org/anthology/2021.naacl-main.297.pdf
403,222272049,Case Study: Deontological Ethics in NLP,conclusion,"despite the limitations of these principles, they can provide useful insights into making nlp systems more ethical.",Finding,https://www.aclweb.org/anthology/2021.naacl-main.297.pdf
404,222272049,Case Study: Deontological Ethics in NLP,conclusion,"through the four case studies discussed in this paper, we demonstrate how these principles can be used to evaluate the decisions made by nlp systems and to identify the missing aspects.",Neutral,https://www.aclweb.org/anthology/2021.naacl-main.297.pdf
405,222272049,Case Study: Deontological Ethics in NLP,conclusion,"for each of the case studies, we also present potential directions for nlp research to move forward and make the system more ethical.",Finding,https://www.aclweb.org/anthology/2021.naacl-main.297.pdf
406,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,probe considerations and limitations.,"the continued growth of probing-based papers has also led to recent work examining best practices for probes, and how to interpret their results.",ReSolved,https://export.arxiv.org/pdf/2103.11072v2.pdf
407,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,probe considerations and limitations.,"hewitt and liang [66] considered how to ensure that a probe is truly reflective of the underlying information present in a model, and proposed the use of a control task, a randomised version of a probe task in which high performance is only possible by memorisation of inputs.",Neutral,https://export.arxiv.org/pdf/2103.11072v2.pdf
408,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,probe considerations and limitations.,"hence, a faithful probe should perform well on a probe task and poorly on a corresponding control task if the underlying model does indeed contain the information being probed for.",Neutral,https://export.arxiv.org/pdf/2103.11072v2.pdf
409,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,probe considerations and limitations.,"the authors found that most probes (including linear classifiers)are over-parameterised, and discuss methods for constraining complex probes (e.g. multilayer perceptrons) to improve faithfulness while still allowing them to achieve similar results.while most papers we have discussed above follow the intuition that probes should avoid complex probes to prevent memorisation",Neutral,https://export.arxiv.org/pdf/2103.11072v2.pdf
410,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,probe considerations and limitations.,"pimentel et al. [127] suggest that instead the probe with the best score on a given task should be chosen as the tightest estimate, since simpler models may simply be unable to extract the linguistic information present in a model, and such linguistic information cannot be 'added' by more complex probes (since their only input are hidden representations).",Neutral,https://export.arxiv.org/pdf/2103.11072v2.pdf
411,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,probe considerations and limitations.,"in addition, the authors argue that memorisation is an important part of linguistic competence, and as such probes should not be artificially punished (via control tasks) for doing this.",Finding,https://export.arxiv.org/pdf/2103.11072v2.pdf
412,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,probe considerations and limitations.,"recent work has also presented methods that avoid making assumptions about probe complexity, such as mdl probing [101,170], which directly measures 'amount of effort' needed to achieve some extraction task, or directprobe [198], which directly examines intermediate representations of models to avoid having to deal with additional classifiers",Neutral,https://export.arxiv.org/pdf/2103.11072v2.pdf
413,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,probe considerations and limitations.,"finally, hall maudslay et al.[59] compared the structural probe",Neutral,https://export.arxiv.org/pdf/2103.11072v2.pdf
414,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,probe considerations and limitations.,"[67] with a lightweight dependency parser (both given the same inputs), and demonstrate that the parser is generally able to extract more syntactic information from bert embedding.",Neutral,https://export.arxiv.org/pdf/2103.11072v2.pdf
415,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,probe considerations and limitations.,"in contrast, the probe performs better with a different metric, showing that the choice of metric is important for probes: when testing for evidence of linguistic information, one should not only consider the nature of the probe, but also the metric used to evaluate it.",Neutral,https://export.arxiv.org/pdf/2103.11072v2.pdf
416,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,probe considerations and limitations.,"furthermore, the significance of well-performing probes is not clear: models may encode linguistic information not actually used by the end-task [138], showing that the presence of linguistic information does not imply it is being used for prediction.",Finding,https://export.arxiv.org/pdf/2103.11072v2.pdf
417,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,probe considerations and limitations.,"more causal approaches such as amnesiac probing [50], which directly intervene in the underlying model's representations, may better distinguish between these cases.",Finding,https://export.arxiv.org/pdf/2103.11072v2.pdf
418,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,discussion and conclusion,this paper focused on the local interpretable methods commonly used for natural language processing models.,ReSolved,https://export.arxiv.org/pdf/2103.11072v2.pdf
419,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,discussion and conclusion,"in this survey, we have divided these methods into three different categories based on their underlying characteristics: 1) explaining the model's outputs from the input features, where these features could be identified through rationale extraction, perturbing inputs, traditional attribution methods, and attention weight extraction; 2) generating the natural language explanations corresponding to each inputs; 3) using diagnostic classifiers to analyse the hidden information stored within a model.",ReSolved,https://export.arxiv.org/pdf/2103.11072v2.pdf
420,232307813,Local Interpretations for Explainable Natural Language Processing: A Survey,discussion and conclusion,"for each method type, we have also outlined the common datasets used for different nlp tasks and different evaluation methods for examining the validity and efficacy of the explanations provided.",ReSolved,https://export.arxiv.org/pdf/2103.11072v2.pdf
421,250390687,MultiSpanQA: A Dataset for Multi-Span Question Answering,conclusion,"we present multispanqa, a reading comprehension dataset where answers consist of multiple discrete spans.",ReSolved,https://www.aclanthology.org/2022.naacl-main.90.pdf
422,250390687,MultiSpanQA: A Dataset for Multi-Span Question Answering,conclusion,"as part of this, we proposed a method for classifying the semantic structure of answers, based on the semantic relation between answer spans.",ReSolved,https://www.aclanthology.org/2022.naacl-main.90.pdf
423,250390687,MultiSpanQA: A Dataset for Multi-Span Question Answering,conclusion,"we also provide an expanded version of the dataset which includes unanswerable questions and single-answer questions, to make it both more challenging and more realistic.",ReSolved,https://www.aclanthology.org/2022.naacl-main.90.pdf
424,250390687,MultiSpanQA: A Dataset for Multi-Span Question Answering,conclusion,"we additionally presented a number of models for multi-span qa extraction, and found that the best-performing model was sequence tagging-based, augmented by a span number prediction module and span adjustment module.",ReSolved,https://www.aclanthology.org/2022.naacl-main.90.pdf
425,238856994,Towards Efficient NLP: A Standard Evaluation and A Strong Baseline,conclusion and future work,"in this work, we present elue, which is a public benchmark and platform for efficient models, and elasticbert, which is a strong baseline (backbone) for efficient static (dynamic) models.",ReSolved,https://www.aclanthology.org/2022.naacl-main.240.pdf
426,238856994,Towards Efficient NLP: A Standard Evaluation and A Strong Baseline,conclusion and future work,"both of the two main contributions are aimed to build the pareto frontier for nlu tasks, such that the position of existing work can be clearly recognized, and future work can be easily and fairly measured.",Finding,https://www.aclanthology.org/2022.naacl-main.240.pdf
427,238856994,Towards Efficient NLP: A Standard Evaluation and A Strong Baseline,conclusion and future work,"our future work is mainly in four aspects: (1) including more baselines in elue, (2) supporting the evaluation for more frameworks such as tensor-flow (abadi et al., 2016)",Finding,https://www.aclanthology.org/2022.naacl-main.240.pdf
428,235313620,Ember: No-Code Context Enrichment via Similarity-Based Keyless Joins,conclusion,"we demonstrate how seemingly unrelated tasks spanning data integration, search, and recommendation can all be viewed as instantiations of context enrichment.",ReSolved,https://arxiv.org/pdf/2106.01501v1.pdf
429,235313620,Ember: No-Code Context Enrichment via Similarity-Based Keyless Joins,conclusion,"we propose keyless joins as a unifying abstraction that can power a system for general context enrichment, which allows us to view context enrichment as a data management problem.",ReSolved,https://arxiv.org/pdf/2106.01501v1.pdf
430,235313620,Ember: No-Code Context Enrichment via Similarity-Based Keyless Joins,conclusion,"consequently, we developed and applied ember, a first-of-its kind system that performs no-code context enrichment via keyless joins.",ReSolved,https://arxiv.org/pdf/2106.01501v1.pdf
431,235313620,Ember: No-Code Context Enrichment via Similarity-Based Keyless Joins,conclusion,"we evaluate how developing a keyless join enrichment layer empowers a single system to generalize to five downstream applications, with no ml code written by the user.",ReSolved,https://arxiv.org/pdf/2106.01501v1.pdf
432,214802134,Graph Sequential Network for Reasoning over Sequences,conclusion,this paper proposes graph sequential network as a novel neural architecture to facilitate reasoning over graphs with sequential data on the nodes.,ReSolved,https://arxiv.org/pdf/2004.02001v1.pdf
433,214802134,Graph Sequential Network for Reasoning over Sequences,conclusion,we develop a new message passing algorithm based on co-attention between two sequences on graph nodes.,ReSolved,https://arxiv.org/pdf/2004.02001v1.pdf
434,214802134,Graph Sequential Network for Reasoning over Sequences,conclusion,"the scheme avoids the information loss inherent in the pooling based early summarization of existing gnn-based models, and improve the reasoning ability on sentence level.",ReSolved,https://arxiv.org/pdf/2004.02001v1.pdf
435,214802134,Graph Sequential Network for Reasoning over Sequences,conclusion,"through experiments on hotpotqa and fever, both of which require the model to perform multi-hop reasoning, we show that our proposed gsn attains better performance than existing gnns on different types of tasks.",ReSolved,https://arxiv.org/pdf/2004.02001v1.pdf
436,214802134,Graph Sequential Network for Reasoning over Sequences,conclusion,for future work we would like to apply gsn to other applications in nlp that require complex reasoning.,Finding,https://arxiv.org/pdf/2004.02001v1.pdf
437,258378176,Combining Parameter-efficient Modules for Task-level Generalisation,conclusions,we argued that a modular design is crucial to ensure that neural networks can learn from a few examples and generalise robustly across tasks by recombining autonomous facets of knowledge.,Neutral,https://www.aclanthology.org/2023.eacl-main.49.pdf
438,258378176,Combining Parameter-efficient Modules for Task-level Generalisation,conclusions,"to this end, we proposed a model where a subset of latent, discrete skills from a fixed inventory is allocated to each task in an end-to-end fashion.",ReSolved,https://www.aclanthology.org/2023.eacl-main.49.pdf
439,258378176,Combining Parameter-efficient Modules for Task-level Generalisation,conclusions,"the task-specific instantiation of a neural network is then obtained by combining efficient parameterisations of the active skills, such as sparse or low-rank adapters.",ReSolved,https://www.aclanthology.org/2023.eacl-main.49.pdf
440,258378176,Combining Parameter-efficient Modules for Task-level Generalisation,conclusions,we evaluate the sample efficiency of our model on multitask instruction following through reinforcement learning and its few-shot adaptability on multitask text-to-text generation through supervised learning.,ReSolved,https://www.aclanthology.org/2023.eacl-main.49.pdf
441,258378176,Combining Parameter-efficient Modules for Task-level Generalisation,conclusions,"in both experiments, we surpass competitive baselines such as conditional parameter generation (hyperformer) and mixture of experts (task-moe).",ReSolved,https://www.aclanthology.org/2023.eacl-main.49.pdf
442,258378176,Combining Parameter-efficient Modules for Task-level Generalisation,conclusions,"finally, we show that modularity helps interpret multi-task models by inferring explicit relationships between tasks according to the skills they share.",ReSolved,https://www.aclanthology.org/2023.eacl-main.49.pdf
443,216562779,MAVEN: A Massive General Domain Event Detection Dataset,conclusion and future work,"in this paper, we present a massive general domain event detection dataset (maven), which significantly alleviates the data sparsity and low coverage problems of existing datasets.",ReSolved,https://arxiv.org/pdf/2004.13590v1.pdf
444,216562779,MAVEN: A Massive General Domain Event Detection Dataset,conclusion and future work,"we conduct a thorough evaluation of the state-of-the-art models on our maven and observe an obvious performance drop, which indicates that our maven is challenging and may facilitate further research on ed.",ReSolved,https://arxiv.org/pdf/2004.13590v1.pdf
445,237450610,Flexible Generation of Natural Language Deductions,conclusion,building systems that use natural language as a medium for reasoning will require operations to logically combine and transform natural language statements.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.506.pdf
446,237450610,Flexible Generation of Natural Language Deductions,conclusion,"in this work, we present parapattern, a method for creating such models with minimal manual effort by finetuning pretrained sequence-to-sequence language models on data generated through a three-step process of syntactic retrieval, template expansion, and automatic paraphrasing.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.506.pdf
447,237450610,Flexible Generation of Natural Language Deductions,conclusion,"our experimental results show that parapattern yields operation models capable of generating consistent logical transformations over a diverse range of natural language inputs, matching the performance of models trained with in-domain human supervision.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.506.pdf
448,202558815,A Discrete Hard EM Approach for Weakly Supervised Question Answering,conclusion,"in this paper, we demonstrated that, for many qa tasks which only provide the answer text as supervision, it is possible to precompute a discrete set of possible solutions that contains one correct option.",ReSolved,https://www.aclweb.org/anthology/D19-1284.pdf
449,202558815,A Discrete Hard EM Approach for Weakly Supervised Question Answering,conclusion,"then, we introduced a discrete latent variable learning algorithm which iterates a procedure of predicting the most likely solution in the precomputed set and further increasing the likelihood of that solution.",ReSolved,https://www.aclweb.org/anthology/D19-1284.pdf
450,202558815,A Discrete Hard EM Approach for Weakly Supervised Question Answering,conclusion,"we showed that this approach significantly outperforms previous approaches on six qa tasks including reading comprehension, opendomain qa, discrete reasoning task and semantic parsing, achieving absolute gains of 2-10% and setting the new state-of-the-art on five wellstudied datasets.",ReSolved,https://www.aclweb.org/anthology/D19-1284.pdf
451,258418354,"Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks",conclusion,"in this paper, we propose a novel method to improve the accuracy, credibility and traceability of large language models (llm) for complex knowledge-intensive tasks called searchain, which is a framework for deep interaction between llm and information retrieval (ir).",ReSolved,https://export.arxiv.org/pdf/2304.14732v1.pdf
452,258418354,"Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks",conclusion,"in searchain, when llm faces complex questions, it constructs a chain called chain-of-query (coq), each node of the coq is an ir-oriented query and llm-generated answer.",Neutral,https://export.arxiv.org/pdf/2304.14732v1.pdf
453,258418354,"Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks",conclusion,"ir interacts with each node on the chain, judges whether the answer is correct, and provides llm with its unknown knowledge.",Neutral,https://export.arxiv.org/pdf/2304.14732v1.pdf
454,258418354,"Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks",conclusion,llm generates a new coq according to the feedback of ir.,Neutral,https://export.arxiv.org/pdf/2304.14732v1.pdf
455,258418354,"Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks",conclusion,"ir interacts with llm for multiple rounds, gradually helping llm generate the correct coq, and finally solve the complex question.",Neutral,https://export.arxiv.org/pdf/2304.14732v1.pdf
456,258418354,"Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks",conclusion,"besides, the contents returned to the user include not only the final answer but also the reasoning process for the question, that is, the coq and the supporting documents retrieved by ir for each node of the coq, which improves the credibility and traceability of the contents generated by llm.",Neutral,https://export.arxiv.org/pdf/2304.14732v1.pdf
457,258418354,"Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks",conclusion,"experiments on multi-hop question answering datasets show that searchain not only has strong knowledge-reasoning ability when faced with complex questions but also can effectively exploit the interaction with ir to supplement and correct its knowledge, so as to improve the accuracy and credibility of the generated contents.",ReSolved,https://export.arxiv.org/pdf/2304.14732v1.pdf
458,258418354,"Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks",conclusion,"besides, searchain effectively decouples the knowledge of llm and ir, which avoids the misleading of llm and can also accurately explain whether the knowledge involved in solving knowledge-intensive tasks comes from parameters or external ir.",ReSolved,https://export.arxiv.org/pdf/2304.14732v1.pdf
459,236477844,PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval,conclusion and future work,this paper presented a novel dense passage retrieval approach that leverages both query-centric and passage-centric similarity relations for capturing more comprehensive semantic relations.,ReSolved,https://export.arxiv.org/pdf/2108.06027v2.pdf
460,236477844,PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval,conclusion and future work,"to implement our approach, we made three important technical contributions in the loss formulation, training data augmentation and effective training procedure.",ReSolved,https://export.arxiv.org/pdf/2108.06027v2.pdf
461,236477844,PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval,conclusion and future work,extensive results demonstrated the effectiveness of our approach.,ReSolved,https://export.arxiv.org/pdf/2108.06027v2.pdf
462,236477844,PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval,conclusion and future work,"to our knowledge, it is the first time that passage-centric similarity relation has been considered for dense passage retrieval.",ReSolved,https://export.arxiv.org/pdf/2108.06027v2.pdf
463,236477844,PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval,conclusion and future work,we believe such an idea itself is worth exploring in designing new ranking mechanism.,Neutral,https://export.arxiv.org/pdf/2108.06027v2.pdf
464,236477844,PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval,conclusion and future work,"in future work, we will design more principle ranking functions and apply current retrieval approach to downstream tasks such as question answering and passage re-ranking.",Finding,https://export.arxiv.org/pdf/2108.06027v2.pdf
465,225067214,READONCE Transformers: Reusable Representations of Text for Transformers,conclusion,"this work introduced readonce transformers, a novel approach for using large scale transformerbased language models to both build and consume reusable document representations.",ReSolved,https://www.aclanthology.org/2021.acl-long.554.pdf
466,225067214,READONCE Transformers: Reusable Representations of Text for Transformers,conclusion,"akin to humans' ability to read a document and extract useful information without knowing the enduse, readonce representations are compact, information-capturing document representations that can be pre-computed once, in a task-and example-independent fashion.",Neutral,https://www.aclanthology.org/2021.acl-long.554.pdf
467,230799347,Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies,conclusion,"we present strategyqa, the first dataset of implicit multi-step questions requiring a wide-range of reasoning skills.",ReSolved,https://arxiv.org/pdf/2101.02235v1.pdf
468,230799347,Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies,conclusion,"to build strategyqa, we introduced a novel annotation pipeline for eliciting creative questions that use simple language, but cover a challenging range of diverse strategies.",ReSolved,https://arxiv.org/pdf/2101.02235v1.pdf
469,230799347,Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies,conclusion,"questions in strategyqa are annotated with decomposition into reasoning steps and evidence paragraphs, to guide the ongoing research towards addressing implicit multi-hop reasoning.",ReSolved,https://arxiv.org/pdf/2101.02235v1.pdf
470,252993059,RankT5: Fine-Tuning T5 for Text Ranking with Ranking Losses,conclusion,"in this paper, we study to utilize pretrained t5 models on text ranking.",ReSolved,https://export.arxiv.org/pdf/2210.10634v1.pdf
471,252993059,RankT5: Fine-Tuning T5 for Text Ranking with Ranking Losses,conclusion,"unlike monot5, which simply converts a text ranking problem into a t5-compatible token generation task, our paper presents two model variants that output numerical numbers based on the t5 architecture: an encoderdecoder model and an encoder-only model.",ReSolved,https://export.arxiv.org/pdf/2210.10634v1.pdf
472,252993059,RankT5: Fine-Tuning T5 for Text Ranking with Ranking Losses,conclusion,we thereby propose fine-tuning t5 with ranking losses to maximize ranking metrics.,ReSolved,https://export.arxiv.org/pdf/2210.10634v1.pdf
473,252993059,RankT5: Fine-Tuning T5 for Text Ranking with Ranking Losses,conclusion,we demonstrate significant improvement when ranking losses are used to fine-tune the t5 model on the ms marco and the nq data sets.,ReSolved,https://export.arxiv.org/pdf/2210.10634v1.pdf
474,252993059,RankT5: Fine-Tuning T5 for Text Ranking with Ranking Losses,conclusion,we further illustrate that such improvement can be maintained in the zero-shot setting on out-of-domain data sets.,ReSolved,https://export.arxiv.org/pdf/2210.10634v1.pdf
475,258822799,HELMA: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models,conclusion,"we introduce helma, a large-scale collection of generated and human-annotated hallucinated samples for evaluating the performance of llms in recognizing and improving hallucinations.",ReSolved,https://export.arxiv.org/pdf/2305.11747v1.pdf
476,258822799,HELMA: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models,conclusion,"to automatically generate large-scale samples, we propose a chatgpt-based two-step approach, i.e., samplingthen-filtering.",ReSolved,https://export.arxiv.org/pdf/2305.11747v1.pdf
477,258822799,HELMA: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models,conclusion,we first introduce two different sampling methods to generate diverse samples using instructions and then filter and select the difficult one.,ReSolved,https://export.arxiv.org/pdf/2305.11747v1.pdf
478,258822799,HELMA: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models,conclusion,"besides, we invite qualified human labelers to annotate the hallucinations of chatgpt responses given user queries.",ReSolved,https://export.arxiv.org/pdf/2305.11747v1.pdf
479,257427664,Challenges in Explanation Quality Evaluation,conclusion,this paper aims at increasing the awareness of the shortcomings and open challenges that today's explanation quality evaluation practices face.,ReSolved,https://export.arxiv.org/pdf/2210.07126v2.pdf
480,257427664,Challenges in Explanation Quality Evaluation,conclusion,"we discuss general characteristics of explanation quality, describe current practices and point out to which extent they violate the discussed characteristics.",ReSolved,https://export.arxiv.org/pdf/2210.07126v2.pdf
481,257427664,Challenges in Explanation Quality Evaluation,conclusion,we support our arguments with empirical evidence of a crowdsourced case study that we conducted for the example of explainable question answering systems from the hotpotqa leaderboard.,ReSolved,https://export.arxiv.org/pdf/2210.07126v2.pdf
482,254246737,What is Not in the Context? Evaluation of Few-shot Learners with Informative Demonstrations,conclusion,"this work introduces a task of conceptual few-shot learning, that reflects on language models' ability to learn in-context and apply a specific, possibly novel reasoning concept.",ReSolved,https://export.arxiv.org/pdf/2212.01692v1.pdf
483,254246737,What is Not in the Context? Evaluation of Few-shot Learners with Informative Demonstrations,conclusion,"we find that current incontext few-shot learners are largely insensitive to the concepts presented in demonstrations, suggesting that their ability to learn in context might be conditioned by other factors, such as their memo-rization capacity, rather than their level of task comprehension.",Finding,https://export.arxiv.org/pdf/2212.01692v1.pdf
484,254246737,What is Not in the Context? Evaluation of Few-shot Learners with Informative Demonstrations,conclusion,conceptual few-shot learning poses a challenge of more controllable and scalable fewshot learning to future few-shot learners.,Finding,https://export.arxiv.org/pdf/2212.01692v1.pdf
485,215238846,Multi-Step Inference for Reasoning Over Paragraphs,conclusion,we propose a multi-step reading comprehension model that performs chained inference over natural language text.,ReSolved,https://arxiv.org/pdf/2004.02995v2.pdf
486,215238846,Multi-Step Inference for Reasoning Over Paragraphs,conclusion,"we have demonstrated that our model substantially outperforms prior work on ropes, a challenging new reading comprehension dataset.",ReSolved,https://arxiv.org/pdf/2004.02995v2.pdf
487,215238846,Multi-Step Inference for Reasoning Over Paragraphs,conclusion,we have additionally presented some analysis of ropes that should inform future work on this dataset.,Finding,https://arxiv.org/pdf/2004.02995v2.pdf
488,215238846,Multi-Step Inference for Reasoning Over Paragraphs,conclusion,"while our model is not a neural module network, as our model uses a single fixed layout instead of different layouts per question, we believe there are enough similarities that future work could explore combining our modules with those used in other neural module networks over text, leading to a single model that could perform the necessary reasoning for multiple different datasets.",Finding,https://arxiv.org/pdf/2004.02995v2.pdf
489,245219136,Evidentiality-guided Generation for Knowledge-Intensive NLP Tasks,conclusion,"augmenting pre-trained generation models with retrievers has shown to be effective in many knowledge-intensive tasks; however, they often rely on spurious cues or generate hallucinations during inference.",Neutral,https://www.aclanthology.org/2022.naacl-main.162.pdf
490,245219136,Evidentiality-guided Generation for Knowledge-Intensive NLP Tasks,conclusion,we introduce a multi-task learning objective the combines answer generation and evidentiality prediction.,ReSolved,https://www.aclanthology.org/2022.naacl-main.162.pdf
491,245219136,Evidentiality-guided Generation for Knowledge-Intensive NLP Tasks,conclusion,we propose task-agnostic data mining techniques to obtain silver evidentiality labels to enable this auxiliary training.,ReSolved,https://www.aclanthology.org/2022.naacl-main.162.pdf
492,245219136,Evidentiality-guided Generation for Knowledge-Intensive NLP Tasks,conclusion,"our experiments across five datasets show large performance improvements over baselines and our evidentialityguided generator advances the state-of-the-art performance on faviq-ambig, fever and wow.",ReSolved,https://www.aclanthology.org/2022.naacl-main.162.pdf
493,245219136,Evidentiality-guided Generation for Knowledge-Intensive NLP Tasks,conclusion,our analysis shows that multi-task learning and silver evidentiality mining both contribute to the performance improvements by helping the model learn to focus on and generate answers from more relevant passages.,ReSolved,https://www.aclanthology.org/2022.naacl-main.162.pdf
494,221819379,Published as a conference paper at ICLR 2021 CONDITIONALLY ADAPTIVE MULTI-TASK LEARNING: IMPROVING TRANSFER LEARNING IN NLP USING FEWER PARAMETERS & LESS DATA,conclusion,we believe that our experiments here have helped demonstrate the potential of task conditioned adaptive learning within a single model that performs multiple tasks.,ReSolved,https://arxiv.org/pdf/2009.09139v3.pdf
495,221819379,Published as a conference paper at ICLR 2021 CONDITIONALLY ADAPTIVE MULTI-TASK LEARNING: IMPROVING TRANSFER LEARNING IN NLP USING FEWER PARAMETERS & LESS DATA,conclusion,"in a large-scale 24-task nlp experiment, ca-mtl outperforms fully tuned single task models by 2.3% for bert large and by 1.2% for roberta large using 1.12 times the number of parameters, while single task fine-tuning approach requires 24 separately tuned single task models or 24 times the number of parameters.",Neutral,https://arxiv.org/pdf/2009.09139v3.pdf
496,221819379,Published as a conference paper at ICLR 2021 CONDITIONALLY ADAPTIVE MULTI-TASK LEARNING: IMPROVING TRANSFER LEARNING IN NLP USING FEWER PARAMETERS & LESS DATA,conclusion,"when a bert vanilla mtl model sees its performance drop as the number of tasks increases, ca-mtl scores continue to climb.",Neutral,https://arxiv.org/pdf/2009.09139v3.pdf
497,221819379,Published as a conference paper at ICLR 2021 CONDITIONALLY ADAPTIVE MULTI-TASK LEARNING: IMPROVING TRANSFER LEARNING IN NLP USING FEWER PARAMETERS & LESS DATA,conclusion,performance gains are not driven by a single task as it is often the case in mtl.,Neutral,https://arxiv.org/pdf/2009.09139v3.pdf
498,221819379,Published as a conference paper at ICLR 2021 CONDITIONALLY ADAPTIVE MULTI-TASK LEARNING: IMPROVING TRANSFER LEARNING IN NLP USING FEWER PARAMETERS & LESS DATA,conclusion,"each ca-mtl module that adapts a transformer model is able to reduce performance variances between tasks, increasing average scores and aligning task covariances.",ReSolved,https://arxiv.org/pdf/2009.09139v3.pdf
499,221819379,Published as a conference paper at ICLR 2021 CONDITIONALLY ADAPTIVE MULTI-TASK LEARNING: IMPROVING TRANSFER LEARNING IN NLP USING FEWER PARAMETERS & LESS DATA,conclusion,this evidence shows that ca-mtl is able to mitigate task interference and promote more efficient parameter sharing.,ReSolved,https://arxiv.org/pdf/2009.09139v3.pdf
500,221819379,Published as a conference paper at ICLR 2021 CONDITIONALLY ADAPTIVE MULTI-TASK LEARNING: IMPROVING TRANSFER LEARNING IN NLP USING FEWER PARAMETERS & LESS DATA,conclusion,we showed that mt-uncertainty is able to avoid degrading performances of low resource tasks.,ReSolved,https://arxiv.org/pdf/2009.09139v3.pdf
501,221819379,Published as a conference paper at ICLR 2021 CONDITIONALLY ADAPTIVE MULTI-TASK LEARNING: IMPROVING TRANSFER LEARNING IN NLP USING FEWER PARAMETERS & LESS DATA,conclusion,"tasks are sampled whenever the model sees entropy increase, helping avoid catastrophic forgetting.",Neutral,https://arxiv.org/pdf/2009.09139v3.pdf
502,221819379,Published as a conference paper at ICLR 2021 CONDITIONALLY ADAPTIVE MULTI-TASK LEARNING: IMPROVING TRANSFER LEARNING IN NLP USING FEWER PARAMETERS & LESS DATA,conclusion,"overall, ca-mtl offers a promising avenue to dynamically adapt and modularize knowledge embedded in large monolithic pretrained models. extending such ideas will be an objective for future work.",Finding,https://arxiv.org/pdf/2009.09139v3.pdf
503,220302524,Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval,conclusion,ance fundamentally eliminates the discrepancy between the representation learning of texts and their usages in dense retrieval.,ReSolved,https://arxiv.org/pdf/2007.00808v1.pdf
504,220302524,Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval,conclusion,"our ance trained dense retrieval model, the vanilla bert-siamese, convincingly outperforms all dense retrieval and sparse retrieval baselines in our large scale document retrieval and passage retrieval experiments.",ReSolved,https://arxiv.org/pdf/2007.00808v1.pdf
505,220302524,Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval,conclusion,it nearly matches the ranking accuracy of the state-of-theart cascade sparse retrieval and bert reranking pipeline.,ReSolved,https://arxiv.org/pdf/2007.00808v1.pdf
506,220302524,Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval,conclusion,"more importantly, all these advantages are achieved with a standard transformer encoder at a 1% online inference latency, using a simple dot-product in the ance-learned representation space.",ReSolved,https://arxiv.org/pdf/2007.00808v1.pdf
507,252368291,Learning to Answer Semantic Queries over Code,conclusions and future work,we presented the codequeries dataset which tests the ability of neural models for code understanding on the proposed problem of answering semantic queries over code.,ReSolved,https://export.arxiv.org/pdf/2209.08372v1.pdf
508,252368291,Learning to Answer Semantic Queries over Code,conclusions and future work,it requires the models to perform single-or multi-hop reasoning.,Neutral,https://export.arxiv.org/pdf/2209.08372v1.pdf
509,252368291,Learning to Answer Semantic Queries over Code,conclusions and future work,"despite a diverse set of 52 queries requiring varied program analyses, the proposed models perform reasonably well if relevant code is given.",Finding,https://export.arxiv.org/pdf/2209.08372v1.pdf
510,252368291,Learning to Answer Semantic Queries over Code,conclusions and future work,"at the same time, our evaluation under pragmatic considerations indicates that scalability to entire files and learning from a limited number of examples have much room for improvement.",Finding,https://export.arxiv.org/pdf/2209.08372v1.pdf
511,252368291,Learning to Answer Semantic Queries over Code,conclusions and future work,"we plan to explore models with the ability to handle larger contexts (e.g., [dai et al., 2019]), better training of relevance classifier and span-prediction inspired pre-training objectives (e.g., [joshi et al., 2020, ram et al., 2021) in the future.",Finding,https://export.arxiv.org/pdf/2209.08372v1.pdf
512,252368291,Learning to Answer Semantic Queries over Code,conclusions and future work,we could also add many more semantic queries and programming languages to our dataset.,Finding,https://export.arxiv.org/pdf/2209.08372v1.pdf
513,258053774,Cancer-Specific Survival after Limb Salvage versus Amputation in Children and Adolescents with Osteosarcoma: A Population-Based Analysis with Propensity Score Matching,conclusion,"to summarize, we established and validated a novel nomogram for os patients of cya, which could serve as concise and practical tools for clinicians to anticipate the 1-, 3-, and 5-years css.",ReSolved,
514,258053774,Cancer-Specific Survival after Limb Salvage versus Amputation in Children and Adolescents with Osteosarcoma: A Population-Based Analysis with Propensity Score Matching,conclusion,lss for patients with os exhibited signifcant beneft on css compared with amputation.,ReSolved,
515,258053774,Cancer-Specific Survival after Limb Salvage versus Amputation in Children and Adolescents with Osteosarcoma: A Population-Based Analysis with Propensity Score Matching,conclusion,"while new chemotherapy regimens will be required to increase survivorship in the setting of os, patients with tumor features suitable to lss had a much higher survival rate than those suitable for amputation.",Neutral,
516,236771976,MuSiQue: Multihop Questions via Single-hop Question Composition,conclusion,constructing multihop datasets is a tricky process. it can introduce shortcuts and artifacts that models can exploit to circumvent the need for multihop reasoning.,Neutral,https://www.aclanthology.org/2022.tacl-1.31.pdf
517,236771976,MuSiQue: Multihop Questions via Single-hop Question Composition,conclusion,a bottom-up process of constructing multihop from single-hop questions allows systematic exploration of a large space of multihop candidates and greater control over which questions we compose.,ReSolved,https://www.aclanthology.org/2022.tacl-1.31.pdf
518,236771976,MuSiQue: Multihop Questions via Single-hop Question Composition,conclusion,"we showed how to use such a carefully controlled process to create a challenging dataset that, by design, requires connected reasoning by reducing potential reasoning shortcuts, minimizing train-test leakage, and including harder distractor contexts.",ReSolved,https://www.aclanthology.org/2022.tacl-1.31.pdf
519,236771976,MuSiQue: Multihop Questions via Single-hop Question Composition,conclusion,empirical results show that -ans has a substantially higher human-model gap and is significantly less cheatable via disconnected reasoning than previous datasets.,ReSolved,https://www.aclanthology.org/2022.tacl-1.31.pdf
520,236771976,MuSiQue: Multihop Questions via Single-hop Question Composition,conclusion,"the dataset also comes with unanswerable questions, and question decompositions which we hope spurs further work in developing models that get right answers for the right reasons.",Finding,https://www.aclanthology.org/2022.tacl-1.31.pdf
521,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,conclusion,"in this paper, we propose reasoning circuits, a new framework suited to real-world scenarios where the nlp task at hand requires multiple steps of structured reasoning, with only a limited number of available labelled examples, and a small annotation budget, also only a modest deep learning computational infrastructure/budget is accessible.",ReSolved,https://export.arxiv.org/pdf/2211.08466v1.pdf
522,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,conclusion,"in this work, we apply this framework to the task of fewshot multi-hop question generation which fits all these criteria.",ReSolved,https://export.arxiv.org/pdf/2211.08466v1.pdf
523,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,conclusion,we identify structured multi-step rationales that break down this problem into many discrete reasoning steps.,ReSolved,https://export.arxiv.org/pdf/2211.08466v1.pdf
524,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,conclusion,"each step in these rationales is treated as a single ""task"" within a mixture of similar ""tasks"".",Neutral,https://export.arxiv.org/pdf/2211.08466v1.pdf
525,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,conclusion,"the individual tasks can be categorized into control tasks, which control the flow of information between tasks, and generative tasks, that generate free-form text for successive tasks in the reasoning circuit.",Neutral,https://export.arxiv.org/pdf/2211.08466v1.pdf
526,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,conclusion,"the framework is relatively easy to implement, since only a single generative model is fine-tuned with a mixture of all reasoning steps; at inference time, the same model can generate all reasoning steps sequentially.",Neutral,https://export.arxiv.org/pdf/2211.08466v1.pdf
527,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,conclusion,we show that fine-tuning with only around 64 to 128 labelled rationale examples with our approach is enough to improve automatic evaluation metrics compared to a baseline trained without rationales on the hot-potqa dataset.,ReSolved,https://export.arxiv.org/pdf/2211.08466v1.pdf
528,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,conclusion,"more importantly, with human evaluation, we find that this framework can strongly improve the central objective of multi-hop qg, to generate challenging questions which cannot be answered from reading only a single passage.",ReSolved,https://export.arxiv.org/pdf/2211.08466v1.pdf
529,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,limitations,the proposed reasoning circuits framework intends to replace the need for thousands of annotated examples with a strong inductive bias of structured rationales.,Neutral,https://export.arxiv.org/pdf/2211.08466v1.pdf
530,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,limitations,"there is two issues with this approach at a conceptual level: 1. it may not always be possible to break down a multi-step reasoning problem cleanly into discrete reasoning steps, and another related issue it increasing complexity of the circuit with the complexity of the task.",Neutral,https://export.arxiv.org/pdf/2211.08466v1.pdf
531,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,limitations,"2. for the design of these reasoning circuits a researcher must develop a thorough understanding of this reasoning task, so that the final circuit design broadly covers all possible types of reasoning problems expected to be solved.",Neutral,https://export.arxiv.org/pdf/2211.08466v1.pdf
532,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,limitations,"an under-or illdesigned reasoning circuit may cause the system to either not support a certain portion of problems or produce non-sensical outputs.essentially, there is trade off between a tighter control over reasoning by investing in a deep understanding of the problem leading to a comprehensive reasoning circuit design and lower annotations budget, versus, less control over logic and depending on a large number of annotations which allow the model to discover this logic on its own at much higher cost of large scale annotations budget.",Neutral,https://export.arxiv.org/pdf/2211.08466v1.pdf
533,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,limitations,at the implementation and operations level one of the the key limitations our proposed system is the number of inference steps to solve the problem.,Finding,https://export.arxiv.org/pdf/2211.08466v1.pdf
534,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,limitations,the number of times model inference may be needed to solve a single example is equal the length of the longest task sequence chain in the reasoning circuit.,Finding,https://export.arxiv.org/pdf/2211.08466v1.pdf
535,253553165,Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales,limitations,one possible solution for this could be by training the model to solve the entire problem by generating all the steps of reasoning and the target string in a single inference step and could massively reduce inference time and costs.,Finding,https://export.arxiv.org/pdf/2211.08466v1.pdf
536,241583187,FaBULOUS: Fact-checking Based on Understanding of Language Over Unstructured and Structured information,conclusion,"overall, this multi-modal task creates a plethora of new challenges to overcome and opens exciting avenues of research for the future of automated fact verification.",ReSolved,https://www.aclanthology.org/2021.fever-1.4.pdf
537,243986045,Recent Advances in Automated Question Answering In Biomedical Domain,conclusion,"in this review, we focused on the recent advances in biomedical question answering.",Neutral,https://arxiv.org/pdf/2111.05937v1.pdf
538,243986045,Recent Advances in Automated Question Answering In Biomedical Domain,conclusion,"we provided a review of general domain question answering using knowledge bases, texts or both, before moving on to biomedical question answering systems.",ReSolved,https://arxiv.org/pdf/2111.05937v1.pdf
539,243986045,Recent Advances in Automated Question Answering In Biomedical Domain,conclusion,we explored current state of the art biomedical qa systems and discussed their limitations.,ReSolved,https://arxiv.org/pdf/2111.05937v1.pdf
540,243986045,Recent Advances in Automated Question Answering In Biomedical Domain,conclusion,we finally provided an overall analysis of limitations of bqa systems along with ways to overcome them.,ReSolved,https://arxiv.org/pdf/2111.05937v1.pdf
541,243986045,Recent Advances in Automated Question Answering In Biomedical Domain,conclusion,we finally explore the potential areas of focus for further research.,ReSolved,https://arxiv.org/pdf/2111.05937v1.pdf
542,252818979,Hierarchical Representation-based Dynamic Reasoning Network for Biomedical Question Answering,conclusion,"this paper proposes hdrn, a novel model for representation learning and reasoning for biomedical question answering.",ReSolved,https://www.aclanthology.org/2022.coling-1.127.pdf
543,252818979,Hierarchical Representation-based Dynamic Reasoning Network for Biomedical Question Answering,conclusion,"first, we construct hierarchical representations to obtain a deep understanding of the biomedical evidences. then, we perform multi-step dynamic reasoning to solve complex biomedical questions.",ReSolved,https://www.aclanthology.org/2022.coling-1.127.pdf
544,252818979,Hierarchical Representation-based Dynamic Reasoning Network for Biomedical Question Answering,conclusion,we evaluate our model on three bioqa datasets and achieve new state-of-theart performances.,ReSolved,https://www.aclanthology.org/2022.coling-1.127.pdf
545,247476426,Relation Leakage in Elicited Natural Language Inference Datasets,conclusion,"we have introduced useful tools and techniques for analyzing elicited sentence relation leakage bias in nli datasets, and applied them to a large, representative set of popular current datasets.",ReSolved,https://arxiv.org/pdf/2112.09237v2.pdf
546,235678938,Controllable Open-ended Question Generation with A New Question Type Ontology,conclusion,we present a new question type ontology which better captures the nuances of questions to support the study of open-ended question generation.,ReSolved,https://www.aclanthology.org/2021.acl-long.502.pdf
547,235678938,Controllable Open-ended Question Generation with A New Question Type Ontology,conclusion,"we further annotate a new dataset with 4,959 questions based on the proposed ontology.",ReSolved,https://www.aclanthology.org/2021.acl-long.502.pdf
548,235678938,Controllable Open-ended Question Generation with A New Question Type Ontology,conclusion,"we describe a joint question focus detection and question generation framework with a novel semantic graphaugmented representation, which is directly built on large pre-trained models.",ReSolved,https://www.aclanthology.org/2021.acl-long.502.pdf
549,235678938,Controllable Open-ended Question Generation with A New Question Type Ontology,conclusion,"based on this framework, we also enhance the controllability and diversity of generated questions by employing template exemplars or automatically generated templates.",ReSolved,https://www.aclanthology.org/2021.acl-long.502.pdf
550,235678938,Controllable Open-ended Question Generation with A New Question Type Ontology,conclusion,"experiments on two large datasets show that questions generated by our models have better quality and higher diversity than non-trivial comparisons, with similar results rated by human judges.",ReSolved,https://www.aclanthology.org/2021.acl-long.502.pdf
551,199668753,Towards Knowledge-Based Recommender Dialog System,conclusion,"in this paper, we propose a novel end-to-end framework, kbrd, which bridges the gap between the recommender system and the dialog system via knowledge propagation.",ReSolved,https://www.aclweb.org/anthology/D19-1189.pdf
552,199668753,Towards Knowledge-Based Recommender Dialog System,conclusion,"through a series of experiments, we show that kbrd can reach better performances in both recommendation and dialog generation in comparison with the baselines. we also discuss how the two systems benefit each other.",ReSolved,https://www.aclweb.org/anthology/D19-1189.pdf
553,199668753,Towards Knowledge-Based Recommender Dialog System,conclusion,"dialog information is effective for the recommender system especially in the setting of cold start, and the introduction of knowledge can strengthen the recommendation performance significantly.",Neutral,https://www.aclweb.org/anthology/D19-1189.pdf
554,199668753,Towards Knowledge-Based Recommender Dialog System,conclusion,information from the recommender system that contains the user preference and the relevant knowledge can enhance the consistency and diversity of the generated dialogs.,Neutral,https://www.aclweb.org/anthology/D19-1189.pdf
555,253510370,World Knowledge in Multiple Choice Reading Comprehension,limitations,we propose an approach that can automatically flag questions that can be answered without contextual information.,ReSolved,https://export.arxiv.org/pdf/2211.07040v2.pdf
556,253510370,World Knowledge in Multiple Choice Reading Comprehension,limitations,"however, the remaining questions are not necessarily high-quality questions, since many other aspects make up question quality.",Finding,https://export.arxiv.org/pdf/2211.07040v2.pdf
557,253510370,World Knowledge in Multiple Choice Reading Comprehension,limitations,"second, the experiments are conducted using only the electra model, though it is expected similar trends will be picked up by alternative transformer-based language models.",Finding,https://export.arxiv.org/pdf/2211.07040v2.pdf
558,253510370,World Knowledge in Multiple Choice Reading Comprehension,limitations,"further, exams might be aimed at a level where a lack of specific knowledge may be assumed.",Finding,https://export.arxiv.org/pdf/2211.07040v2.pdf
559,253510370,World Knowledge in Multiple Choice Reading Comprehension,limitations,"our work does not consider variable candidate knowledge levels, and our evaluation was only done by highly educated (we'd like to think) graduate students.",Finding,https://export.arxiv.org/pdf/2211.07040v2.pdf
560,253510370,World Knowledge in Multiple Choice Reading Comprehension,limitations,"finally, we acknowledge that our human evaluation was limited in size and questions, however it is clearly demonstrated that for low 'shortcut entropy' questions, comprehension is not necessarily required.",Finding,https://export.arxiv.org/pdf/2211.07040v2.pdf
561,243756815,Extracting a Knowledge Base of COVID-19 Events from Social Media,conclusion,"in this paper, we presented a corpus of 10,000 tweets annotated with 5 types of events and 28 slots.",ReSolved,https://export.arxiv.org/pdf/2006.02567v4.pdf
562,243756815,Extracting a Knowledge Base of COVID-19 Events from Social Media,conclusion,we showed that our corpus supports automatic extraction of covid-19 events using supervised learning.,ReSolved,https://export.arxiv.org/pdf/2006.02567v4.pdf
563,243756815,Extracting a Knowledge Base of COVID-19 Events from Social Media,conclusion,"by aggregating extractions over millions of tweets, our approach can accurately answer a range of structured queries about events that are publicly reported in real-time on twitter.",ReSolved,https://export.arxiv.org/pdf/2006.02567v4.pdf
564,243756815,Extracting a Knowledge Base of COVID-19 Events from Social Media,conclusion,"our knowledge base could be a useful tool for epidemiologists, journalists and policymakers to more efficiently track the spread of this new disease.",ReSolved,https://export.arxiv.org/pdf/2006.02567v4.pdf
565,243756815,Extracting a Knowledge Base of COVID-19 Events from Social Media,conclusion,this work also presents a case-study on how an information extraction system can be rapidly developed for a new domain in response to an emerging crisis.,ReSolved,https://export.arxiv.org/pdf/2006.02567v4.pdf
566,243756815,Extracting a Knowledge Base of COVID-19 Events from Social Media,conclusion,"for example, our methodology could be applied to develop knowledge bases for natural disasters (spiliopoulou et al., 2020) or future disease outbreaks.",Finding,https://export.arxiv.org/pdf/2006.02567v4.pdf
567,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"we have shown evidence that our method, qlora, can replicate 16-bit full finetuning performance with a 4-bit base model and low-rank adapters (lora).",ReSolved,https://export.arxiv.org/pdf/2305.14314v1.pdf
568,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"despite this evidence, we did not establish that qlora can match full 16-bit finetuning performance at 33b and 65b scales.",Finding,https://export.arxiv.org/pdf/2305.14314v1.pdf
569,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"due to the immense resource costs, we leave this study to future work.another limitation is the evaluation of instruction finetuning models.",Finding,https://export.arxiv.org/pdf/2305.14314v1.pdf
570,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"while we provide evaluations on mmlu, the vicuna benchmark, and the oa benchmark, we did not evaluate on other benchmarks such as bigbench, raft, and helm, and it is not ensured that our evaluations generalize to these benchmarks.",Finding,https://export.arxiv.org/pdf/2305.14314v1.pdf
571,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"on the other hand, we perform a very broad study on mmlu and develop new methods for evaluating chatbots.from the evidence presented, it appears that the performance of these benchmarks likely depends how similar the finetuning data is to the benchmark dataset.",Finding,https://export.arxiv.org/pdf/2305.14314v1.pdf
572,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"for example, flan v2 is similar to mmlu, but dissimilar to chatbot benchmarks and vice versa for the chip2 dataset and both models score accordingly on the mmlu and vicuna benchmarks.",Neutral,https://export.arxiv.org/pdf/2305.14314v1.pdf
573,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"this highlights that not only better benchmarks and evaluation is needed, but that one needs to be careful about what one is evaluating in the first place.",Finding,https://export.arxiv.org/pdf/2305.14314v1.pdf
574,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,do we want to create models that do well on classroom highschool and colleague knowledge or do we want to do well on chatbot conversation ability? maybe something else?,Finding,https://export.arxiv.org/pdf/2305.14314v1.pdf
575,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"because it is always easier to evaluate on an existing benchmark compared to creating a new one, certain benchmarks can steer the community towards a certain direction.",Neutral,https://export.arxiv.org/pdf/2305.14314v1.pdf
576,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"we should ensure as a community that the benchmarks measure what we care about.while we provide a detailed evaluation for general chatbot performance, another limitation is that we only do a limited responsible ai evaluation of guanaco.",Finding,https://export.arxiv.org/pdf/2305.14314v1.pdf
577,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,we evaluate the likelihood of guanaco-65b to generate a socially biased sequence of tokens compared to other models in table 8.,Neutral,https://export.arxiv.org/pdf/2305.14314v1.pdf
578,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,we see that the average score in guanaco-65b is much lower than other raw pretrained models.,ReSolved,https://export.arxiv.org/pdf/2305.14314v1.pdf
579,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"as such, it seems that finetuning on the oasst1 dataset reduces the bias of the llama base model.",Neutral,https://export.arxiv.org/pdf/2305.14314v1.pdf
580,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"while these results are encouraging, it is unclear if guanaco does also well when assessed on other types of biases.",Finding,https://export.arxiv.org/pdf/2305.14314v1.pdf
581,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"we leave further evaluation of analyzing biases in guanaco and similar chatbots to future work.an additional limitation is that we did not evaluate different bit-precisions, such as using 3-bit base models, or different adapter methods.",Finding,https://export.arxiv.org/pdf/2305.14314v1.pdf
582,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"besides lora, there is also a wide variety parameter efficient finetuning (peft) methods that have been shown to work well. however, it is unclear if these methods scale to large models.",Finding,https://export.arxiv.org/pdf/2305.14314v1.pdf
583,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,we used lora as many results established its robustness but other adapters might yield better performance.,Finding,https://export.arxiv.org/pdf/2305.14314v1.pdf
584,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,since finetuning after quantization seems to recover most of the information that is lost during quantization this might enable much more aggressive quantization.,Neutral,https://export.arxiv.org/pdf/2305.14314v1.pdf
585,258841328,QLORA: Efficient Finetuning of Quantized LLMs,limitations and discussion,"for example, 3-bit gptq quantization of the basemodel with lora might also yield 16-bit full finetuning performance after finetuning.",Neutral,https://export.arxiv.org/pdf/2305.14314v1.pdf
586,202539540,QUARTZ: An Open-Domain Dataset of Qualitative Relationship Questions,conclusion,"understanding and applying textual qualitative knowledge is an important skill for questionanswering, but has received limited attention, in part due the lack of a broad-coverage dataset to study the task.",Neutral,https://www.aclweb.org/anthology/D19-1608.pdf
587,202539540,QUARTZ: An Open-Domain Dataset of Qualitative Relationship Questions,conclusion,"quartz aims to fill this gap by providing the first open-domain dataset of qualitative relationship questions, along with the requisite qualitative knowledge and a rich set of annotations.",ReSolved,https://www.aclweb.org/anthology/D19-1608.pdf
588,202539540,QUARTZ: An Open-Domain Dataset of Qualitative Relationship Questions,conclusion,"specifically, quartz removes the requirement, present in all previous qualitative reasoning work, that a fixed set of qualitative relationships be formally pre-specified.",ReSolved,https://www.aclweb.org/anthology/D19-1608.pdf
589,202539540,QUARTZ: An Open-Domain Dataset of Qualitative Relationship Questions,conclusion,"instead, quartz tests the ability of a system to find and apply an arbitrary relationship on the fly to answer a question, including when simple reasoning (arguments, polarities) is required.",ReSolved,https://www.aclweb.org/anthology/D19-1608.pdf
590,258841368,What Else Do I Need to Know? The Effect of Background Information on Users' Reliance on AI Systems Question: Which non-Swedish actress also starred in The Light Between Oceans?,discussion and conclusion,"large general-purpose language models, such as gpt family of models [brown et al.2020;openai 2023] , lamda [thoppilan et al. 2022], palm [anil et al. 2023;chowdhery et al. 2022], and others, have propagated into informationseeking workflows of a general audience.",Neutral,https://export.arxiv.org/pdf/2305.14331v1.pdf
591,258841368,What Else Do I Need to Know? The Effect of Background Information on Users' Reliance on AI Systems Question: Which non-Swedish actress also starred in The Light Between Oceans?,discussion and conclusion,"a vast host of existing and ongoing work in nlp examine the deficiencies of these language models, ranging from hallucinated generations  with background with background and highlights.",Neutral,https://export.arxiv.org/pdf/2305.14331v1.pdf
592,258841368,What Else Do I Need to Know? The Effect of Background Information on Users' Reliance on AI Systems Question: Which non-Swedish actress also starred in The Light Between Oceans?,discussion and conclusion,"users' subjective rating of the system for the usefulness of highlights, background, their confidence in the ai system, selfconfidence, and satisfaction with ai.",Neutral,https://export.arxiv.org/pdf/2305.14331v1.pdf
593,258841368,What Else Do I Need to Know? The Effect of Background Information on Users' Reliance on AI Systems Question: Which non-Swedish actress also starred in The Light Between Oceans?,discussion and conclusion,users rate self-confidence marginally higher in the condition with background than the condition without (left).,Neutral,https://export.arxiv.org/pdf/2305.14331v1.pdf
594,258841368,What Else Do I Need to Know? The Effect of Background Information on Users' Reliance on AI Systems Question: Which non-Swedish actress also starred in The Light Between Oceans?,discussion and conclusion,"however, users rate their satisfaction with ai in the condition with background slightly lower than without.",Neutral,https://export.arxiv.org/pdf/2305.14331v1.pdf
595,258841368,What Else Do I Need to Know? The Effect of Background Information on Users' Reliance on AI Systems Question: Which non-Swedish actress also starred in The Light Between Oceans?,discussion and conclusion,"users' satisfaction rating is slightly lower even after introducing highlights with the background (right), with a slightly higher rating of background utility in the condition with highlights than without.",Neutral,https://export.arxiv.org/pdf/2305.14331v1.pdf
596,258841368,What Else Do I Need to Know? The Effect of Background Information on Users' Reliance on AI Systems Question: Which non-Swedish actress also starred in The Light Between Oceans?,discussion and conclusion,"however, there are no other discernible differences in ratings in the background condition with or without highlight.",Finding,https://export.arxiv.org/pdf/2305.14331v1.pdf
597,247518803,Synthetic Question Value Estimation for Domain Adaptation of Question Answering,conclusion,we propose a question value estimator to estimate the usefulness of synthetic questions and select useful ones for improving target-domain qa train- 7,ReSolved,https://www.aclanthology.org/2022.acl-long.95.pdf
598,247518803,Synthetic Question Value Estimation for Domain Adaptation of Question Answering,conclusion,"we treat it as a binary classification problem here: if a question is selected, the prediction is 1; 0 otherwise.",ReSolved,https://www.aclanthology.org/2022.acl-long.95.pdf
599,233219505,Evaluating Pre-Trained Models for User Feedback Analysis in Software Engineering: A Study on Classification of App-Reviews,conclusion,we conducted an extensive exploratory study comparing app issue classification tools and pre-trained transformer-based models in various settings.,ReSolved,https://arxiv.org/pdf/2104.05861v3.pdf
600,233219505,Evaluating Pre-Trained Models for User Feedback Analysis in Software Engineering: A Study on Classification of App-Reviews,conclusion,"we conducted the experiments on six available datasets and a highly imbalanced dataset, which is a combination of the six datasets.",ReSolved,https://arxiv.org/pdf/2104.05861v3.pdf
601,233219505,Evaluating Pre-Trained Models for User Feedback Analysis in Software Engineering: A Study on Classification of App-Reviews,conclusion,domain-specific ptms were trained using different sizes of app review data we collected from google play and these customized ptms were also studied here.,ReSolved,https://arxiv.org/pdf/2104.05861v3.pdf
602,233219505,Evaluating Pre-Trained Models for User Feedback Analysis in Software Engineering: A Study on Classification of App-Reviews,conclusion,"our results confirm that ptms are achieving higher scores in binary and multi-class classification compared to prior approaches, but the over-the-shelf ptms are not always the best models to be used in all scenarios.",ReSolved,https://arxiv.org/pdf/2104.05861v3.pdf
603,233219505,Evaluating Pre-Trained Models for User Feedback Analysis in Software Engineering: A Study on Classification of App-Reviews,conclusion,"instead, cptms have the highest scores and are able to perform better than other models in all settings.",ReSolved,https://arxiv.org/pdf/2104.05861v3.pdf
604,233219505,Evaluating Pre-Trained Models for User Feedback Analysis in Software Engineering: A Study on Classification of App-Reviews,conclusion,"moreover, incorporating app specific data in the pre-training of ptms reduces the prediction time.",ReSolved,https://arxiv.org/pdf/2104.05861v3.pdf
605,233219505,Evaluating Pre-Trained Models for User Feedback Analysis in Software Engineering: A Study on Classification of App-Reviews,conclusion,one of the future directions of this research is assessing domain-specific ptms in other areas of app reviews and exploring ways to increase performance in zero-shot setting.,Finding,https://arxiv.org/pdf/2104.05861v3.pdf
606,256846917,"Backdoor Learning for NLP: Recent Advances, Challenges, and Future Research Directions",conclusion,this work extensively covers research efforts on backdoor learning for nlp.,Neutral,https://export.arxiv.org/pdf/2302.06801v1.pdf
607,256846917,"Backdoor Learning for NLP: Recent Advances, Challenges, and Future Research Directions",conclusion,"to this end, we systematically and comprehensively survey state-of-the-art research studies on backdoor attacks and defenses.",ReSolved,https://export.arxiv.org/pdf/2302.06801v1.pdf
608,256846917,"Backdoor Learning for NLP: Recent Advances, Challenges, and Future Research Directions",conclusion,"additionally, we thoroughly review and analyze various aspects of backdoor learning, including techniques, model architectures, evaluation metrics, and benchmark datasets.",ReSolved,https://export.arxiv.org/pdf/2302.06801v1.pdf
609,256846917,"Backdoor Learning for NLP: Recent Advances, Challenges, and Future Research Directions",conclusion,"we argue that for backdoor learning to contribute to actual robustness, research studies should take into account an expansive view and strive to answer questions related to why such attacks and defenses are successful.",Neutral,https://export.arxiv.org/pdf/2302.06801v1.pdf
610,256846917,"Backdoor Learning for NLP: Recent Advances, Challenges, and Future Research Directions",conclusion,it is crucial to determine whether any given technique is booming due to limitations and weaknesses associated with the target model (inherent incapability arising from intrinsic properties of a target model) or whether it is due to weaknesses or limitations in the dataset itself.,Neutral,https://export.arxiv.org/pdf/2302.06801v1.pdf
611,256846917,"Backdoor Learning for NLP: Recent Advances, Challenges, and Future Research Directions",conclusion,"finally, we offer insights into open challenges and future research directions worth pursuing.  ",Neutral,https://export.arxiv.org/pdf/2302.06801v1.pdf
612,165163607,BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions,conclusion,"we have introduced boolq, a new reading comprehension dataset of naturally occurring yes/no questions.",ReSolved,https://www.aclweb.org/anthology/N19-1300.pdf
613,165163607,BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions,conclusion,we have shown these questions are challenging and require a wide range of inference abilities to solve.,ReSolved,https://www.aclweb.org/anthology/N19-1300.pdf
614,165163607,BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions,conclusion,"we have also studied how transfer learning performs on this task, and found crowd-sourced entailment datasets can be leveraged to boost performance even on top of language model pre-training.",ReSolved,https://www.aclweb.org/anthology/N19-1300.pdf
615,165163607,BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions,conclusion,"future work could include building a document-level version of this task, which would increase its difficulty and its correspondence to an end-user application.",Finding,https://www.aclweb.org/anthology/N19-1300.pdf
616,165163607,BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions,conclusion,likewise we compute p * from the premise.,Neutral,https://www.aclweb.org/anthology/N19-1300.pdf
617,231883811,Unification-based Reconstruction of Multi-hop Explanations for Science Questions,conclusion,this paper proposed a novel framework for multihop explanation reconstruction based on explanatory unification.,ReSolved,https://www.aclweb.org/anthology/2021.eacl-main.15.pdf
618,231883811,Unification-based Reconstruction of Multi-hop Explanations for Science Questions,conclusion,an extensive evaluation on the worldtree corpus led to the following conclusions:,ReSolved,https://www.aclweb.org/anthology/2021.eacl-main.15.pdf
619,216553210,Semantic Graphs for Generating Deep Questions,conclusion and future works,we propose the problem of dqg to generate questions that requires reasoning over multiple disjoint pieces of information.,ReSolved,https://www.aclweb.org/anthology/2020.acl-main.135.pdf
620,216553210,Semantic Graphs for Generating Deep Questions,conclusion and future works,"to this end, we propose a novel framework which incorporates semantic graphs to enhance the input document representations and generate questions by jointly training with the task of content selection.",ReSolved,https://www.aclweb.org/anthology/2020.acl-main.135.pdf
621,216553210,Semantic Graphs for Generating Deep Questions,conclusion and future works,"experiments on the hotpotqa dataset demonstrate that introducing semantic graph significantly reduces the semantic errors, and content selection benefits the selection and reasoning over disjoint relevant contents, leading to questions with better quality.",ReSolved,https://www.aclweb.org/anthology/2020.acl-main.135.pdf
622,258866004,Machine Reading Comprehension using Case-based Reasoning,conclusion,"we present cbr-mrc, a semi-parametric model for machine reading comprehension that is simple, accurate, and interpretable.",ReSolved,https://export.arxiv.org/pdf/2305.14815v1.pdf
623,258866004,Machine Reading Comprehension using Case-based Reasoning,conclusion,"our model stores a collection of cases, retrieves the most relevant cases for a given test question, and then explicitly reuses the reasoning patterns encoded in the embeddings of these cases to predict an answer.",ReSolved,https://export.arxiv.org/pdf/2305.14815v1.pdf
624,212644640,A Framework for Evaluation of Machine Reading Comprehension Gold Standards,conclusion,"in this paper, we introduce a novel framework to characterise machine reading comprehension gold standards.",ReSolved,https://www.aclweb.org/anthology/2020.lrec-1.660.pdf
625,212644640,A Framework for Evaluation of Machine Reading Comprehension Gold Standards,conclusion,"this framework has potential applications when comparing different gold standards, considering the design choices for a new gold standard and performing qualitative error analyses for a proposed approach.",Finding,https://www.aclweb.org/anthology/2020.lrec-1.660.pdf
626,212644640,A Framework for Evaluation of Machine Reading Comprehension Gold Standards,conclusion,"furthermore we applied the framework to analyse popular state-of-the-art gold standards for machine reading comprehension: we reveal issues with their factual correctness, show the presence of lexical cues and we observe that semantics-altering grammatical modifiers are missing in all of the investigated gold standards.",ReSolved,https://www.aclweb.org/anthology/2020.lrec-1.660.pdf
627,212644640,A Framework for Evaluation of Machine Reading Comprehension Gold Standards,conclusion,"studying how to introduce those modifiers into gold standards and observing whether state-of-the-art mrc models are capable of performing reading comprehension on text containing them, is a future research goal.",Finding,https://www.aclweb.org/anthology/2020.lrec-1.660.pdf
628,212644640,A Framework for Evaluation of Machine Reading Comprehension Gold Standards,conclusion,a future line of research is to extend the framework to be able to identify the different types of exploitable cues such as question or entity typing and concrete overlap patterns. this will allow the framework to serve as an interpretable estimate of reading comprehension complexity of gold standards.,Finding,https://www.aclweb.org/anthology/2020.lrec-1.660.pdf
629,212644640,A Framework for Evaluation of Machine Reading Comprehension Gold Standards,conclusion,"finally, investigating gold standards under this framework where mrc models outperform the human baseline (e.g. squad) will contribute to a deeper understanding of the seemingly superb performance of deep learning approaches on them.",Finding,https://www.aclweb.org/anthology/2020.lrec-1.660.pdf
630,227334750,KgPLM: Knowledge-guided Language Model Pre-training via Generative and Discriminative Learning,conclusion,we have proposed a pre-training method by cooperatively modeling the generative and discriminative knowledge injecting approaches.,ReSolved,https://arxiv.org/pdf/2012.03551v1.pdf
631,227334750,KgPLM: Knowledge-guided Language Model Pre-training via Generative and Discriminative Learning,conclusion,our model can be easily extended to larger pre-training corpus and does not introduce any modifications for downstream tasks during finetuning.,ReSolved,https://arxiv.org/pdf/2012.03551v1.pdf
632,227334750,KgPLM: Knowledge-guided Language Model Pre-training via Generative and Discriminative Learning,conclusion,"experiments show our model consistently outperforms all base models on a variety of question answering datasets, demonstrating that our kgplm is a preferred choice for the knowledge intensive nlp tasks.  ",ReSolved,https://arxiv.org/pdf/2012.03551v1.pdf
633,233296243,Learning with Instance Bundles for Reading Comprehension,conclusion,"we have presented a way to use contrastive estimation in a supervised manner to learn from distinguishing cues between multiple related qa pairs, or instance bundles.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.584.pdf
634,233296243,Learning with Instance Bundles for Reading Comprehension,conclusion,"our experiments with multiple ce-based loss functions, defined over a joint neighborhood of questions and answers, have shown that these models outperform existing methods on two datasets: ropes and hotpotqa.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.584.pdf
635,233296243,Learning with Instance Bundles for Reading Comprehension,conclusion,"apart from presenting several ways to create instance bundles, we also explore theoretical connections between unlikelihood training and contrastive estimation, and initial exploration into when instance bundles are likely to be effective with these methods.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.584.pdf
636,233296243,Learning with Instance Bundles for Reading Comprehension,conclusion,we believe our results give strong motivation for further work in techniques to both create and use instance bundles in nlp datasets.,Finding,https://www.aclanthology.org/2021.emnlp-main.584.pdf
637,233296243,Learning with Instance Bundles for Reading Comprehension,conclusion,the code is available at https://github.com/ddua/ contrastive-estimation.,Neutral,https://www.aclanthology.org/2021.emnlp-main.584.pdf
638,254366618,Text Embeddings by Weakly-Supervised Contrastive Pre-training,conclusion,"in this work, we train a general-purpose text embedding model e5 from weak supervision signals.",ReSolved,https://export.arxiv.org/pdf/2212.03533v1.pdf
639,254366618,Text Embeddings by Weakly-Supervised Contrastive Pre-training,conclusion,we adopt a simple contrastive training framework with in-batch negatives and learn from a large-scale text pair dataset we harvest from heterogeneous data sources across the web.,ReSolved,https://export.arxiv.org/pdf/2212.03533v1.pdf
640,254366618,Text Embeddings by Weakly-Supervised Contrastive Pre-training,conclusion,"e5 offers strong off-the-shelf performance for a wide range of tasks requiring single-vector text representations such as retrieval, semantic textual similarity, and text matching.",Neutral,https://export.arxiv.org/pdf/2212.03533v1.pdf
641,254366618,Text Embeddings by Weakly-Supervised Contrastive Pre-training,conclusion,"when further customized for downstream tasks, e5 achieves superior fine-tuned performance compared to existing embedding models with 40× more parameters on the large, 56-task mteb benchmark datasets.",ReSolved,https://export.arxiv.org/pdf/2212.03533v1.pdf
642,254366618,Text Embeddings by Weakly-Supervised Contrastive Pre-training,conclusion,"the ""others"" category includes ""sim-plewiki"", ""gooaq"", ""wikihow"", ""yahoo answers"" from https://huggingface.co/datasets/ sentence-transformers/embedding-training-data.",Neutral,https://export.arxiv.org/pdf/2212.03533v1.pdf
643,248476403,Inferring Implicit Relations with Language Models,conclusion,"in this work, we propose the task of implicit relation inference, which decouples the inference of reasoning steps from their execution.",ReSolved,https://arxiv.org/pdf/2204.13778v1.pdf
644,248476403,Inferring Implicit Relations with Language Models,conclusion,"we introduce implicitrelations, a benchmark that includes over 600 questions implicit reasoning questions along with more than 2,000 annotated implicit relations.",ReSolved,https://arxiv.org/pdf/2204.13778v1.pdf
645,248476403,Inferring Implicit Relations with Language Models,conclusion,"we show that large lms can infer implicit relations well in the in-context setup across multiple types of questions and reasoning skills, but that this success does not transfer to an improvement in the downstream task of answering implicit reasoning questions.",ReSolved,https://arxiv.org/pdf/2204.13778v1.pdf
646,248476403,Inferring Implicit Relations with Language Models,conclusion,"our work sheds light on the types of capabilities missing from large lms for addressing implicit reasoning questions, and provides a valuable resource for further improving the ability of models to infer implicit relations.",ReSolved,https://arxiv.org/pdf/2204.13778v1.pdf
647,239016730,On the Robustness of Reading Comprehension Models to Entity Renaming,conclusion,"in this paper, we systematically study the robustness of mrc models to entity name substitution.",ReSolved,https://www.aclanthology.org/2022.naacl-main.37.pdf
648,239016730,On the Robustness of Reading Comprehension Models to Entity Renaming,conclusion,"specifically, we propose a substitution framework along with candidate names of different implications.",ReSolved,https://www.aclanthology.org/2022.naacl-main.37.pdf
649,239016730,On the Robustness of Reading Comprehension Models to Entity Renaming,conclusion,we experiment with three pretrained language models on five mrc datasets.,ReSolved,https://www.aclanthology.org/2022.naacl-main.37.pdf
650,239016730,On the Robustness of Reading Comprehension Models to Entity Renaming,conclusion,"we find that models trained on distantly-supervised datasets are susceptible to entity name substitution, while models trained on human-annotated datasets are relatively robust, with gpe renaming harder than per and org renaming.",ReSolved,https://www.aclanthology.org/2022.naacl-main.37.pdf
651,239016730,On the Robustness of Reading Comprehension Models to Entity Renaming,conclusion,the lack of robustness can be further attributed to model's overreliance on entity knowledge and name clues.,ReSolved,https://www.aclanthology.org/2022.naacl-main.37.pdf
652,239016730,On the Robustness of Reading Comprehension Models to Entity Renaming,conclusion,"we also find that spanbert, which is pretrained using span-level objectives, shows better robustness than bert and roberta.",ReSolved,https://www.aclanthology.org/2022.naacl-main.37.pdf
653,239016730,On the Robustness of Reading Comprehension Models to Entity Renaming,conclusion,"leveraging these insights, we study defense approaches based on continual pretraining and demonstrate that entity-based masking policies are beneficial to model's robustness.",ReSolved,https://www.aclanthology.org/2022.naacl-main.37.pdf
654,239016730,On the Robustness of Reading Comprehension Models to Entity Renaming,conclusion,"future works include systematically studying the effect of background knowledge in mrc, and developing more effective methods to improve the robustness of mrc models.",Finding,https://www.aclanthology.org/2022.naacl-main.37.pdf
655,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,conclusion,"we propose a novel extension of soft prompt tuning (pt) -vector quantized input-contextualized prompt tuning (vip), designed to have two desirable characteristics -(i) contextualizing the soft prompt tokens w.r.t input text using a learnable sentence encoder (ii) discretizing the contextual prompts using a vector quantization network.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.455.pdf
656,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,conclusion,"on an extensive set of language understanding tasks -superglue, qa, nli, ner, and relation classification, vip outperforms pt baseline.",Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
657,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,conclusion,"further, our generalization studies on out-of-domain evaluations of qa and nli and multi-task settings over 4 tasks also show that vip is able to learn richer and more robust prompt representations than pt.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.455.pdf
658,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"in this section, we point out the limitations of vip and its potential future directions. pretraining prompt contextualizer.",Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
659,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,the sentence encoder in vip is trained from scratch for each downstream task.,Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
660,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"however, following the prompt pre-training proposed in gu et al. (2021), a possible future work is to pretrain the prompt contextualizer in a task-agnostic way",Finding,https://www.aclanthology.org/2022.emnlp-main.455.pdf
661,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"vip framework demands a larger parameter size than the baseline soft prompt tuning, owing mainly to the codebook.",Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
662,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"in appendix a.2 we show that by reducing the number of vip-prompt tokens and codebooksize, we can reduce the parameter size to onethird while compromising performance slightly on superglue.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.455.pdf
663,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"more extensive experimental analysis and better techniques for compressing the codebook, we leave as future work",Finding,https://www.aclanthology.org/2022.emnlp-main.455.pdf
664,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"other than the standard hyperparameters of the sentence encoder, the quantizer introduces new hyperparameters -codebook-size, multinomial sample size, and the temperature constant τ to scale logits.",Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
665,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"while vip needs additional hyperparameters, in all our experiments across 20 training datasets from 5 tasks, we fix all hyperparameters related to codebook and sentence-encoder.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.455.pdf
666,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,this shows that our model is indeed not sensitive to the hyperparameters and does not need very specific tuning for each task/setting.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.455.pdf
667,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,learning the codebook requires an ema style updating scheme instead of the standard gradient update.,Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
668,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"with the plm being frozen, this needs more careful handlingfor e.g. a critical hyperparameter is the value of the temperature constant τ .",Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
669,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,a very high value can lead to representation collapse of the codebook while very low values can lead to sparse codebook usage.,Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
670,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"however, as discussed above, τ is independent of the task and depends on the initial norm of codebook vectors.",Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
671,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"we posit that due to the larger parameter size of vip, it performs worse than pt in tasks with lesser training data, e.g. scores on the cb dataset in table 1.",Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
672,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,this is due to the larger parameter size of vip.,Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
673,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"indeed, by reducing the parameter size of vip, we achieve much better performance on cb. t5-base as backbone plm.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.455.pdf
674,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"due to resource limitations, in all our experiments we use t5base as the backbone.",Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
675,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"following lester et al. (2021) where larger plms are shown to improve prompt-tuning performance, we speculate vip to showcase a similar effect.",Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
676,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"also, though we use t5 as plm in this work, our vip architecture can be used in bert or gpt style prediction or generation as well.",Finding,https://www.aclanthology.org/2022.emnlp-main.455.pdf
677,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"however, a formal analysis of this is left as future work. ",Finding,https://www.aclanthology.org/2022.emnlp-main.455.pdf
678,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"the language understanding tasks and datasets were predominantly in the english language, and thus limit our claims to the english language.",Finding,https://www.aclanthology.org/2022.emnlp-main.455.pdf
679,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,"gender, age, race, and other socioeconomic biases may exist in these datasets, and models trained on these datasets may propagate these biases.",Finding,https://www.aclanthology.org/2022.emnlp-main.455.pdf
680,248986718,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,limitations,it is likely that additional biases are also embedded within the t5-base plm that was used as the backbone of vip.,Neutral,https://www.aclanthology.org/2022.emnlp-main.455.pdf
681,235446913,A Neural Model for Joint Document and Snippet Ranking in Question Answering for Large Document Collections,conclusions and future work,our contributions can be summarized as follows:,ReSolved,https://www.aclanthology.org/2021.acl-long.301.pdf
682,235719347,Programming Language Agnostic Mining of Code and Language Pairs with Sequence Labeling Based Question Answering,conclusion,"in this paper, we propose a sequence labeling based question answering (slqa) approach to construct nl-pl pairs in a pl-agnostic way.",ReSolved,https://arxiv.org/pdf/2203.10744v1.pdf
683,235719347,Programming Language Agnostic Mining of Code and Language Pairs with Sequence Labeling Based Question Answering,conclusion,"we propose a model that can produce multiple code blocks as solutions of a post's question, which is achieved by using bio sequence tagging.",ReSolved,https://arxiv.org/pdf/2203.10744v1.pdf
684,235719347,Programming Language Agnostic Mining of Code and Language Pairs with Sequence Labeling Based Question Answering,conclusion,we also propose to incorporate the global textual context as pl-independent supplementary information.,ReSolved,https://arxiv.org/pdf/2203.10744v1.pdf
685,235719347,Programming Language Agnostic Mining of Code and Language Pairs with Sequence Labeling Based Question Answering,conclusion,"to validate the capacity of our method, we manually annotate a challenging cross-pl multi-block dataset, named lang2code-human.",ReSolved,https://arxiv.org/pdf/2203.10744v1.pdf
686,235719347,Programming Language Agnostic Mining of Code and Language Pairs with Sequence Labeling Based Question Answering,conclusion,substantial experiments on the single-pl single-block staqc-human and our lang2code-human benchmarks demonstrate the effectiveness and cross-pl transferability of our method.,ReSolved,https://arxiv.org/pdf/2203.10744v1.pdf
687,235719347,Programming Language Agnostic Mining of Code and Language Pairs with Sequence Labeling Based Question Answering,conclusion,"finally, we present lang2code, the largest-to-date nl-pl corpus to the best of our knowledge, containing over 1.4 million pairs spanning six pls.",ReSolved,https://arxiv.org/pdf/2203.10744v1.pdf
688,235719347,Programming Language Agnostic Mining of Code and Language Pairs with Sequence Labeling Based Question Answering,conclusion,"under statistical analysis and downstream evaluation on code generation task, we demonstrate that lang2code is a large-scale and high-quality nl-pl pair corpus and can greatly help developing data-hungry models in future research.",Finding,https://arxiv.org/pdf/2203.10744v1.pdf
689,233296016,BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models,conclusions and future work,"in this work, we presented beir: a heterogeneous benchmark for information retrieval.",ReSolved,https://arxiv.org/pdf/2104.08663v4.pdf
690,233296016,BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models,conclusions and future work,we provided a broader selection of target tasks ranging from narrow expert domains to open domain datasets.,ReSolved,https://arxiv.org/pdf/2104.08663v4.pdf
691,233296016,BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models,conclusions and future work,we included nine different retrieval tasks spanning 18 diverse datasets.,ReSolved,https://arxiv.org/pdf/2104.08663v4.pdf
692,214233456,Investigating Prior Knowledge for Challenging Chinese Machine Reading Comprehension,conclusion,"we present the first free-form multiple-choice chinese machine reading comprehension dataset (c 3 ), collected from real-world language exams, requiring linguistic, domain-specific, or general world knowledge to answer questions based on the given written or orally oriented texts.",ReSolved,https://www.aclweb.org/anthology/2020.tacl-1.10.pdf
693,214233456,Investigating Prior Knowledge for Challenging Chinese Machine Reading Comprehension,conclusion,we study the prior knowledge needed in this challenging machine reading comprehension dataset and carefully investigate the impacts of distractor plausibility and data augmentation (based on similar resources for english) on the performance of state-of-the-art neural models.,ReSolved,https://www.aclweb.org/anthology/2020.tacl-1.10.pdf
694,214233456,Investigating Prior Knowledge for Challenging Chinese Machine Reading Comprehension,conclusion,experimental results demonstrate the there is still a significant performance gap between the best-performing model (68.5%) and human readers (96.0%) and a need for better ways for exploiting rich resources in other languages.,Finding,https://www.aclweb.org/anthology/2020.tacl-1.10.pdf
695,238744204,Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?,conclusion,"in this paper, we propose spar, a salient-phrase aware dense retriever, which can augment any dense retriever with the lexical matching capacity and out-of-domain generalization from a sparse retriever.",ReSolved,https://export.arxiv.org/pdf/2110.06918v3.pdf
696,238744204,Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?,conclusion,"this is achieved by training a dense lexical model � to imitate the behavior of the teacher sparse retriever, the feasibility of which remained unknown until this work.",Neutral,https://export.arxiv.org/pdf/2110.06918v3.pdf
697,238744204,Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?,conclusion,"we show that spar outperforms previous state-of-the-art dense and sparse retrievers, matching or even exceeding more complex hybrid systems, on various in-domain and outof-domain evaluation datasets.",ReSolved,https://export.arxiv.org/pdf/2110.06918v3.pdf
698,238744204,Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?,conclusion,for future work we plan to explore if a dense retriever can be trained to learn lexical matching directly without relying on a teacher model.,Finding,https://export.arxiv.org/pdf/2110.06918v3.pdf
699,238744204,Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?,conclusion,"this way, we can avoid imitating the errors of the sparse retriever, and devise new ways of training dense retrievers that can potentially surpass hybrid models.",Neutral,https://export.arxiv.org/pdf/2110.06918v3.pdf
700,238744204,Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?,conclusion,"moreover, there are several intriguing findings in this work that may warrant further study, such as why spar's acc@k improves relatively to the hybrid model as k increases, and why joint training is less effective than post-hoc vector concatenation.",Finding,https://export.arxiv.org/pdf/2110.06918v3.pdf
701,252780709,Understanding and Improving Zero-shot Multi-hop Reasoning in Generative Question Answering,conclusion,"in this paper, we examined the multi-hop reasoning capabilities of generative qa models, finding that overall models take shortcuts when answering multi-hop questions, not demonstrating convincing multi-hop reasoning capability.",ReSolved,https://www.aclanthology.org/2022.coling-1.152.pdf
702,252780709,Understanding and Improving Zero-shot Multi-hop Reasoning in Generative Question Answering,conclusion,"when trained only on single-hop questions, models generalize poorly to multi-hop questions, while approximation using the concatenation of single-hop questions and sparql queries improves the multi-hop performance significantly.",ReSolved,https://www.aclanthology.org/2022.coling-1.152.pdf
703,252780709,Understanding and Improving Zero-shot Multi-hop Reasoning in Generative Question Answering,conclusion,further directions include better approximations of multi-hop questions and advanced modeling techniques that encourage compositional ability.,Neutral,https://www.aclanthology.org/2022.coling-1.152.pdf
704,249395505,On the Advance of Making Language Models Better Reasoners,conclusion and future work,"we introduce diverse, an effective and general method to make large language models better reasoners.",ReSolved,https://arxiv.org/pdf/2206.02336v2.pdf
705,249395505,On the Advance of Making Language Models Better Reasoners,conclusion and future work,"as a continuation of the line of research that prompting language models using multi-step reasoning paths, the key insights of diverse are three-fold: diverse prompts, voting verifier, and step-level correctness.",ReSolved,https://arxiv.org/pdf/2206.02336v2.pdf
706,249395505,On the Advance of Making Language Models Better Reasoners,conclusion and future work,experimental results clearly show that diverse can bring significant and consistent improvements.,ReSolved,https://arxiv.org/pdf/2206.02336v2.pdf
707,249395505,On the Advance of Making Language Models Better Reasoners,conclusion and future work,"for example, with codedavinci-002, diverse achieves new state-of-theart results in most of the reasoning tasks, outperforming the 540b palm model combined with previous prompting approaches.",Neutral,https://arxiv.org/pdf/2206.02336v2.pdf
708,252873674,The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning,discussion & conclusion,"caveats and risks of explanations from large language models our analysis suggests that llms' internal ""reasoning"" does not always align with explanations that it generates, as shown by our consistency results.",Neutral,https://export.arxiv.org/pdf/2205.03401v2.pdf
709,252873674,The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning,discussion & conclusion,"more concerning, the explanations might not be factually grounded in the provided prompt.",Finding,https://export.arxiv.org/pdf/2205.03401v2.pdf
710,252873674,The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning,discussion & conclusion,"this shortcoming should caution against any deployment of this technology in practice: because the explanations are grammatical english and look very convincing, they may deceive users into believing the system's responses even when those responses are incorrect.",Finding,https://export.arxiv.org/pdf/2205.03401v2.pdf
711,252873674,The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning,discussion & conclusion,section 6 of bender et al. (2021) discusses these risks in additional detail.,Neutral,https://export.arxiv.org/pdf/2205.03401v2.pdf
712,252873674,The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning,discussion & conclusion,"the fact that language models can hallucinate explanations is also found in other work (zhou and tan, 2021).",Neutral,https://export.arxiv.org/pdf/2205.03401v2.pdf
713,252873674,The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning,discussion & conclusion,"this result is unsurprising in some sense: without sufficient supervision or grounding, language models do not learn meaning as distinct from form (bender and koller, 2020), so we should not expect their explanations to be strongly grounded.",Neutral,https://export.arxiv.org/pdf/2205.03401v2.pdf
714,255440689,InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval,conclusion,"in this work, we presented inpars-v2, an improved version of inpars [1] that uses a publicly available language model to generate queries and a better query-document pair selection process.",ReSolved,https://export.arxiv.org/pdf/2301.01820v4.pdf
715,255440689,InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval,conclusion,our results show that we achieve effectiveness on par with the state of the art on beir.,ReSolved,https://export.arxiv.org/pdf/2301.01820v4.pdf
716,255440689,InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval,conclusion,the synthetic data and finetuned models were publicly released.,Neutral,https://export.arxiv.org/pdf/2301.01820v4.pdf
717,248426967,HYBRIDIALOGUE: An Information-Seeking Dialogue Dataset Grounded on Tabular and Textual Data,conclusion,"in this paper, we presented a novel dataset, hy-bridialogue, for information-seeking dialogue where knowledge is grounded in both tables and text.",ReSolved,https://www.aclanthology.org/2022.findings-acl.41.pdf
718,248426967,HYBRIDIALOGUE: An Information-Seeking Dialogue Dataset Grounded on Tabular and Textual Data,conclusion,"while previous work has combined table and text modality in the question-answering space, this has not been utilized in the dialogue setting.",Neutral,https://www.aclanthology.org/2022.findings-acl.41.pdf
719,248426967,HYBRIDIALOGUE: An Information-Seeking Dialogue Dataset Grounded on Tabular and Textual Data,conclusion,our results in the various tasks demonstrate that there is still significant room for improvement and illustrate the need to build models that can adapt well to this hybrid format.,ReSolved,https://www.aclanthology.org/2022.findings-acl.41.pdf
720,248426967,HYBRIDIALOGUE: An Information-Seeking Dialogue Dataset Grounded on Tabular and Textual Data,conclusion,"in addition to the baseline tasks, future research can utilize hybridialogue to explore automatic multihop question decomposition.",Finding,https://www.aclanthology.org/2022.findings-acl.41.pdf
721,254926391,Multi-hop Evidence Retrieval for Cross-document Relation Extraction,conclusion,we study efficient and effective ways to extract multi-hop evidence for cross-document re and propose mr.cod.,ReSolved,https://export.arxiv.org/pdf/2212.10786v2.pdf
722,254926391,Multi-hop Evidence Retrieval for Cross-document Relation Extraction,conclusion,mr.cod extracts evidence paths from an open set of documents and ranks them with adapted dense retrievers as scorers.,ReSolved,https://export.arxiv.org/pdf/2212.10786v2.pdf
723,254926391,Multi-hop Evidence Retrieval for Cross-document Relation Extraction,conclusion,"to overcome the gap between retrieval in odqa and evidence retrieval for re, we develop a contextual dpr that augments sparse queries with passage context.",ReSolved,https://export.arxiv.org/pdf/2212.10786v2.pdf
724,254926391,Multi-hop Evidence Retrieval for Cross-document Relation Extraction,conclusion,extensive experiments show high-quality evidence retrieved by mr.cod boosts end-to-end cross-document re performance.,ReSolved,https://export.arxiv.org/pdf/2212.10786v2.pdf
725,254926391,Multi-hop Evidence Retrieval for Cross-document Relation Extraction,conclusion,"future works include extending mr.cod to more retrieval methods, such as generative dense retrievers.",Finding,https://export.arxiv.org/pdf/2212.10786v2.pdf
726,258558037,Empowering Language Model with Guided Knowledge Fusion for Biomedical Document Re-ranking,conclusion,"in this work, we proposed an effective approach to re-rank the documents by utilizing the knowledge graph and integrating the external knowledge into the plms.",ReSolved,https://export.arxiv.org/pdf/2305.04344v1.pdf
727,258558037,Empowering Language Model with Guided Knowledge Fusion for Biomedical Document Re-ranking,conclusion,"to effectively fuse the language and graph information in the knowledge-enriched framework, we introduced a mutual informationbased objective function, which ensures the fused representations are non-redundant and informative in nature.",ReSolved,https://export.arxiv.org/pdf/2305.04344v1.pdf
728,258558037,Empowering Language Model with Guided Knowledge Fusion for Biomedical Document Re-ranking,conclusion,extensive experiments on biomedical and open-domain datasets show the effectiveness of the proposed approach.,ReSolved,https://export.arxiv.org/pdf/2305.04344v1.pdf
729,216035859,Logic-Guided Data Augmentation and Regularization for Consistent Question Answering,conclusion,"we introduce a logic guided data augmentation and consistency-based regularization framework for accurate and globally consistent qa, especially under limited training data setting.",ReSolved,https://www.aclweb.org/anthology/2020.acl-main.499.pdf
730,216035859,Logic-Guided Data Augmentation and Regularization for Consistent Question Answering,conclusion,our approach significantly improves the state-of-the-art models across three substantially different qa datasets.,ReSolved,https://www.aclweb.org/anthology/2020.acl-main.499.pdf
731,216035859,Logic-Guided Data Augmentation and Regularization for Consistent Question Answering,conclusion,"notably, our approach advances the state-of-the-art on quarel and wiqa, two standard benchmarks requiring rich logical and language understanding.",ReSolved,https://www.aclweb.org/anthology/2020.acl-main.499.pdf
732,216035859,Logic-Guided Data Augmentation and Regularization for Consistent Question Answering,conclusion,we further show that our approach can effectively learn from extremely limited training data.,ReSolved,https://www.aclweb.org/anthology/2020.acl-main.499.pdf
733,233289699,What to Pre-Train on? Efficient Intermediate Task Selection,conclusion,"in this work we have established that intermediate pre-training can yield gains in adapter-based setups, however, around 44% of all transfer combinations result in decreased performances.",Neutral,https://www.aclanthology.org/2021.emnlp-main.827.pdf
734,233289699,What to Pre-Train on? Efficient Intermediate Task Selection,conclusion,we have consolidated several existing and new methods for efficiently identifying beneficial intermediate tasks.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.827.pdf
735,257985191,CoT-MAE v2: Contextual Masked Auto-Encoder with Multi-view Modeling for Passage Retrieval,conclusion,this paper proposes a multi-view contextual masked auto-encoding pre-training architecture for better passage retrieval.,ReSolved,https://export.arxiv.org/pdf/2304.03158v1.pdf
736,257985191,CoT-MAE v2: Contextual Masked Auto-Encoder with Multi-view Modeling for Passage Retrieval,conclusion,experiment results show that multi-view representation and multi-view decoding paradigms significantly contribute to effec-tive retrieval performance.,ReSolved,https://export.arxiv.org/pdf/2304.03158v1.pdf
737,257985191,CoT-MAE v2: Contextual Masked Auto-Encoder with Multi-view Modeling for Passage Retrieval,conclusion,our method also shows good robustness and stability.,ReSolved,https://export.arxiv.org/pdf/2304.03158v1.pdf
738,257985191,CoT-MAE v2: Contextual Masked Auto-Encoder with Multi-view Modeling for Passage Retrieval,conclusion,"in the future, we will further explore incorporating new pre-training paradigms to get more effective and robust retrievers.",Finding,https://export.arxiv.org/pdf/2304.03158v1.pdf
739,207852656,Meta Answering for Machine Reading,conclusion,"meta-answering is a framework for qa that attempts to simulate real-world-imperfectinformation-seeking tasks, where humans look for answers in settings mediated by machines, using natural language.",ReSolved,https://arxiv.org/pdf/1911.04156v2.pdf
740,207852656,Meta Answering for Machine Reading,conclusion,"human meta-answerers can compete with a bert-based single system with access to full documents, by only looking at a five token window around candidates.",ReSolved,https://arxiv.org/pdf/1911.04156v2.pdf
741,207852656,Meta Answering for Machine Reading,conclusion,"a machine meta-answerer built on bert can improve the environment's qa system, thus proving that it is possible to investigate mr in imperfect information settings in high-performance regimes.",ReSolved,https://arxiv.org/pdf/1911.04156v2.pdf
742,207852656,Meta Answering for Machine Reading,conclusion,"further, the task brings to the surface, yet again but from a novel perspective, limitations of the current nlu paradigm.",Neutral,https://arxiv.org/pdf/1911.04156v2.pdf
743,207852656,Meta Answering for Machine Reading,conclusion,mma cannot use the contextual information that is effortlessly exploited by humans.,Finding,https://arxiv.org/pdf/1911.04156v2.pdf
744,207852656,Meta Answering for Machine Reading,conclusion,"thus, it might prove a suitable framework to advance on these challenges.",Finding,https://arxiv.org/pdf/1911.04156v2.pdf
745,257532206,Semantic matching based legal information retrieval system for COVID-19 pandemic,conclusion,we propose a semantic matching network for pairwise relation learning.,ReSolved,
746,257532206,Semantic matching based legal information retrieval system for COVID-19 pandemic,conclusion,"moreover, we introduce auxiliary contrastive learning to help network better distinguish the sentences.",ReSolved,
747,257532206,Semantic matching based legal information retrieval system for COVID-19 pandemic,conclusion,our experiments show that our method leads to performance improvements under a variety of encoder designs.,ReSolved,
748,257532206,Semantic matching based legal information retrieval system for COVID-19 pandemic,conclusion,"based on the network we proposed, we design and implement a legal ir system for the covid-19 pandemic.",ReSolved,
749,257532206,Semantic matching based legal information retrieval system for COVID-19 pandemic,conclusion,"the system can identify: (1) the crime cases entered by the user and find the most similar cases to be pushed to the user as answers, and (2) the crime cases documented by the user and give the reference legal gist applicable to the case.",Neutral,
750,257532206,Semantic matching based legal information retrieval system for COVID-19 pandemic,conclusion,"meanwhile, the study could benefit developing a more comprehensive legal ir system and similar systems.",Finding,
751,257532206,Semantic matching based legal information retrieval system for COVID-19 pandemic,conclusion,"in the future, it is worth doing more experiments on more data set to analyse the effect of various neural models for such tasks and accordingly improving the system.",Finding,
752,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,conclusion & future work,"in this work, we proposed cft as an improvement upon end-to-end learning.",ReSolved,https://export.arxiv.org/pdf/2210.12607v1.pdf
753,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,conclusion & future work,"to enable research on this topic, we developed a new schema for generating recommendation datasets, which we instantiated in two domains.",ReSolved,https://export.arxiv.org/pdf/2210.12607v1.pdf
754,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,conclusion & future work,"we showed that cft indeed consistently outperforms end-to-end learning, as much as 32% for local dining.",ReSolved,https://export.arxiv.org/pdf/2210.12607v1.pdf
755,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,conclusion & future work,"furthermore, we found evidence suggesting that more component tasks can be beneficial for cft.",ReSolved,https://export.arxiv.org/pdf/2210.12607v1.pdf
756,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,conclusion & future work,"finally, instantiating chain of thought prompting in our dataset and cft in sports understanding, we found cft to be as good or better with lms only 7.4% of the size.",ReSolved,https://export.arxiv.org/pdf/2210.12607v1.pdf
757,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,this work focuses on testing if cft outperforms end-to-end learning and chain of thought prompting in two very different domains.,Neutral,https://export.arxiv.org/pdf/2210.12607v1.pdf
758,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,"despite the positive evidence, it remains to be seen: (i) if task decomposition can be fully automated, and (ii) if different decompositions-in the case of tasks that allow for multiple decompositions-yield similar results.",Finding,https://export.arxiv.org/pdf/2210.12607v1.pdf
759,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,both are second-order research questions that can be pursued once compositionality has been confirmed to improve performance.,Neutral,https://export.arxiv.org/pdf/2210.12607v1.pdf
760,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,"importantly, both questions have been left open in the initial chain of thought work as well.",Neutral,https://export.arxiv.org/pdf/2210.12607v1.pdf
761,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,we hope that our results will add to theirs in attracting more attention to these questions in the future.another limitation of this work is that cft is not applicable to several decomposition datasets that have been proposed.,Finding,https://export.arxiv.org/pdf/2210.12607v1.pdf
762,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,"for example, a dataset focused on compositional generalization may include many different types of questions, each requiring different types of intermediate steps.",Neutral,https://export.arxiv.org/pdf/2210.12607v1.pdf
763,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,cft is not designed for intermediate steps that carry out very heterogeneous logic.,Finding,https://export.arxiv.org/pdf/2210.12607v1.pdf
764,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,"nonetheless, as shown in the recommendation tasks, cft is still relevant for a substantial family of tasks with real-world applicability.lastly, this work is limited by its focus on the english language, and by the use of gpt-3 for its unique range of model sizes.",Finding,https://export.arxiv.org/pdf/2210.12607v1.pdf
765,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,"for example, when we discuss that cft on a 13b parameter model (curie) is a much cheaper alternative to chain of thought prompting on a 175b parameter model (davinci), the finding is limited to this setting.",Finding,https://export.arxiv.org/pdf/2210.12607v1.pdf
766,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,"it is important to replicate this work on other languages and models, which we plan to do as these become available.comprises two attributes.",Finding,https://export.arxiv.org/pdf/2210.12607v1.pdf
767,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,"for world cities, we have a = {temperature, population} where average city temperatures are obtained from wikipedia 4 and city populations from sim-plemaps 2019.",Neutral,https://export.arxiv.org/pdf/2210.12607v1.pdf
768,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,"5 after merging items from both sources, we end with 347 well-known cities (>50k inhabitans) from around the globe, such that d c = (i f ull c , {temperature, population}) and |i f ull c | = 347.",Neutral,https://export.arxiv.org/pdf/2210.12607v1.pdf
769,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,"for local restaurants, we randomly sample 240 restaurants from the city with most restaurants in the yelp dataset 6 , toronto.",Neutral,https://export.arxiv.org/pdf/2210.12607v1.pdf
770,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,"we have a = {price, distance} where restaurant prices are obtained from yelp and distances to a hypothetical location are randomly generated, thus limiting the lm's access to prior knowledge in this scenario.",Finding,https://export.arxiv.org/pdf/2210.12607v1.pdf
771,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,"with that, we have d r = (i f ull r , {price, distance}) and |i f ull r | = 240.in terms of component tasks, we have 694 factual statements for the cities domain and 480 for restaurants, covering two attributes per item.",Neutral,https://export.arxiv.org/pdf/2210.12607v1.pdf
772,253098647,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,limitations,"whenever factual statements are provided in cft, they always cover i f ull entirely in order to give the lm full knowledge of the attribute values.",Neutral,https://export.arxiv.org/pdf/2210.12607v1.pdf
773,254069686,Penalizing Confident Predictions on Largely Perturbed Inputs Does Not Improve Out-of-Distribution Generalization in Question Answering,conclusion,we first showed that entropy maximization often fails to transfer to unseen perturbation types.,ReSolved,https://export.arxiv.org/pdf/2211.16093v1.pdf
774,254069686,Penalizing Confident Predictions on Largely Perturbed Inputs Does Not Improve Out-of-Distribution Generalization in Question Answering,conclusion,maximizing the entropy terms for various types of perturbations is effective in mitigating this problem.,ReSolved,https://export.arxiv.org/pdf/2211.16093v1.pdf
775,254069686,Penalizing Confident Predictions on Largely Perturbed Inputs Does Not Improve Out-of-Distribution Generalization in Question Answering,conclusion,the failure of entropy maximization to improve out-of-distribution generalization may be caused by the unnaturalness of the perturbed inputs.,Finding,https://export.arxiv.org/pdf/2211.16093v1.pdf
776,254069686,Penalizing Confident Predictions on Largely Perturbed Inputs Does Not Improve Out-of-Distribution Generalization in Question Answering,conclusion,modifying the perturbation functions to effectively improve outof-distribution generalization is future work.,Finding,https://export.arxiv.org/pdf/2211.16093v1.pdf
777,253522964,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,conclusion,"we presented oreolm, a novel model that incorporates symbolic kg reasoning with existing lms.",ReSolved,https://export.arxiv.org/pdf/2211.08380v1.pdf
778,253522964,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,conclusion,"we showed that oreolm can bring significant performance gain to open-domain qa benchmarks, both for closed-book and open-book settings, as well as encoder-only and encoder-decoder models.",ReSolved,https://export.arxiv.org/pdf/2211.08380v1.pdf
779,253522964,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,conclusion,"additionally, oreolm produces reasoning paths that helps interpret the model prediction.",ReSolved,https://export.arxiv.org/pdf/2211.08380v1.pdf
780,253522964,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,conclusion,"in future, we'd like to improve oreolm by training to conduct more reasoning steps, supporting locial reasoning, and apply oreolm to a broader range of knowledge-intensive nlp tasks.",Finding,https://export.arxiv.org/pdf/2211.08380v1.pdf
781,253522964,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,limitations,"limited reasoning steps in our experiments, we show that using reasoning step t = 2 has better performance to t = 1 on one-hop and multi-hop (mostly two) qa datasets. thus, it's a natural question about whether we could extending reasoning steps more?",Finding,https://export.arxiv.org/pdf/2211.08380v1.pdf
782,253522964,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,limitations,"as previous kg reasoning mostly could support very long path (with lstm design)though we didn't spend much time exploring before the paper submission, we indeed try using t = 3, but currently it didn't get better results.",Finding,https://export.arxiv.org/pdf/2211.08380v1.pdf
783,253522964,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,limitations,we hypothesize the following reasons: 1) a large portion of our current model's improvement relies on the weakly supervised relation pre-training.,Neutral,https://export.arxiv.org/pdf/2211.08380v1.pdf
784,253522964,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,limitations,"to do it, we construct a k-hop (k=2 now) subgraph, and sample dependency graph based on it.",Neutral,https://export.arxiv.org/pdf/2211.08380v1.pdf
785,253522964,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,limitations,"the larger k we choose, the more noise is included into the generated relation label, in an exponential increasing speed.",Neutral,https://export.arxiv.org/pdf/2211.08380v1.pdf
786,253522964,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,limitations,"thus, it's harder to get accurate reasoning path ground-truth for high-order t .",Finding,https://export.arxiv.org/pdf/2211.08380v1.pdf
787,253522964,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,limitations,"another potential reason is that within transformer model, the representation space in lower and upper layer might be very different, say, encode more syntax and surface knowledge at lower layers, while more semantic knowledge at upper layers.",Finding,https://export.arxiv.org/pdf/2211.08380v1.pdf
788,253522964,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,limitations,"currently we adopt a mlp projection head, wishing to map integrated knowledge into the same space, but it might have many flaws and need further improvement.",Finding,https://export.arxiv.org/pdf/2211.08380v1.pdf
789,253522964,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,limitations,"table requires pre-training and gpu resources our current design has a huge entity embedding table, which should be learned through additional supervision and could not directly fine-tune to downstream tasks. this is restricts our approach's usage.",Finding,https://export.arxiv.org/pdf/2211.08380v1.pdf
790,220403560,KQA Pro: A Large Diagnostic Dataset for Complex Question Answering over Knowledge Base,conclusions,"we introduce kqa pro, a new benchmark of complex kbqa with following features: 1) with explicit reasoning process, including sparqls and programs; 2) large-scale, with about 120k natural questions; 3) with rich kinds of knowledge, including relational, literal, and high-level.",ReSolved,https://arxiv.org/pdf/2007.03875v1.pdf
791,220403560,KQA Pro: A Large Diagnostic Dataset for Complex Question Answering over Knowledge Base,conclusions,we create a unified codebase to implement the baselines and state-of-the-arts of complex kbqa.,ReSolved,https://arxiv.org/pdf/2007.03875v1.pdf
792,220403560,KQA Pro: A Large Diagnostic Dataset for Complex Question Answering over Knowledge Base,conclusions,"extensive experiments reveal a huge gap between machines and humans, demonstrating that kqa pro is very challenging.",Neutral,https://arxiv.org/pdf/2007.03875v1.pdf
793,220403560,KQA Pro: A Large Diagnostic Dataset for Complex Question Answering over Knowledge Base,conclusions,kqa pro is the first kbqa benchmark that provides the explicit reasoning process for complex questions.,ReSolved,https://arxiv.org/pdf/2007.03875v1.pdf
794,220403560,KQA Pro: A Large Diagnostic Dataset for Complex Question Answering over Knowledge Base,conclusions,we hope that these additional information can help machines develop the compositional reasoning ability and learn to tackle complex questions like a human.,Neutral,https://arxiv.org/pdf/2007.03875v1.pdf
795,248722227,Exploring Universal Intrinsic Task Subspace via Prompt Tuning,conclusion and discussion,we study the hypothesis that plm adaptations to various tasks can be reparameterized as optimizations within a unified low-dimensional intrinsic task subspace.,ReSolved,https://export.arxiv.org/pdf/2110.07867v3.pdf
796,248722227,Exploring Universal Intrinsic Task Subspace via Prompt Tuning,conclusion and discussion,we develop an analysis tool ipt.,ReSolved,https://export.arxiv.org/pdf/2110.07867v3.pdf
797,248722227,Exploring Universal Intrinsic Task Subspace via Prompt Tuning,conclusion and discussion,it first finds a subspace by jointly decomposing the adaptive parameters of multiple tasks and then tunes parameters within the subspace for unseen data and tasks.,Neutral,https://export.arxiv.org/pdf/2110.07867v3.pdf
798,248722227,Exploring Universal Intrinsic Task Subspace via Prompt Tuning,conclusion and discussion,"experiments show the found subspaces contain good solutions for plm adaptations, which is strong evidence for our hypothesis.",ReSolved,https://export.arxiv.org/pdf/2110.07867v3.pdf
799,219401765,GMAT: Global Memory Augmentation for Transformers,conclusion,"in this work, we proposed gmat, a simple extension to the transformer architecture that allows a better trade-off between compute and performance and can be naturally used for sequence compression.",ReSolved,https://arxiv.org/pdf/2006.03274v1.pdf
800,219401765,GMAT: Global Memory Augmentation for Transformers,conclusion,our approach can be seamlessly integrated with the increasingly-popular sparse transformer variants.,ReSolved,https://arxiv.org/pdf/2006.03274v1.pdf
801,257365136,MULTITASK PROMPT TUNING ENABLES PARAMETER-EFFICIENT TRANSFER LEARNING,conclusion,"we introduced and studied multitask prompt tuning (mpt), which learns a single transferable prompt by decomposing and distilling knowledge from multiple source tasks and their task-specific source prompts.",ReSolved,https://export.arxiv.org/pdf/2303.02861v1.pdf
802,257365136,MULTITASK PROMPT TUNING ENABLES PARAMETER-EFFICIENT TRANSFER LEARNING,conclusion,mpt decomposes the task prompt as the hadamard product of a shared prompt matrix and a rank-one task-specific matrix.,ReSolved,https://export.arxiv.org/pdf/2303.02861v1.pdf
803,257365136,MULTITASK PROMPT TUNING ENABLES PARAMETER-EFFICIENT TRANSFER LEARNING,conclusion,the shared component is then transferred and adapted to target tasks for further tuning.,Neutral,https://export.arxiv.org/pdf/2303.02861v1.pdf
804,257365136,MULTITASK PROMPT TUNING ENABLES PARAMETER-EFFICIENT TRANSFER LEARNING,conclusion,"empirically we found this approach enables parameter-efficient transfer learning to target downstream tasks across diverse nlp benchmarks, even outperforming the full finetuning baseline in some cases, despite tuning much fewer task-specific parameters.",Neutral,https://export.arxiv.org/pdf/2303.02861v1.pdf
805,256662717,Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories,conclusion,in this paper we propose a new plug-in mixture-ofmemory mechanism for the retrieval augmented language models to improve their zero-shot ability on the dense retrieval task.,ReSolved,https://export.arxiv.org/pdf/2302.03754v1.pdf
806,256662717,Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories,conclusion,"to learn the memory mixture we develop a new joint learning approach that trains the augmentation component using the positive signals from the end task, the language model's attention scores, and  wood jr.",ReSolved,https://export.arxiv.org/pdf/2302.03754v1.pdf
807,256662717,Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories,conclusion,"(october 10, december 10, 1978) was an american filmmaker, actor, writer, producer, and director.",Neutral,https://export.arxiv.org/pdf/2302.03754v1.pdf
808,256662717,Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories,conclusion,hard negatives retrieved from the mixture of augmentation corpora.,Neutral,https://export.arxiv.org/pdf/2302.03754v1.pdf
809,256662717,Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories,conclusion,this leads to our final model moma (t5-ance) and moma (coco) that achieve strong zero-shot accuracy on 18 retrieval tasks included in beir.,ReSolved,https://export.arxiv.org/pdf/2302.03754v1.pdf
810,256662717,Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories,conclusion,our analysis shows the importance of augmenting with diverse memory sources and in-domain information for robust generalization.,ReSolved,https://export.arxiv.org/pdf/2302.03754v1.pdf
811,256662717,Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories,conclusion,we also share our observations and insights on how the model learns to leverage the augmentation information from multiple corpora during training and testing.,ReSolved,https://export.arxiv.org/pdf/2302.03754v1.pdf
812,256662717,Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories,conclusion,"we hope our findings and illustrations can inspire more future research in better augmenting language models, to provide other alternatives to achieve generalization ability beyond solely relying on model scale.",Finding,https://export.arxiv.org/pdf/2302.03754v1.pdf
813,253080775,WIKIWHY: ANSWERING AND EXPLAINING CAUSE-AND-EFFECT QUESTIONS,conclusion,"with this paper, we release wikiwhy, a question-answering dataset enabling the analysis and improvement of llms' reasoning capability.",ReSolved,https://export.arxiv.org/pdf/2210.12152v2.pdf
814,253080775,WIKIWHY: ANSWERING AND EXPLAINING CAUSE-AND-EFFECT QUESTIONS,conclusion,we propose explanation between grounded cause-effect pairs to distinguish memorization of the relation from a genuine understanding of the underlying mechanics.,ReSolved,https://export.arxiv.org/pdf/2210.12152v2.pdf
815,253080775,WIKIWHY: ANSWERING AND EXPLAINING CAUSE-AND-EFFECT QUESTIONS,conclusion,"compared to related works on explainable qa, our explanation format finds a natural middle ground that balances complexity and depth, allowing our crowdsourcing methods to produce thought-provoking examples while being highly scalable.",ReSolved,https://export.arxiv.org/pdf/2210.12152v2.pdf
816,253080775,WIKIWHY: ANSWERING AND EXPLAINING CAUSE-AND-EFFECT QUESTIONS,conclusion,we exploit this scalability to cover topics previously overlooked by other explanation datasets and demonstrate our proposed task to be difficult with strong baselines (our experiments feature models failing to produce satisfying explanations even under ideal conditions).,ReSolved,https://export.arxiv.org/pdf/2210.12152v2.pdf
817,253080775,WIKIWHY: ANSWERING AND EXPLAINING CAUSE-AND-EFFECT QUESTIONS,conclusion,"finally, we motivate the development of new automatic metrics that are better able to handle the complexities of generated reasoning.",Neutral,https://export.arxiv.org/pdf/2210.12152v2.pdf
818,227231411,Answer-driven Deep Question Generation based on Reinforcement Learning,conclusion and future work,deep question generation aims to generate complex questions that require reasoning over multiple pieces of information.,Neutral,https://www.aclweb.org/anthology/2020.coling-main.452.pdf
819,227231411,Answer-driven Deep Question Generation based on Reinforcement Learning,conclusion and future work,"in this paper, we propose an answer-driven end-to-end deep question generation model (addqg) based on reinforcement learning.",ReSolved,https://www.aclweb.org/anthology/2020.coling-main.452.pdf
820,227231411,Answer-driven Deep Question Generation based on Reinforcement Learning,conclusion and future work,an answer-aware initialization module with a gated connection layer and a semantic-rich fusion attention mechanism are designed to incorporate document and answer information into the generation process.,Neutral,https://www.aclweb.org/anthology/2020.coling-main.452.pdf
821,227231411,Answer-driven Deep Question Generation based on Reinforcement Learning,conclusion and future work,reinforcement learning is further applied to integrate both syntactic and semantic metrics as the reward to enhance the training of addqg.,ReSolved,https://www.aclweb.org/anthology/2020.coling-main.452.pdf
822,227231411,Answer-driven Deep Question Generation based on Reinforcement Learning,conclusion and future work,experiments show that addqg outperforms the state-of-the-art systems on the challenging dqg dataset.,ReSolved,https://www.aclweb.org/anthology/2020.coling-main.452.pdf
823,227231411,Answer-driven Deep Question Generation based on Reinforcement Learning,conclusion and future work,"ablation studies have demonstrated the effectiveness of our designs, and human evaluations show that our model can produce more coherent and answer-focused questions.",ReSolved,https://www.aclweb.org/anthology/2020.coling-main.452.pdf
824,2945602,Proteome Science Detection and identification of NAP-2 as a biomarker in hepatitis B-related hepatocellular carcinoma by proteomic approach,conclusion,"in summary, we have identified a set of protein peaks that could discriminate hcc from healthy controls.",ReSolved,
825,2945602,Proteome Science Detection and identification of NAP-2 as a biomarker in hepatitis B-related hepatocellular carcinoma by proteomic approach,conclusion,"from the protein peaks specific to hcc disease, we identified and characterized neutrophil-activating peptide-2 as a potential proteomic biomarker of hcc.",ReSolved,
826,2945602,Proteome Science Detection and identification of NAP-2 as a biomarker in hepatitis B-related hepatocellular carcinoma by proteomic approach,conclusion,"further studies with larger sample sizes will be needed to verify this specific protein marker and to address its efficacy, especially with regard to discriminating histologic types of hcc and disease stages.",Finding,
827,2945602,Proteome Science Detection and identification of NAP-2 as a biomarker in hepatitis B-related hepatocellular carcinoma by proteomic approach,conclusion,"nevertheless, our study demonstrates a rational approach for identifying hcc biomarkers that could be used for detection and monitoring hcc by proteomic techniques.",ReSolved,
828,214071925,Translucent Answer Predictions in Multi-Hop Reading Comprehension,conclusions,tap is a novel architecture for the multi-hop reasoning based rcqa task.,ReSolved,https://ojs.aaai.org/index.php/AAAI/article/download/6272/6128
829,214071925,Translucent Answer Predictions in Multi-Hop Reading Comprehension,conclusions,"core to this system is logix, a new approach that effectively addresses the challenges of local context and global interactions present in multi-passage, multihop qa.",ReSolved,https://ojs.aaai.org/index.php/AAAI/article/download/6272/6128
830,214071925,Translucent Answer Predictions in Multi-Hop Reading Comprehension,conclusions,"we have shown that tap advances the state-of-theart on hotpotqa dataset, reaching rank-1 and rank-2 in its ensemble and single model variants at the time of submission.",ReSolved,https://ojs.aaai.org/index.php/AAAI/article/download/6272/6128
831,214071925,Translucent Answer Predictions in Multi-Hop Reading Comprehension,conclusions,"finally, by restricting the input of the ap to logix's selected supporting facts, tap admits interpretability that can be used to debug the model for performance enhancement purposes prior to its deployment.",ReSolved,https://ojs.aaai.org/index.php/AAAI/article/download/6272/6128
832,252567884,Mr. Right: Multimodal Retrieval on Representation of ImaGe witH Text,conclusion,"in this paper, we propose mr. right, a multimodal retrieval dataset for information retrieval.",ReSolved,https://export.arxiv.org/pdf/2209.13764v1.pdf
833,252567884,Mr. Right: Multimodal Retrieval on Representation of ImaGe witH Text,conclusion,"mr. right covers three types of text-based search queries with different modality information, including text-related, image-related, and mixed, to simulate real-world search situations.",Neutral,https://export.arxiv.org/pdf/2209.13764v1.pdf
834,252567884,Mr. Right: Multimodal Retrieval on Representation of ImaGe witH Text,conclusion,"further, our dataset provides documents with texts and images to develop multimodal representation.",ReSolved,https://export.arxiv.org/pdf/2209.13764v1.pdf
835,252567884,Mr. Right: Multimodal Retrieval on Representation of ImaGe witH Text,conclusion,we build our end-to-end multimodal retrieval model for mr. right to unify features across modalities.,ReSolved,https://export.arxiv.org/pdf/2209.13764v1.pdf
836,252567884,Mr. Right: Multimodal Retrieval on Representation of ImaGe witH Text,conclusion,"compared to the previous text and image retrieval frameworks, multimodal retrieval shows improvements on different queries and points out the balance between modalities.",ReSolved,https://export.arxiv.org/pdf/2209.13764v1.pdf
837,252567884,Mr. Right: Multimodal Retrieval on Representation of ImaGe witH Text,conclusion,"however, current multimodal models still have a significant gap to human performance, showing the potential of mr. right as a challenge in multimodal retrieval.",Finding,https://export.arxiv.org/pdf/2209.13764v1.pdf
838,252567884,Mr. Right: Multimodal Retrieval on Representation of ImaGe witH Text,conclusion,we believe mr. right can breathe new insights into information retrieval for more robust retrieval systems.,Finding,https://export.arxiv.org/pdf/2209.13764v1.pdf
839,252567884,Mr. Right: Multimodal Retrieval on Representation of ImaGe witH Text,limitations and future work,"in mr. right, we only consider text-based queries, which may limit the search modalities from users.",Finding,https://export.arxiv.org/pdf/2209.13764v1.pdf
840,252567884,Mr. Right: Multimodal Retrieval on Representation of ImaGe witH Text,limitations and future work,"we can expand our dataset with additional domain queries and documents such as images, audio, and video.",Finding,https://export.arxiv.org/pdf/2209.13764v1.pdf
841,252567884,Mr. Right: Multimodal Retrieval on Representation of ImaGe witH Text,limitations and future work,"further, mr. right focuses on the materials in wikipedia.",Neutral,https://export.arxiv.org/pdf/2209.13764v1.pdf
842,252567884,Mr. Right: Multimodal Retrieval on Representation of ImaGe witH Text,limitations and future work,"we can explore other sources such as news, blogs, or commercial websites.",Finding,https://export.arxiv.org/pdf/2209.13764v1.pdf
843,252567884,Mr. Right: Multimodal Retrieval on Representation of ImaGe witH Text,limitations and future work,"mr. right is a preliminary attempt to explore multimodal retrieval, and there are still challenges we need to analyze and study in future work.",Finding,https://export.arxiv.org/pdf/2209.13764v1.pdf
844,248987232,Domain Adaptation for Memory-Efficient Dense Retrieval,conclusion,"supervised dense compression algorithms have been popular and effective in-domain in recent times, however can have difficulties to generalize well to unseen domains.",Neutral,https://arxiv.org/pdf/2205.11498v1.pdf
845,248987232,Domain Adaptation for Memory-Efficient Dense Retrieval,conclusion,"the algorithms are memory efficient, but lack in performance when evaluated in specialized domains which contain no training data.",Neutral,https://arxiv.org/pdf/2205.11498v1.pdf
846,248987232,Domain Adaptation for Memory-Efficient Dense Retrieval,conclusion,"in order to adapt these compression algorithms under severe domain shifts, in this paper we propose a solution to jointly optimize domainadaption algorithms along with vector compression.",ReSolved,https://arxiv.org/pdf/2205.11498v1.pdf
847,248987232,Domain Adaptation for Memory-Efficient Dense Retrieval,conclusion,"the recent technique, gpl in combination with bpr and jpq provide a boost of 19.3 and 11.6 ndcg@10 points respectively.",ReSolved,https://arxiv.org/pdf/2205.11498v1.pdf
848,248987232,Domain Adaptation for Memory-Efficient Dense Retrieval,limitations and future work,even though we find the gpl technique to provide a boost with memory compressed models: bpr and jpq.,Neutral,https://arxiv.org/pdf/2205.11498v1.pdf
849,248987232,Domain Adaptation for Memory-Efficient Dense Retrieval,limitations and future work,"our work has a few limitations which we briefly mention them below and for future work: different compression algorithms: in our work, we considered jpq and bpr due to its popularity and effectiveness shown in our preliminary results.",Finding,https://arxiv.org/pdf/2205.11498v1.pdf
850,248987232,Domain Adaptation for Memory-Efficient Dense Retrieval,limitations and future work,"in future, we can work on extending our methods to more recent memory compression algorithms such as repconc (zhan et al., 2022).better backbone models: we suspect the performances on the beir can further improved with stronger backbone models in comparison with tas-b. due to the model agnostic nature of our method, we can easily extend our work to different state-ofthe-art dense retrievers in the upcoming future.requires separate models: bpr and jpq both require training separate models for each domain or task with our technique.",Finding,https://arxiv.org/pdf/2205.11498v1.pdf
851,248987232,Domain Adaptation for Memory-Efficient Dense Retrieval,limitations and future work,"this can be quite cumbersome for practical use-cases involving several hundreds of domains or retrieval tasks, for which one would need to train multiple models.compute intensive: our method gpl is compute intensive: (1) for bpr+gpl, every dense retriever requires to separately compute embeddings for the whole corpus for hard-negative mining.(2) cross-encoder teacher model although very effective, slows down the training significantly as required to label during training.",Finding,https://arxiv.org/pdf/2205.11498v1.pdf
852,248987232,Domain Adaptation for Memory-Efficient Dense Retrieval,limitations and future work,"in future, we can explore efficient and faster teachers instead of cross-encoders for gpl such as colbert (khattab and zaharia, 2020) or tilde (zhuang and zuccon, 2021)",Finding,https://arxiv.org/pdf/2205.11498v1.pdf
853,225039884,On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries,conclusion,"we introduce squall, the first large-scale semantic parsing dataset with both hand-produced target logical forms and manually-derived lexical alignments between questions and sql queries.",ReSolved,https://www.aclweb.org/anthology/2020.findings-emnlp.167.pdf
854,225039884,On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries,conclusion,our dataset enables finer-grained supervision than existing datasets have previously supported.,ReSolved,https://www.aclweb.org/anthology/2020.findings-emnlp.167.pdf
855,225039884,On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries,conclusion,we incorporate the alignments into encoder-decoder-based neural models through supervised attention and an auxiliary task of column prediction.,ReSolved,https://www.aclweb.org/anthology/2020.findings-emnlp.167.pdf
856,225039884,On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries,conclusion,experiments confirm our intuition that finer-grained supervision is helpful to model training.,ReSolved,https://www.aclweb.org/anthology/2020.findings-emnlp.167.pdf
857,225039884,On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries,conclusion,our oracle studies also show that there is large unrealized further potential for our annotations.,Finding,https://www.aclweb.org/anthology/2020.findings-emnlp.167.pdf
858,225039884,On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries,conclusion,"thus, it remains an exciting challenge for future research to use our lexical alignment annotations more effectively.",Finding,https://www.aclweb.org/anthology/2020.findings-emnlp.167.pdf
859,225039884,On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries,conclusion,our annotation cost analysis shows that collecting additional lexical alignments is more costeffective for improving model accuracy than having only logical forms.,ReSolved,https://www.aclweb.org/anthology/2020.findings-emnlp.167.pdf
860,225039884,On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries,conclusion,we hope that our findings will help future dataset design decisions and extensions of other existing datasets.,ReSolved,https://www.aclweb.org/anthology/2020.findings-emnlp.167.pdf
861,225039884,On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries,conclusion,one potential future direction is to further investigate the utility of lexical alignments in a cross-dataset/domain evaluation setting,Finding,https://www.aclweb.org/anthology/2020.findings-emnlp.167.pdf
862,250048838,MVP: Multi-task Supervised Pre-training for Natural Language Generation,conclusion,"in this paper, we present multi-task supervised pre-training (mvp) for natural language generation.",ReSolved,https://export.arxiv.org/pdf/2206.12131v3.pdf
863,250048838,MVP: Multi-task Supervised Pre-training for Natural Language Generation,conclusion,"firstly, we collect a large-scale nlg corpus, mvpcorpus, from 77 datasets over 11 diverse nlg tasks.",ReSolved,https://export.arxiv.org/pdf/2206.12131v3.pdf
864,250048838,MVP: Multi-task Supervised Pre-training for Natural Language Generation,conclusion,"after converting various nlg tasks into a unified text-to-text format, we propose multi-task supervised pre-training to learn an effective and general model mvp with task-specific prompts for nlg tasks.",ReSolved,https://export.arxiv.org/pdf/2206.12131v3.pdf
865,250048838,MVP: Multi-task Supervised Pre-training for Natural Language Generation,conclusion,extensive experiments have demonstrated that: (1) supervised pre-training is beneficial for nlg tasks as an effective solution.,ReSolved,https://export.arxiv.org/pdf/2206.12131v3.pdf
866,235125947,Fact-driven Logical Reasoning,conclusion,"in this work, we propose a novel method named focal reasoner for logical reasoning in the machine reading comprehension task.",ReSolved,https://arxiv.org/pdf/2105.10334v1.pdf
867,235125947,Fact-driven Logical Reasoning,conclusion,"our method not only better uncovers the logical structures within the context, which can be a general method for other sophisticated reasoning tasks but also better captures the logical interactions between context and options.",ReSolved,https://arxiv.org/pdf/2105.10334v1.pdf
868,235125947,Fact-driven Logical Reasoning,conclusion,the experimental results verify the effectiveness of our method.,ReSolved,https://arxiv.org/pdf/2105.10334v1.pdf
869,235125947,Fact-driven Logical Reasoning,conclusion,"in the future, we intend to design more elaborate mechanisms to cope with different question types and logical types as well as combine the symbolic and neural approaches.",Finding,https://arxiv.org/pdf/2105.10334v1.pdf
870,218470415,Self-supervised Knowledge Triplet Learning for Zero-shot Question Answering,conclusion,"in this work, we propose a new framework of knowledge triplet learning over knowledge graphs.",ReSolved,https://arxiv.org/pdf/2005.00316v1.pdf
871,218470415,Self-supervised Knowledge Triplet Learning for Zero-shot Question Answering,conclusion,"we show learning all three possible functions, f r ,f h , and f t helps the model to perform zero-shot multiple-choice question answering.",ReSolved,https://arxiv.org/pdf/2005.00316v1.pdf
872,218470415,Self-supervised Knowledge Triplet Learning for Zero-shot Question Answering,conclusion,we learn from the atomic knowledge graph and evaluate our framework on the socialiqa dataset.,ReSolved,https://arxiv.org/pdf/2005.00316v1.pdf
873,218470415,Self-supervised Knowledge Triplet Learning for Zero-shot Question Answering,conclusion,our framework achieves state-of-the-art in the zero-shot question answering task and sets a strong baseline in the few-shot question answering task.,ReSolved,https://arxiv.org/pdf/2005.00316v1.pdf
874,237263476,CommonsenseQA 2.0: Exposing the Limits of AI through Gamification,conclusion,"in this work, we propose gamification as a general framework for creating diverse and challenging nlu benchmarks.",ReSolved,https://arxiv.org/pdf/2201.05320v1.pdf
875,237263476,CommonsenseQA 2.0: Exposing the Limits of AI through Gamification,conclusion,"we use this framework to collect csqa2, a new benchmark that contains 14,343",ReSolved,https://arxiv.org/pdf/2201.05320v1.pdf
876,237263476,CommonsenseQA 2.0: Exposing the Limits of AI through Gamification,conclusion,"we perform a detailed analysis of csqa2, which elucidates the unique properties of our dataset, and thoroughly evaluate on a strong suite of baselines.",ReSolved,https://arxiv.org/pdf/2201.05320v1.pdf
877,237263476,CommonsenseQA 2.0: Exposing the Limits of AI through Gamification,conclusion,"we find that the best model, unicorn-11b, achieves an accuracy of 70.2%, dozens of points lower than human accuracy.",ReSolved,https://arxiv.org/pdf/2201.05320v1.pdf
878,237263476,CommonsenseQA 2.0: Exposing the Limits of AI through Gamification,conclusion,we argue that gamification is a promising approach for creating challenge sets that expose the weaknesses of current state-of-the-art models.,ReSolved,https://arxiv.org/pdf/2201.05320v1.pdf
879,249890380,KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Few-Shot NLP,conclusion and future work,this paper explores multi-task learning paradigms at a massive scale for data augmentation in fewshot language learning for the first time.,ReSolved,https://export.arxiv.org/pdf/2206.10265v1.pdf
880,249890380,KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Few-Shot NLP,conclusion and future work,"we demonstrate that the proposed knowledge mixture training enables pre-trained language models the capability of generating proper synthetic instances from scratch for complicated tasks (i.e., the data sample has long sequences or multiple sentences).",ReSolved,https://export.arxiv.org/pdf/2206.10265v1.pdf
881,249890380,KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Few-Shot NLP,conclusion and future work,"experiments verified the effectiveness of our knowda, and knowda outperforms state-of-the-art data augmentation approaches on well-established benchmarks superglue, conll'03, and wikiann in the few-shot setting.",ReSolved,https://export.arxiv.org/pdf/2206.10265v1.pdf
882,249890380,KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Few-Shot NLP,conclusion and future work,we also perform ablation studies indicating the importance of including demonstrations and the impact of different keys.,ReSolved,https://export.arxiv.org/pdf/2206.10265v1.pdf
883,249890380,KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Few-Shot NLP,conclusion and future work,"moreover, increasing the size of multi-task scaling and investigating more advanced training objectives for data augmentation is still a promising direction worthy of long-term exploration.",Finding,https://export.arxiv.org/pdf/2206.10265v1.pdf
884,245616876,Using Bloom's Taxonomy to Classify Question Complexity,conclusion and future work,we have shown that bloom's revised taxonomy can be transferred from pedagogy to qa systems.,ReSolved,https://www.aclanthology.org/2021.icnlsp-1.34.pdf
885,245616876,Using Bloom's Taxonomy to Classify Question Complexity,conclusion and future work,"the diagonal of the matrix is a determinant for defining complex questions, ranging from simple questions in the upper left to complex questions on the bottom right.",Neutral,https://www.aclanthology.org/2021.icnlsp-1.34.pdf
886,245616876,Using Bloom's Taxonomy to Classify Question Complexity,conclusion and future work,"for the proof of concept, we added pos tags to the questions as syntactic information to train a domain-independent classifier for question complexity.",ReSolved,https://www.aclanthology.org/2021.icnlsp-1.34.pdf
887,245616876,Using Bloom's Taxonomy to Classify Question Complexity,conclusion and future work,"we argued that question words also contribute to complexity, so they were not transformed.",ReSolved,https://www.aclanthology.org/2021.icnlsp-1.34.pdf
888,245616876,Using Bloom's Taxonomy to Classify Question Complexity,conclusion and future work,"although the unequal distribution of the training data only allowed a binary classification for two representative classes a1 and d3, the classifier already provides good results for computing question complexity.",ReSolved,https://www.aclanthology.org/2021.icnlsp-1.34.pdf
889,232147859,Semantic Models for the First-stage Retrieval: A Comprehensive Review,conclusion,"the purpose of this survey is to summarize the current research status on semantic retrieval models, analyze existing methodologies, and gain some insights for future development.",ReSolved,https://arxiv.org/pdf/2103.04831v4.pdf
890,232147859,Semantic Models for the First-stage Retrieval: A Comprehensive Review,conclusion,"it includes a brief review of early semantic retrieval methods, a detailed description of recent neural semantic retrieval methods and the connection between them.",ReSolved,https://arxiv.org/pdf/2103.04831v4.pdf
891,232147859,Semantic Models for the First-stage Retrieval: A Comprehensive Review,conclusion,"specially, we pay attention to neural semantic retrieval methods, and review them from three major paradigms, including sparse retrieval methods, dense retrieval methods and hybrid retrieval methods.",ReSolved,https://arxiv.org/pdf/2103.04831v4.pdf
892,232147859,Semantic Models for the First-stage Retrieval: A Comprehensive Review,conclusion,"we also refer to key topics about neural semantic retrieval models learning, such as loss functions and negative sampling strategies.",ReSolved,https://arxiv.org/pdf/2103.04831v4.pdf
893,232147859,Semantic Models for the First-stage Retrieval: A Comprehensive Review,conclusion,"in addition, we discuss several challenges and promising directions that are important for future researches.",Finding,https://arxiv.org/pdf/2103.04831v4.pdf
894,232147859,Semantic Models for the First-stage Retrieval: A Comprehensive Review,conclusion,we look forward to working with the community on these issues.,Finding,https://arxiv.org/pdf/2103.04831v4.pdf
895,222141025,PROVER: Proof Generation for Interpretable Reasoning over Rules,conclusion,"we introduce prover, an interpretable joint model that answers binary questions over natural language rule-bases and generates corresponding proofs.",ReSolved,https://arxiv.org/pdf/2010.02830v1.pdf
896,222141025,PROVER: Proof Generation for Interpretable Reasoning over Rules,conclusion,the proofs are generated through the node and edge modules of the model in the presence of multiple global constraints during training and ilp inference.,ReSolved,https://arxiv.org/pdf/2010.02830v1.pdf
897,222141025,PROVER: Proof Generation for Interpretable Reasoning over Rules,conclusion,our model improves state-of-theart qa accuracy in the zero-shot scenario by 6% and generates proofs accurately.,ReSolved,https://arxiv.org/pdf/2010.02830v1.pdf
898,222141025,PROVER: Proof Generation for Interpretable Reasoning over Rules,conclusion,prover also generalizes much better to higher depth questions with up to 15% absolute improvement in qa performance over ruletakers.,ReSolved,https://arxiv.org/pdf/2010.02830v1.pdf
899,222141025,PROVER: Proof Generation for Interpretable Reasoning over Rules,conclusion,"prover's modeling is relatively generic, and similar proof generation methods can be explored in traditional multi-hop qa tasks.",Neutral,https://arxiv.org/pdf/2010.02830v1.pdf
900,222141025,PROVER: Proof Generation for Interpretable Reasoning over Rules,conclusion,prover can also be a helpful aid to formal reasoners in scenarios where rules are fuzzy and creating rule-bases in a formal language is tedious or infeasible.,Neutral,https://arxiv.org/pdf/2010.02830v1.pdf
901,258615731,Active Retrieval Augmented Generation,conclusion,"to aid long-form generation with retrieval augmentation, we propose an active retrieval augmented generation framework that decides when and what to retrieve during generation.",ReSolved,https://export.arxiv.org/pdf/2305.06983v1.pdf
902,258615731,Active Retrieval Augmented Generation,conclusion,we implement this framework with forward-looking active retrieval that iteratively uses the upcoming sentence to retrieve relevant information if it contains lowconfidence tokens and regenerates the next sentence.,ReSolved,https://export.arxiv.org/pdf/2305.06983v1.pdf
903,258615731,Active Retrieval Augmented Generation,conclusion,experimental results on 4 tasks/datasets demonstrate the effectiveness of our methods.,ReSolved,https://export.arxiv.org/pdf/2305.06983v1.pdf
904,258615731,Active Retrieval Augmented Generation,conclusion,future directions include better alternatives for active retrieval and developing lm architectures for efficient active retrieval augmentation.,Finding,https://export.arxiv.org/pdf/2305.06983v1.pdf
905,258615731,Active Retrieval Augmented Generation,limitation,"we  krishna et al. (2021) such as difficulties of grounding generation in retrieval and evaluation, both single-time retrieval and flare did not provide significant gains over not using retrieval.",ReSolved,https://export.arxiv.org/pdf/2305.06983v1.pdf
906,258615731,Active Retrieval Augmented Generation,limitation,"from an engineering perspective, interleaving generation with retrieval with a naive implementation increases both overheads and the cost of generation.",ReSolved,https://export.arxiv.org/pdf/2305.06983v1.pdf
907,258615731,Active Retrieval Augmented Generation,limitation,the lm needs to be activated multiple times (once for each retrieval) and a cachingfree implementation will also require recomputing the previous activation each time after a retrieval.,Neutral,https://export.arxiv.org/pdf/2305.06983v1.pdf
908,258615731,Active Retrieval Augmented Generation,limitation,this issue can be potentially alleviated with special architectural designs that encode the retrieved documents d qt and the input/generation (x/y <t ) independently.,Finding,https://export.arxiv.org/pdf/2305.06983v1.pdf
909,258841283,Query Rewriting for Retrieval-Augmented Large Language Models,conclusion,"this paper introduces rewrite-retrieve-read pipeline, where a query rewriting step is added for retrieval augmentation.",ReSolved,https://export.arxiv.org/pdf/2305.14283v1.pdf
910,258841283,Query Rewriting for Retrieval-Augmented Large Language Models,conclusion,this approach is applicable for adopting a frozen large language model as the reader and a real-time web search engine as the retriever.,ReSolved,https://export.arxiv.org/pdf/2305.14283v1.pdf
911,258841283,Query Rewriting for Retrieval-Augmented Large Language Models,conclusion,"further, we propose to apply a tuneable language model the rewriter, which can be trained to cater to the frozen retriever and reader.",ReSolved,https://export.arxiv.org/pdf/2305.14283v1.pdf
912,258841283,Query Rewriting for Retrieval-Augmented Large Language Models,conclusion,evaluation   on open-domian qa and multi-choice qa shows the effectiveness of query rewriting.,ReSolved,https://export.arxiv.org/pdf/2305.14283v1.pdf
913,258841283,Query Rewriting for Retrieval-Augmented Large Language Models,conclusion,our work proposes novel retrieval-augmented llm framework and provides new baselines for integrating trainable module into black-box llms.,ReSolved,https://export.arxiv.org/pdf/2305.14283v1.pdf
914,257636839,Reflexion: an autonomous agent with dynamic memory and self-reflection,limitations of reflexion,reflexion relies on the emergent property of self-reflection that is present in several large language models.,Neutral,https://export.arxiv.org/pdf/2303.11366v1.pdf
915,257636839,Reflexion: an autonomous agent with dynamic memory and self-reflection,limitations of reflexion,"in this study, we used gpt-3.0 and gpt 3.5 to power a react agent (yao et al., 2023) to learn from its past mistakes.",ReSolved,https://export.arxiv.org/pdf/2303.11366v1.pdf
916,257636839,Reflexion: an autonomous agent with dynamic memory and self-reflection,limitations of reflexion,"while reflexion enabled the agent to discover new problem-solving techniques in alfworld decision-making tasks and hotpotqa knowledge-intensive tasks, we observed a shortcoming in its ability to improve on its baseline performance in a third benchmark, webshop (yao et al., rint).webshop is a text-based problem-solving benchmark that tests natural language agents to navigate an e-commerce website to find and purchase products given requests from a client.",ReSolved,https://export.arxiv.org/pdf/2303.11366v1.pdf
917,257636839,Reflexion: an autonomous agent with dynamic memory and self-reflection,limitations of reflexion,"we tested the agent in 100 environments, giving the agent two few-shot examples of successful webshop trajectories using the react problem-solving technique.",ReSolved,https://export.arxiv.org/pdf/2303.11366v1.pdf
918,257636839,Reflexion: an autonomous agent with dynamic memory and self-reflection,limitations of reflexion,"however, after only 4 trials, we terminated the baseline and reflexion runs as the agent did not show improvement in accuracy  and was not generating helpful, intuitive self-reflections.",Finding,https://export.arxiv.org/pdf/2303.11366v1.pdf
919,257636839,Reflexion: an autonomous agent with dynamic memory and self-reflection,limitations of reflexion,"the agent achieved a 33% 34% accuracy improvement in the baseline run and a mere 33% 35% accuracy improvement in the reflexion run, which suggests that the agent only successfully completed 1 additional task relative to the baseline agent's performance.however, after analyzing the failed trajectories, we noted that the chance of a successful item purchase for an agent in a webshop environment was not necessarily dependent on the agent's ability to plan and execute a correct sequence of actions, but rather on the quality of the webshop search engine's results.",Neutral,https://export.arxiv.org/pdf/2303.11366v1.pdf
920,257636839,Reflexion: an autonomous agent with dynamic memory and self-reflection,limitations of reflexion,"this observation may not be a direct limitation of the reflexion approach, but it highlights the ability of a reflexion agent to optimize reasoning trace and action execution but not complete awareness of the quality of the tools that it may be using.",Finding,https://export.arxiv.org/pdf/2303.11366v1.pdf
921,257636839,Reflexion: an autonomous agent with dynamic memory and self-reflection,conclusion,we proposed an approach that allows natural language agents to learn from past mistakes and redirect future decisions in planning sequences which removes the human trainer in a human-in-the-middle approach.,ReSolved,https://export.arxiv.org/pdf/2303.11366v1.pdf
922,257636839,Reflexion: an autonomous agent with dynamic memory and self-reflection,conclusion,we demonstrated learning curves on the alfworld and hotpotqa benchmarks that significantly outperform base react agents.,ReSolved,https://export.arxiv.org/pdf/2303.11366v1.pdf
923,257636839,Reflexion: an autonomous agent with dynamic memory and self-reflection,conclusion,"in addition, we include an inconclusive attempt to improve performance on the webshop benchmark and provide a discussion that highlights a few limitations of this approach.",Finding,https://export.arxiv.org/pdf/2303.11366v1.pdf
924,257636839,Reflexion: an autonomous agent with dynamic memory and self-reflection,conclusion,reflexion is a highly applicable method to improve performance between trials on decision-making and knowledge-intensive tasks due to its sole dependence on a binary reward model.,Neutral,https://export.arxiv.org/pdf/2303.11366v1.pdf
925,257636839,Reflexion: an autonomous agent with dynamic memory and self-reflection,conclusion,"in the alfworld and hotpotqa experiments, we constrained the reward model to imitate environments in which informative reward models may be difficult to design or compute.",Neutral,https://export.arxiv.org/pdf/2303.11366v1.pdf
926,257636839,Reflexion: an autonomous agent with dynamic memory and self-reflection,conclusion,"we encourage others to apply reflexion to more complex tasks in which the agent must learn to develop new ideas, explore larger unseen state spaces, and form more accurate plans of action through its experiences in past environments.",Finding,https://export.arxiv.org/pdf/2303.11366v1.pdf
927,243865235,Diagnosing the First-Order Logical Reasoning Ability Through LogicNLI,conclusion,"in this paper, we propose a diagnostic method to diagnose lms' fol reasoning ability.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.303.pdf
928,243865235,Diagnosing the First-Order Logical Reasoning Ability Through LogicNLI,conclusion,"this method introduces a novel proposed benchmark, logicnli, that disentangles the fol reasoning from commonsense inference.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.303.pdf
929,243865235,Diagnosing the First-Order Logical Reasoning Ability Through LogicNLI,conclusion,"specifically, it includes four evaluations to measure the fol reasoning ability from different perspectives.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.303.pdf
930,243865235,Diagnosing the First-Order Logical Reasoning Ability Through LogicNLI,conclusion,"results on three lms show that although some lms (roberta) own a certain interpretable fol reasoning ability, they still cannot make sensible fol reasoning like humans.",Finding,https://www.aclanthology.org/2021.emnlp-main.303.pdf
931,243865235,Diagnosing the First-Order Logical Reasoning Ability Through LogicNLI,conclusion,detailed analysis motivates us to enhance specific reasoning abilities or explore new methods to make neural models understand more refined logic.,Finding,https://www.aclanthology.org/2021.emnlp-main.303.pdf
932,258436694,Explain-able Conversational Question Answering over Heterogeneous Sources via Iterative Graph Neural Networks,conclusion,there are three main takeaways for a broader audience from this work.,ReSolved,https://export.arxiv.org/pdf/2305.01548v1.pdf
933,258436694,Explain-able Conversational Question Answering over Heterogeneous Sources via Iterative Graph Neural Networks,conclusion,"first, at a time when large language models (llms) like chat-gpt are used as a one-stop shop for most nlp tasks including convqa, our method explaignn stands out by providing traceable provenance of its answer predictions.",ReSolved,https://export.arxiv.org/pdf/2305.01548v1.pdf
934,258436694,Explain-able Conversational Question Answering over Heterogeneous Sources via Iterative Graph Neural Networks,conclusion,"next, explainability for graph neural networks is an unsolved concern: we propose an iterative model that sequentially reduces the graph size as a medium for offering causal insights into the prediction process.",ReSolved,https://export.arxiv.org/pdf/2305.01548v1.pdf
935,258436694,Explain-able Conversational Question Answering over Heterogeneous Sources via Iterative Graph Neural Networks,conclusion,"finally, for several systems in ir and nlp, performance, efficiency, and explainability are seen as trade-offs.",Neutral,https://export.arxiv.org/pdf/2305.01548v1.pdf
936,258436694,Explain-able Conversational Question Answering over Heterogeneous Sources via Iterative Graph Neural Networks,conclusion,"through our highly configurable solution, we show that in certain use cases, it is actually possible to find configurations that lie at the sweet spots of all the three factors.",ReSolved,https://export.arxiv.org/pdf/2305.01548v1.pdf
937,237258250,Teach Me to Explain: A Review of Datasets for Explainable Natural Language Processing,conclusions,"we have presented a review of existing datasets for exnlp research, highlighted discrepancies in data collection that can have downstream modeling effects, and synthesized the literature both inside and outside exnlp into a set of recommendations for future data collection.",ReSolved,https://arxiv.org/pdf/2102.12060v4.pdf
938,248780469,MULTIHIERTT: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data,limitations and future work,"although the proposed mt2net model outperforms other baseline models, it still performs significantly worse than human experts, which reflects the challenge of multihiertt.",Finding,https://www.aclanthology.org/2022.acl-long.454.pdf
939,248780469,MULTIHIERTT: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data,limitations and future work,"primarily, we find that models do not perform well on certain types of questions: 1) questions requiring reasoning across multiple tables; 2) questions requiring multi-step reasoning; 3) questions requiring reasoning over tables with complex hierarchical structures; and 4) questions requiring external financial knowledge.to deal with these challenges, we believe that four main directions of work may be workable: 1) designing a specialized module to handle multitable reasoning; 2) decomposing a complex question requiring multi-step reasoning into several simpler sub-questions that qa models can handle (perez et al., 2020;chen et al., 2020); 3) applying a more advanced table-encoding method.",Finding,https://www.aclanthology.org/2022.acl-long.454.pdf
940,248780469,MULTIHIERTT: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data,limitations and future work,"for example, a pre-trained model with specialized table structure-aware mechanisms cheng et al., 2021a;yang et al., 2022) can be utilized in the facts retrieving module to better understand hierarchical tables; and 4) leveraging structured knowledge (xie et al., 2022) to inject external financial knowledge to models.",Neutral,https://www.aclanthology.org/2022.acl-long.454.pdf
941,248780469,MULTIHIERTT: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data,conclusion,"we have proposed multihiertt, a new largescale qa dataset that aims to solve complicated qa tasks that require numerical reasoning over documents containing multiple hierarchical tables and paragraphs.",ReSolved,https://www.aclanthology.org/2022.acl-long.454.pdf
942,248780469,MULTIHIERTT: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data,conclusion,"to address the challenge of multi-hiertt, we introduce a baseline framework named mt2net.",ReSolved,https://www.aclanthology.org/2022.acl-long.454.pdf
943,248780469,MULTIHIERTT: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data,conclusion,the framework first retrieves supporting facts from financial reports and then generates executable reasoning programs to answer the question.,ReSolved,https://www.aclanthology.org/2022.acl-long.454.pdf
944,248780469,MULTIHIERTT: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data,conclusion,the results of comprehensive experiments showed that current qa models (best f 1 : 38.43%) still lag far behind the human expert performance (f 1 : 87.03%).,Finding,https://www.aclanthology.org/2022.acl-long.454.pdf
945,248780469,MULTIHIERTT: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data,conclusion,this motivates further research on developing qa models for such complex hybrid data with multiple hierarchical tables.,Finding,https://www.aclanthology.org/2022.acl-long.454.pdf
946,249062828,ROBUSTLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners,conclusion,"in this paper, we proposed robustlr, a diagnostic benchmark to test the logical robustness of deductive reasoning models.",ReSolved,https://export.arxiv.org/pdf/2205.12598v2.pdf
947,249062828,ROBUSTLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners,conclusion,"in robustlr, we propose two evaluation sets, logical contrast and logical equivalence, each probing different logical reasoning abilities.",ReSolved,https://export.arxiv.org/pdf/2205.12598v2.pdf
948,249062828,ROBUSTLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners,conclusion,"overall, we find that fine-tuning lms such as roberta and t5 on deductive reasoning datasets is not sufficient to learn the semantics of the logical operators conjunction, disjunction, and negation.",Finding,https://export.arxiv.org/pdf/2205.12598v2.pdf
949,249062828,ROBUSTLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners,conclusion,"although well-aligned training dataset improves model performance, the models still find it challenging to understand negations, both in logical contrast and logical equivalence sets.",Finding,https://export.arxiv.org/pdf/2205.12598v2.pdf
950,249062828,ROBUSTLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners,conclusion,"we demonstrate some interesting shortcoming of lms designed for logical reasoning, that can eventually enable building better reasoning models.",ReSolved,https://export.arxiv.org/pdf/2205.12598v2.pdf
951,249062828,ROBUSTLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners,limitation,a key limitation of the work is the synthetic nature of the dataset.,Finding,https://export.arxiv.org/pdf/2205.12598v2.pdf
952,249062828,ROBUSTLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners,limitation,"while it is ideal to explore more natural theories, it makes the systematic logical perturbation process very challenging.",Neutral,https://export.arxiv.org/pdf/2205.12598v2.pdf
953,249062828,ROBUSTLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners,limitation,"thus, in this work, we resort to using synthetic datasets, but aim to bridge this gap in future works.",ReSolved,https://export.arxiv.org/pdf/2205.12598v2.pdf
954,249062828,ROBUSTLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners,limitation,another limitation is the complexity of the datasets we explore.,Finding,https://export.arxiv.org/pdf/2205.12598v2.pdf
955,249062828,ROBUSTLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners,limitation,we use fairly simple logical rules and constructs for robustlr.,Neutral,https://export.arxiv.org/pdf/2205.12598v2.pdf
956,249062828,ROBUSTLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners,limitation,some more complex forms of logical reasoning-based theories can potentially reveal even more limitations of deductive reasoning models.,Finding,https://export.arxiv.org/pdf/2205.12598v2.pdf
957,249062828,ROBUSTLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners,limitation,another interesting aspect we do not explore in this scope is potential techniques to improve these models on deductive reasoning tasks.,Finding,https://export.arxiv.org/pdf/2205.12598v2.pdf
958,249062828,ROBUSTLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners,limitation,"this might involve trying different inductive biases in the form of architectural designs, more specialized datasets, etc.",Finding,https://export.arxiv.org/pdf/2205.12598v2.pdf
959,244119706,Enhancing Dual-Encoders with Question and Answer Cross-Embeddings for Answer Retrieval,conclusion,"in this work, we propose a framework that enhances dual-encoders with cross-embeddings for answer retrieval.",ReSolved,https://arxiv.org/pdf/2206.02978v1.pdf
960,244119706,Enhancing Dual-Encoders with Question and Answer Cross-Embeddings for Answer Retrieval,conclusion,a novel geometry alignment mechanism is introduced to align the geometry of dual-encoders with cross-embeddings.,ReSolved,https://arxiv.org/pdf/2206.02978v1.pdf
961,244119706,Enhancing Dual-Encoders with Question and Answer Cross-Embeddings for Answer Retrieval,conclusion,extensive experimental results show that our method significantly improves dual-encoders model and outperforms the state-of-the-art method on multiple answer retrieval datasets.,ReSolved,https://arxiv.org/pdf/2206.02978v1.pdf
962,186346769,The Connection Commonalities in the Mathematical Content of Lesson Sequences,conclusion,the comparisons of the individual teachers' practices revealed how one particular teacher was noteworthy.,ReSolved,
963,186346769,The Connection Commonalities in the Mathematical Content of Lesson Sequences,conclusion,"according to the interview data collected from all four teachers, notably, only x-t2 mentioned the importance of making the relevant connections in his mathematics teaching.",ReSolved,
964,186346769,The Connection Commonalities in the Mathematical Content of Lesson Sequences,conclusion,"from the interview, x-t2 stressed that it was essential for all his students to see the connections of what reallife examples can bring to the topic of statistics.",Neutral,
965,186346769,The Connection Commonalities in the Mathematical Content of Lesson Sequences,conclusion,"at the same time, he wanted his students to enjoy and learn mathematics from the enthusiasm he brought into his mathematics teaching.",Neutral,
966,186346769,The Connection Commonalities in the Mathematical Content of Lesson Sequences,conclusion,"from the observations made, the same level of technique (the technique used to implement making connections problems) made by x-t2 was not detected in the lessons of the other three brunei teachers.",Neutral,
967,186346769,The Connection Commonalities in the Mathematical Content of Lesson Sequences,conclusion,"then again, why is the least mathematically equipped teacher doing the most innovative teaching?",Finding,
968,186346769,The Connection Commonalities in the Mathematical Content of Lesson Sequences,conclusion,"a possible explanation that can be suggested is that, perhaps, since he did not have the relevant mathematical education background, he may have not seen the connection himself.",Finding,
969,186346769,The Connection Commonalities in the Mathematical Content of Lesson Sequences,conclusion,"we need to encourage teachers who are mathematical experts, not take for granted the connections that are obvious to them (and possibly, will be obvious to their students), and to include what x-t2 was doing, and to actually, very deliberately try to create the connections within and across their own lessons.",Finding,
970,248562643,The Unreliability of Explanations in Few-Shot In-Context Learning PREPRINT,conclusion,we have explored the capabilities of gpt-3 in using explanation in in-context learning for textual reasoning.,ReSolved,https://arxiv.org/pdf/2205.03401v1.pdf
971,248562643,The Unreliability of Explanations in Few-Shot In-Context Learning PREPRINT,conclusion,"through our experiments on two qa datasets and an nli dataset, we find that simply including explanations in the prompt does not always improve the performance of in-context learning.",ReSolved,https://arxiv.org/pdf/2205.03401v1.pdf
972,251280129,SPANDROP: Simple and Effective Counterfactual Learning for Long Sequences,conclusion,"in this paper, we presented spandrop, a simple and effective method for learning from long sequences, which ablates parts of the sequence at random to generate counterfactual data to distill the sparse supervision signal that is predictive of the desired output.",ReSolved,https://export.arxiv.org/pdf/2208.02169v1.pdf
973,251280129,SPANDROP: Simple and Effective Counterfactual Learning for Long Sequences,conclusion,"we show via theoretical analysis and carefully designed synthetic datasets that spandrop and its variant based on the beta-bernoulli distribution, beta-spandrop, help models achieve competitive performance with a fraction of the data by introducing diverse augmented training examples, and generalize better to previously unseen data.",ReSolved,https://export.arxiv.org/pdf/2208.02169v1.pdf
974,251280129,SPANDROP: Simple and Effective Counterfactual Learning for Long Sequences,conclusion,"our experiments on four real-world nlp datasets confirm these theoretical findings, and demonstrate span-drop's efficacy on strong neural models even when data is abundant.",ReSolved,https://export.arxiv.org/pdf/2208.02169v1.pdf
975,248377036,Evaluating Extrapolation Performance of Dense Retrieval,conclusions,"in this paper, we propose a simple yet effective method that evaluates the extrapolation performance of dr models, i.e., how dr models perform on queries that are distinct from the training queries.",ReSolved,https://arxiv.org/pdf/2204.11447v1.pdf
976,248377036,Evaluating Extrapolation Performance of Dense Retrieval,conclusions,"with the proposed evaluation method, we first revisit how existing dr models perform in the extrapolation regimes.",Neutral,https://arxiv.org/pdf/2204.11447v1.pdf
977,248377036,Evaluating Extrapolation Performance of Dense Retrieval,conclusions,results lead to several non-trivial findings that have been concealed by the existing evaluation protocol.,ReSolved,https://arxiv.org/pdf/2204.11447v1.pdf
978,248377036,Evaluating Extrapolation Performance of Dense Retrieval,conclusions,"concretely, dr is substantially more vulnerable to extrapolation than the interaction-based deep neural ranking models, and pretraining is a more effective method to improve the extrapolation ability of dr than finetuning techniques.",ReSolved,https://arxiv.org/pdf/2204.11447v1.pdf
979,248377036,Evaluating Extrapolation Performance of Dense Retrieval,conclusions,then we further interpret our extrapolation performance by investigating its relationship with the domain transfer ability.,Neutral,https://arxiv.org/pdf/2204.11447v1.pdf
980,248377036,Evaluating Extrapolation Performance of Dense Retrieval,conclusions,"results suggest that the extrapolation performance is a potential indicator of the domain transfer ability, further highlighting the feasibility of our methods to evaluate the generalization ability of dr models.",ReSolved,https://arxiv.org/pdf/2204.11447v1.pdf
981,248377036,Evaluating Extrapolation Performance of Dense Retrieval,conclusions,"although this paper focuses on evaluating how dr models extrapolate, the methodologies can also be used for other models in the future.",Finding,https://arxiv.org/pdf/2204.11447v1.pdf
982,252519203,Towards Faithful Model Explanation in NLP: A Survey,conclusion,"this survey provides an extensive tour of recent advances in nlp explainability, through the lens of faithfulness.",ReSolved,https://export.arxiv.org/pdf/2209.11326v2.pdf
983,252519203,Towards Faithful Model Explanation in NLP: A Survey,conclusion,"despite being a fundamental principle of model explanation methods, faithfulness does not have a well-established technical definition or evaluation framework.",Neutral,https://export.arxiv.org/pdf/2209.11326v2.pdf
984,252519203,Towards Faithful Model Explanation in NLP: A Survey,conclusion,"consequently, it is difficult to compare different methods in terms of faithfulness, and many of them do not report any quantitative faithfulness evaluation results.",Neutral,https://export.arxiv.org/pdf/2209.11326v2.pdf
985,211258645,Unsupervised Question Decomposition for Question Answering,conclusion,"we proposed an algorithm that decomposes questions without supervision, using 3 stages: (1) learning to decompose using pseudo-decompositions without supervision, (2) answering sub-questions with an off-the-shelf qa system, and (3) answering hard questions more accurately using sub-questions and their answers as additional input.",ReSolved,https://arxiv.org/pdf/2002.09758v1.pdf
986,211258645,Unsupervised Question Decomposition for Question Answering,conclusion,"when evaluated on hotpotqa, a standard benchmark for multihop qa, our approach significantly improved accuracy over an equivalent model that did not use decompositions.",ReSolved,https://arxiv.org/pdf/2002.09758v1.pdf
987,211258645,Unsupervised Question Decomposition for Question Answering,conclusion,"our approach relies only on the final answer as supervision but works as effectively as state-of-the-art methods that rely on strong supervision, such as supporting fact labels or example decompositions.",ReSolved,https://arxiv.org/pdf/2002.09758v1.pdf
988,211258645,Unsupervised Question Decomposition for Question Answering,conclusion,"qualitatively, we found that unsupervised decomposition resulted in fluent sub-questions whose answers often match the annotated supporting facts in hotpotqa.",ReSolved,https://arxiv.org/pdf/2002.09758v1.pdf
989,211258645,Unsupervised Question Decomposition for Question Answering,conclusion,"our unsupervised decompositions are largely extractive, which is effective for compositional, multi-hop questions but not all complex questions, showing room for future work.",Finding,https://arxiv.org/pdf/2002.09758v1.pdf
990,211258645,Unsupervised Question Decomposition for Question Answering,conclusion,"overall, this work opens up exciting avenues for leveraging methods in unsupervised learning and natural language generation to improve the interpretability and generalization of machine learning systems.",Neutral,https://arxiv.org/pdf/2002.09758v1.pdf
991,258556908,VCC: Scaling Transformers to 128K Tokens or More by Prioritizing Important Tokens,conclusions,we propose a vip-token centric sequence compression method to compress/decompress the input/output sequences of transformer layers thereby reducing the complexity dependency on the sequence length n without sacrificing the model accuracy.,ReSolved,https://export.arxiv.org/pdf/2305.04241v2.pdf
992,258556908,VCC: Scaling Transformers to 128K Tokens or More by Prioritizing Important Tokens,conclusions,"specifically, we design the compression our empirical evaluation shows that our method can be directly incorporated into existing pretrained models with some additional training.",ReSolved,https://export.arxiv.org/pdf/2305.04241v2.pdf
993,258556908,VCC: Scaling Transformers to 128K Tokens or More by Prioritizing Important Tokens,conclusions,"also, it often has much higher efficiency compared to baselines with the same sequence length while offering better or competitive model accuracy.",ReSolved,https://export.arxiv.org/pdf/2305.04241v2.pdf
994,258556908,VCC: Scaling Transformers to 128K Tokens or More by Prioritizing Important Tokens,conclusions,"for future work, we believe that extending our method to the decoder of the encoder-decoder models will further boost the efficiency of transformers while maintaining similar model performance.    ",Finding,https://export.arxiv.org/pdf/2305.04241v2.pdf
995,258556908,VCC: Scaling Transformers to 128K Tokens or More by Prioritizing Important Tokens,conclusions,we provide a table 4 of notations that are used for more than once so that the readers can refer to their definition easily.,Neutral,https://export.arxiv.org/pdf/2305.04241v2.pdf
996,250462558,PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search,discussion and conclusion,"while wic and english wsd rely exclusively on dictionaries (pilehvar and camacho-collados, 2019) to obtain word senses and example sentences, our data collection depends on wikipedia, wic, & nlp models and our annotation depends on experts.",Neutral,https://www.aclanthology.org/2023.eacl-main.1.pdf
997,250462558,PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search,limitations,"our dataset is currently limited to multi-word, english noun-phrases.",Finding,https://www.aclanthology.org/2023.eacl-main.1.pdf
998,250462558,PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search,limitations,"furthermore, it is expected to contain around a 5% error on pr-pass (i.e. the best human performance is 95% em).",Finding,https://www.aclanthology.org/2023.eacl-main.1.pdf
999,250462558,PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search,limitations,"on pr-page, there may be more than one correct target phrase; however, we only label one phrase as the correct answer per document.",Finding,https://www.aclanthology.org/2023.eacl-main.1.pdf
1000,250462558,PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search,limitations,we use only phrases that contain at least one wic word.,Finding,https://www.aclanthology.org/2023.eacl-main.1.pdf
1001,250462558,PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search,limitations,hyperparameters we train each bert-based classifier for a maximum of 100 epochs with early stopping monitored on validation accuracy (patience of 10 epochs).,Neutral,https://www.aclanthology.org/2023.eacl-main.1.pdf
1002,250462558,PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search,limitations,"we use a batch size of 200 and adam optimizer with learning rate α = 0.0001, β 1 = 0.9, β 2 = 0.999, and ϵ = 10 −8 .",Neutral,https://www.aclanthology.org/2023.eacl-main.1.pdf
1003,240288953,Answering Open-Domain Questions of Varying Reasoning Steps from Text,conclusion,"in this paper, we presented iterative retriever, reader, and reranker (irrr), a system that uses a single model to perform subtasks to answer open-domain questions of arbitrary reasoning steps.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.292.pdf
1004,240288953,Answering Open-Domain Questions of Varying Reasoning Steps from Text,conclusion,"irrr achieves competitive results on standard opendomain qa benchmarks, and establishes a strong baseline on b qa, the new unified benchmark we present, which features questions with mixed levels of complexity.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.292.pdf
1005,258841172,IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions,limitations,"the main limitation of ifqa dataset is that it only covers event-based questions, due to the nature of creating counterfactual presuppositions.",Finding,https://export.arxiv.org/pdf/2305.14010v1.pdf
1006,258841172,IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions,limitations,"therefore, our dataset is not intended for training general opendomain qa models or evaluate their capabilities.for data collection, we relied heavily on human annotators, both for question annotation and verification.",Finding,https://export.arxiv.org/pdf/2305.14010v1.pdf
1007,258841172,IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions,limitations,"despite our efforts to mitigate annotator bias by providing explicit instructions and examples and by sampling annotators from diverse populations, it is not possible to completely remove this bias.",Finding,https://export.arxiv.org/pdf/2305.14010v1.pdf
1008,258841172,IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions,limitations,"in addition, we use heuristic rules to select only a small portion of wikipedia passages and then present them to human annotators (as mentioned in section 3.1.1), which might lead to pattern-oriented bias in the annotated data.for evaluated models, large language models performance on our dataset may preserve biases learned from the web text during pre-training or and make biased judgments as a result.",Finding,https://export.arxiv.org/pdf/2305.14010v1.pdf
1009,233231436,AR-LSAT: Investigating Analytical Reasoning of Text,conclusion,"in this paper, we study the challenging task of analytical reasoning and introduce a dataset ar-lsat to facilitate research on analytical reasoning.",ReSolved,https://arxiv.org/pdf/2104.06598v2.pdf
1010,233231436,AR-LSAT: Investigating Analytical Reasoning of Text,conclusion,"we analyze the knowledge understanding and reasoning ability required for this task and present two basic approaches: a transformer-based approach and a logical-level reasoning framework, named analytical reasoning machine (arm).",ReSolved,https://arxiv.org/pdf/2104.06598v2.pdf
1011,233231436,AR-LSAT: Investigating Analytical Reasoning of Text,conclusion,"arm extracts symbolic knowledge, including participants, facts and rules mentioned in the context and extract logical functions from the rules.",ReSolved,https://arxiv.org/pdf/2104.06598v2.pdf
1012,233231436,AR-LSAT: Investigating Analytical Reasoning of Text,conclusion,"afterwards, it performs deep reasoning to find all the legitimate solutions to the problem posed and finally makes a prediction.",ReSolved,https://arxiv.org/pdf/2104.06598v2.pdf
1013,233231436,AR-LSAT: Investigating Analytical Reasoning of Text,conclusion,"arm sheds a light on the reasoning procedure for analytical reasoning, and each component can be further developed.",ReSolved,https://arxiv.org/pdf/2104.06598v2.pdf
1014,233231436,AR-LSAT: Investigating Analytical Reasoning of Text,conclusion,experiments show that this task is very challenging for current transformer-based pre-trained language models and arm outperforms them with better performance and interpretability.,ReSolved,https://arxiv.org/pdf/2104.06598v2.pdf
1015,233231436,AR-LSAT: Investigating Analytical Reasoning of Text,conclusion,further discussions are made to shed light on important future directions.,Neutral,https://arxiv.org/pdf/2104.06598v2.pdf
1016,222080412,KPQA: A Metric for Generative Question Answering Using Keyphrase Weights,conclusion,"in this paper, we create high-quality human judgments on two genqa datasets, ms-marco and avsd, and show that previous evaluation metrics are poorly correlated with human judgments in terms of the correctness of an answer.",ReSolved,https://www.aclweb.org/anthology/2021.naacl-main.170.pdf
1017,222080412,KPQA: A Metric for Generative Question Answering Using Keyphrase Weights,conclusion,"we propose kpqa-metric, which uses the pre-trained model that can predict the importance weights of words in answers to a given question to be integrated with existing metrics.",ReSolved,https://www.aclweb.org/anthology/2021.naacl-main.170.pdf
1018,222080412,KPQA: A Metric for Generative Question Answering Using Keyphrase Weights,conclusion,"our approach has a dramatically higher correlation with human judgments than existing metrics, showing that our model-based importance weighting is critical to measure the correctness of a generated answer in genqa.",ReSolved,https://www.aclweb.org/anthology/2021.naacl-main.170.pdf
1019,248157463,ASQA: Factoid Questions Meet Long-Form Answers,conclusion,"in contrast to existing datasets for long-form qa, asqa admits a clear notion of correctness that we use to define an overall metric of performance (dr).",ReSolved,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1020,248157463,ASQA: Factoid Questions Meet Long-Form Answers,conclusion,our empirical evaluations demonstrate that dr correlates well with the human judgment; and there is a large gap between human performance and the strong baselines.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1021,248157463,ASQA: Factoid Questions Meet Long-Form Answers,conclusion,"thus, we believe that asqa is an appealing task for the qa community.",Neutral,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1022,248157463,ASQA: Factoid Questions Meet Long-Form Answers,conclusion,our analysis suggests that strong performance on asqa is contingent upon both high-quality retrieval and summarization. these aspects constitute important directions for future work on asqa.,Finding,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1023,248157463,ASQA: Factoid Questions Meet Long-Form Answers,limitations,"we now make two remarks that we urge the reader to consider when interpreting the results of this work.inter-annotator agreement in section 3.3, we observed that inter-annotator agreement in asqa is higher than in eli5.",Neutral,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1024,248157463,ASQA: Factoid Questions Meet Long-Form Answers,limitations,high inter-annotator agreement in asqa is contingent upon the high inter-annotator agreement in the ambigqa dataset.,Neutral,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1025,248157463,ASQA: Factoid Questions Meet Long-Form Answers,limitations,"indeed, ambigqa disambiguations serve as a shared source of information between the two asqa annotators working on the same instance, potentially inflating the level of agreement.that said, min et al.",Neutral,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1026,248157463,ASQA: Factoid Questions Meet Long-Form Answers,limitations,"(2020) observe that human annotators have a decent level of agreement in constructing the disambiguations in ambigqa, thereby supporting the observation that asqa is more objective than eli5.evaluation metrics second, we caveat that our accuracy metrics (str-em and disambig-f1) only measure the recall of the required information in the long answers.",Neutral,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1027,248157463,ASQA: Factoid Questions Meet Long-Form Answers,limitations,"in cases where the long answer hallucinates incorrect disambiguations or facts, the accuracy metrics may still be high as long as the correct disambiguations are included.",Neutral,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1028,248157463,ASQA: Factoid Questions Meet Long-Form Answers,limitations,"we note, however, that this unnecessary extra information may still be penalized by the rouge-l metric.",Finding,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1029,248157463,ASQA: Factoid Questions Meet Long-Form Answers,limitations,"moreover, in the presence of distractors, we also expect the accuracy of the roberta model used for reading comprehension to degrade, thereby effectively penalizing a low precision.on a separate note, the disambig-f1 metric requires a high-accuracy qa system.",Finding,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1030,248157463,ASQA: Factoid Questions Meet Long-Form Answers,limitations,"hence, for domains that are significantly different from wikipedia, fine-tuning the roberta squadv2 model on the task might be important to ensure the effectiveness of the disambig-f1 metric.",Finding,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1031,248157463,ASQA: Factoid Questions Meet Long-Form Answers,limitations,and receive an answer within a day.,Neutral,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1032,248157463,ASQA: Factoid Questions Meet Long-Form Answers,limitations,"to support this mechanism, we allowed annotators to ""park"" an annotation task they were unsure about and return to it after they have their concerns resolved.annotators' well-being for this study, we recruited annotators who were fully dedicated to our task (8 hours a day for 5 days a week).",ReSolved,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1033,248157463,ASQA: Factoid Questions Meet Long-Form Answers,limitations,"to reduce the pressure on annotators and allow them to work at a comfortable pace, we gave annotators one hour to answer each question and recommended answering ten or more questions per day.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1034,248157463,ASQA: Factoid Questions Meet Long-Form Answers,limitations,"on average, it took annotators 15 minutes to answer each question with the time consumption slightly decreasing as annotators get familiar with the task.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1035,248157463,ASQA: Factoid Questions Meet Long-Form Answers,limitations,the compensation rate for the task was set to be $17.8/hour which is higher than the minimum hourly wage in the us.,Neutral,https://www.aclanthology.org/2022.emnlp-main.566.pdf
1036,254685782,MASTER: MULTI-TASK PRE-TRAINED BOTTLE- NECKED MASKED AUTOENCODERS ARE BETTER DENSE RETRIEVERS,conclusion,"in this paper, we proposed master, a multi-task pre-trained bottlenecked masked autoencoder for dense retrieval task.",ReSolved,https://export.arxiv.org/pdf/2212.07841v1.pdf
1037,254685782,MASTER: MULTI-TASK PRE-TRAINED BOTTLE- NECKED MASKED AUTOENCODERS ARE BETTER DENSE RETRIEVERS,conclusion,"in our approach, we adopted a bottlenecked multi-decoder architecture to integrate a variety of pre-training tasks, and devised three types of pre-training tasks about corrupted passages recovering, related passage recovering and plms outputs recovering.",ReSolved,https://export.arxiv.org/pdf/2212.07841v1.pdf
1038,254685782,MASTER: MULTI-TASK PRE-TRAINED BOTTLE- NECKED MASKED AUTOENCODERS ARE BETTER DENSE RETRIEVERS,conclusion,"the three types of tasks focused on compressing the semantic information within the passages, modeling relations among passages, and learning the knowledge from external public generative plms, respectively, leading to more informative and effective dense vectors.",ReSolved,https://export.arxiv.org/pdf/2212.07841v1.pdf
1039,254685782,MASTER: MULTI-TASK PRE-TRAINED BOTTLE- NECKED MASKED AUTOENCODERS ARE BETTER DENSE RETRIEVERS,conclusion,experimental results have shown that our approach outperforms several competitive baselines.,ReSolved,https://export.arxiv.org/pdf/2212.07841v1.pdf
1040,254685782,MASTER: MULTI-TASK PRE-TRAINED BOTTLE- NECKED MASKED AUTOENCODERS ARE BETTER DENSE RETRIEVERS,conclusion,we compare our approach with a variety of methods: of bert on these nlu tasks.,Neutral,https://export.arxiv.org/pdf/2212.07841v1.pdf
1041,254685782,MASTER: MULTI-TASK PRE-TRAINED BOTTLE- NECKED MASKED AUTOENCODERS ARE BETTER DENSE RETRIEVERS,conclusion,it indicates that our multi-task pre-training can also enrich the useful knowledge about nlu tasks for the plm.,ReSolved,https://export.arxiv.org/pdf/2212.07841v1.pdf
1042,252815949,Capturing Global Structural Information in Long Document Question Answering with Compressive Graph Selector Network,conclusion,"to solve the problem of lacking global structure in ldqa methods, we propose compress graph selector network to capture the global structure over the long document when selecting evidence pieces.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.336.pdf
1043,252815949,Capturing Global Structural Information in Long Document Question Answering with Compressive Graph Selector Network,conclusion,extensive experiments demonstrate the strong performance of the model.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.336.pdf
1044,218610721,Can We Predict New Facts with Open Knowledge Graph Embeddings? A Benchmark for Open Link Prediction,conclusion,we proposed the olp task and a method to create an olp benchmark.,ReSolved,https://www.aclweb.org/anthology/2020.acl-main.209.pdf
1045,218610721,Can We Predict New Facts with Open Knowledge Graph Embeddings? A Benchmark for Open Link Prediction,conclusion,"we created the large olp benchmark olpbench, which will be made publicly available.",ReSolved,https://www.aclweb.org/anthology/2020.acl-main.209.pdf
1046,218610721,Can We Predict New Facts with Open Knowledge Graph Embeddings? A Benchmark for Open Link Prediction,conclusion,"we investigated the effect of leakage of evaluation facts, non-relational information, and entity-knowledge during model selection using a prototypical open link prediction model.",ReSolved,https://www.aclweb.org/anthology/2020.acl-main.209.pdf
1047,218610721,Can We Predict New Facts with Open Knowledge Graph Embeddings? A Benchmark for Open Link Prediction,conclusion,our results indicate that most predicted true facts are genuinely new.,ReSolved,https://www.aclweb.org/anthology/2020.acl-main.209.pdf
1048,218610721,Can We Predict New Facts with Open Knowledge Graph Embeddings? A Benchmark for Open Link Prediction,conclusion,jointly in the context of lp.,Neutral,https://www.aclweb.org/anthology/2020.acl-main.209.pdf
1049,225040262,Stronger Transformers for Neural Multi-Hop Question Generation,conclusion,"in this work, we propose a series of strong transformer models for multi-hop qg.",ReSolved,https://arxiv.org/pdf/2010.11374v1.pdf
1050,225040262,Stronger Transformers for Neural Multi-Hop Question Generation,conclusion,"to effectively encode the context documents and the answer, we introduce answer type embeddings and a new sublayer to incorporate the extracted entity-centric graph.",ReSolved,https://arxiv.org/pdf/2010.11374v1.pdf
1051,225040262,Stronger Transformers for Neural Multi-Hop Question Generation,conclusion,we also propose an auxiliary contrastive objective to identify the supporting facts and a data filtering approach to balance the training-test distribution mismatch.,ReSolved,https://arxiv.org/pdf/2010.11374v1.pdf
1052,225040262,Stronger Transformers for Neural Multi-Hop Question Generation,conclusion,experiments on the hotpotqa dataset show that our models outperform the current best approaches by a substantial margin of 5 bleu points.,ReSolved,https://arxiv.org/pdf/2010.11374v1.pdf
1053,225040262,Stronger Transformers for Neural Multi-Hop Question Generation,conclusion,"our analysis further reveals that graph-based components may not be the most critical in improving the performance, but can render complementary strengths to the transformer.  ",ReSolved,https://arxiv.org/pdf/2010.11374v1.pdf
1054,207847640,Blockwise Self-Attention for Long Document Understanding,conclusion,"in this work, we study the lightweight bert model with the goal of achieving both efficiency and effectiveness.",ReSolved,https://www.aclweb.org/anthology/2020.findings-emnlp.232.pdf
1055,207847640,Blockwise Self-Attention for Long Document Understanding,conclusion,"we profile and analyze the memory bottlenecks of bert and focus on optimize dotproduct self-attention, which consumes quadratic memory with respect to the sequence length.",ReSolved,https://www.aclweb.org/anthology/2020.findings-emnlp.232.pdf
1056,207847640,Blockwise Self-Attention for Long Document Understanding,conclusion,"to reduce both time and memory consumption, we present blockbert, which sparsifies the attention matrices to be sparse block matrices.",ReSolved,https://www.aclweb.org/anthology/2020.findings-emnlp.232.pdf
1057,207847640,Blockwise Self-Attention for Long Document Understanding,conclusion,the proposed model achieves time and memory saving without significant loss of performance.,ReSolved,https://www.aclweb.org/anthology/2020.findings-emnlp.232.pdf
1058,239016681,Learning to Solve Complex Tasks by Talking to Agents,conclusion,in this work we motivate a new challenge task of solving complex task by communicating with existing ai agents.,ReSolved,https://arxiv.org/pdf/2110.08542v1.pdf
1059,239016681,Learning to Solve Complex Tasks by Talking to Agents,conclusion,"developing approaches for this challenge, we argue, could allow for more generalizable, privacy-preserving and efficient models.",Neutral,https://arxiv.org/pdf/2110.08542v1.pdf
1060,239016681,Learning to Solve Complex Tasks by Talking to Agents,conclusion,"towards this goal, we introduce a new benchmark dataset commaqa which involves multihop questions with three multi-hop reasoning challenges, all solvable by composing four qa agents.",ReSolved,https://arxiv.org/pdf/2110.08542v1.pdf
1061,239016681,Learning to Solve Complex Tasks by Talking to Agents,conclusion,each agent has an internal knowledge base (similar to ai assistants or large lms) that can be queried via natural language queries.,ReSolved,https://arxiv.org/pdf/2110.08542v1.pdf
1062,239016681,Learning to Solve Complex Tasks by Talking to Agents,conclusion,"experiments with state-of-art language models indicated that they struggle to solve commaqa, even when provided with agents' internal knowledge.",Finding,https://arxiv.org/pdf/2110.08542v1.pdf
1063,239016681,Learning to Solve Complex Tasks by Talking to Agents,conclusion,"in contrast, a model that is able to learn to communicate with the agents, albeit using annotated decompositions, is able to solve this task.",Neutral,https://arxiv.org/pdf/2110.08542v1.pdf
1064,239016681,Learning to Solve Complex Tasks by Talking to Agents,conclusion,this indicates the need and potential of such approaches to solve complex tasks.,Neutral,https://arxiv.org/pdf/2110.08542v1.pdf
1065,239016681,Learning to Solve Complex Tasks by Talking to Agents,conclusion,we hope this dataset will enable future work on learning to communicate with agents without relying on this additional supervision.,ReSolved,https://arxiv.org/pdf/2110.08542v1.pdf
1066,239016681,Learning to Solve Complex Tasks by Talking to Agents,conclusion,theory 1: what movies have people from the country $1 acted in?,Neutral,https://arxiv.org/pdf/2110.08542v1.pdf
1067,248299683,STANDING ON THE SHOULDERS OF GIANT FROZEN LANGUAGE MODELS,conclusions,"while fine-tuning huge lms can often yield excellent performance, this approach is expensive at training time, requires serving a plethora of models at runtime, and provides poor adaptability in the face of variations in the targeted task.",Finding,https://arxiv.org/pdf/2204.10019v1.pdf
1068,248299683,STANDING ON THE SHOULDERS OF GIANT FROZEN LANGUAGE MODELS,conclusions,"this paper has shown that a better alternative exists: freezing a single, huge pretrained lm and learning much smaller neural modules that specialize the lm to different tasks.",ReSolved,https://arxiv.org/pdf/2204.10019v1.pdf
1069,248299683,STANDING ON THE SHOULDERS OF GIANT FROZEN LANGUAGE MODELS,conclusions,"while prompt tuning, prefix tuning, and other existing frozen model methods cited above can be seen as a simple instantiations of this idea, this paper shows that much more complex architectures can achieve much stronger performance.",ReSolved,https://arxiv.org/pdf/2204.10019v1.pdf
1070,251223486,Few-shot Adaptation Works with UnpredicTable Data,conclusion,"we produced unpredictable, a dataset of 413,299 diverse few-shot learning tasks from internet tables.",ReSolved,https://export.arxiv.org/pdf/2208.01009v2.pdf
1071,251223486,Few-shot Adaptation Works with UnpredicTable Data,conclusion,finetuning on unpredictable improves the fsl ability of lms.,ReSolved,https://export.arxiv.org/pdf/2208.01009v2.pdf
1072,251223486,Few-shot Adaptation Works with UnpredicTable Data,conclusion,"however, the size of our dataset is not the key factor in its success.",Neutral,https://export.arxiv.org/pdf/2208.01009v2.pdf
1073,251223486,Few-shot Adaptation Works with UnpredicTable Data,conclusion,"we find that certain narrow datasets (even ones made of trivia) are even more helpful than diverse, curated nlp datasets.",ReSolved,https://export.arxiv.org/pdf/2208.01009v2.pdf
1074,251223486,Few-shot Adaptation Works with UnpredicTable Data,conclusion,"finetuning on these narrow datasets leads to strong improvements on the same test tasks as finetuning on diverse, curated nlp datasets.",ReSolved,https://export.arxiv.org/pdf/2208.01009v2.pdf
1075,251223486,Few-shot Adaptation Works with UnpredicTable Data,conclusion,"this suggests that finetuning on these datasets cause domain-agnostic fsl gains, though we were unable to find clear patterns to explain why this happens for some data and not others.",Finding,https://export.arxiv.org/pdf/2208.01009v2.pdf
1076,251223486,Few-shot Adaptation Works with UnpredicTable Data,conclusion,our results question common wisdom that task diversity is necessary for adapting lms to fsl.,Neutral,https://export.arxiv.org/pdf/2208.01009v2.pdf
1077,251223486,Few-shot Adaptation Works with UnpredicTable Data,conclusion,"we hope our work spurs investigation on what data causes few-shot learning to emerge, both to develop better datasets and to better understand how training data leads to unexpected behaviors or failures.  ",ReSolved,https://export.arxiv.org/pdf/2208.01009v2.pdf
1078,236447339,QA Dataset Explosion: A Taxonomy of NLP Resources for Question Answering and Reading Comprehension,conclusion,the number of qa/rc datasets produced by the nlp community is large and growing rapidly.,Neutral,https://export.arxiv.org/pdf/2107.12708v2.pdf
1079,236447339,QA Dataset Explosion: A Taxonomy of NLP Resources for Question Answering and Reading Comprehension,conclusion,"we have presented the most extensive survey of the field to date, identifying the key dimensions along which the current datasets vary.",ReSolved,https://export.arxiv.org/pdf/2107.12708v2.pdf
1080,253117139,Analyzing Multi-Task Learning for Abstractive Text Summarization,conclusion & future work,"in this work, we studied the influence of multi-task learning combinations of task families during the pre-finetuning stage for english abstractive text summarization.",ReSolved,https://export.arxiv.org/pdf/2210.14606v2.pdf
1081,253117139,Analyzing Multi-Task Learning for Abstractive Text Summarization,conclusion & future work,"we trained three different training strategies, six task families composed of 18 tasks, and evaluated two downstream tasks.",ReSolved,https://export.arxiv.org/pdf/2210.14606v2.pdf
1082,211832082,"A Survey of Antimicrobial Resistance Determinants in Category A Select Agents, Exempt Strains, and Near-Neighbor Species",conclusions,both pcr and microarrays are valuable tools for the tracking the genetic underpinnings of amr resistance.,Neutral,
1083,211832082,"A Survey of Antimicrobial Resistance Determinants in Category A Select Agents, Exempt Strains, and Near-Neighbor Species",conclusions,"here, we used two complementary technologies-microarray analysis and hrma-to survey 127 select agents, exempt strains, and near-neighbor species for a broad variety of resistance mechanisms acquired through both horizontal transfer and gene mutations.",ReSolved,
1084,211832082,"A Survey of Antimicrobial Resistance Determinants in Category A Select Agents, Exempt Strains, and Near-Neighbor Species",conclusions,"to our knowledge, this is the largest survey of category a agents, exempt strains, and near-neighbor species for genes covering multiple mechanisms of amr.",ReSolved,
1085,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"in this work we focused only on word documents as a common document type where users can author, copy-edit, or read content.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1086,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"indeed, the organization where we deployed our studies primarily uses word for business documents.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1087,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"the focus on word rather than e.g., pdfs or web pages also allowed us to obtain questions about documents at various stages of development, not just finalized manuscripts.",ReSolved,https://export.arxiv.org/pdf/2203.15073v2.pdf
1088,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"future work can investigate the types of questions that arise when users interact with other file types such as pdf, excel, and powerpoint.",Finding,https://export.arxiv.org/pdf/2203.15073v2.pdf
1089,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"because each file type is used for different purposes (e.g., excel documents for long-term book-keeping [27]) and possibly containing content at different levels of abstraction, the extent to which question answering in these documents can be automated and the kinds of expertise knowledge workers need may be different from the word documents in our study.because all questions had to first pass through the knowledge workers' system, the majority of the responses that participants received from the q&a system had a delay.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1090,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"therefore, it is possible that participants would have asked different questions if the responses had been provided instantaneously.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1091,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,another property that could have conceivably impacted the types of questions users asked is the quality of the answers that they received.,Finding,https://export.arxiv.org/pdf/2203.15073v2.pdf
1092,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"to understand if the types of questions by a user changed over time as they gained familiarity with the system, we examined the questions that were posted by the same user both across different documents or on the same document.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1093,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"we observed that some users posted multiple questions in succession and close together in time, e.g., in the span of a few minutes.",ReSolved,https://export.arxiv.org/pdf/2203.15073v2.pdf
1094,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"although these users would realize that the system does not provide answers instantaneously, their cluster of initial questions would not be impacted by the expectation of a long delay, their perceived capabilities of the system, or the quality of the answers.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1095,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"in fact, although we had specified in the consent form that there may be a delay in the responses that participants would receive from the q&a system, some end-of-study survey responses indicated that a number of participants had in fact not noticed this point and had asked their first few questions expecting instantaneous answers-""i was initially confused by the delay of asking the question in the document and then waiting for an email that told me to go back to the document.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1096,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,it seemed a bit redundant to get an email about it vs. just a notification in the word doc itself and telling me it was working on it or something.,Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1097,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"for a plug-in, however, i would expect less of a delay. """,Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1098,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"therefore, the first few questions from these participants could help with the generalizability of our results.the delay or the quality of answers however, may have influenced those users who submitted questions after receiving answers from the system.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1099,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"upon examination, we found that in many instances, when users received answers to their previous questions, they explored increasingly more sophisticated questions of various types, e.g., content-related, concerning metadata, or seeking external information.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1100,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"for instance, one participant started by asking simple metadata questions (""who is the author?"") and proceeded to ask questions on a scanned document that needed not only complex reasoning, but also optical character recognition (ocr): ""what is the total score?"" on a document where handwritten scores were given to each question.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1101,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,this finding suggests that the answers may have in fact encouraged users to be liberal with the types of questions they wished to subsequently ask.,Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1102,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"this exploration could be due to users gaining confidence that the system can in fact handle the types of questions with which they need support or could be because they wished to test the limits of its abilities.nevertheless, the characterization that we present in the paper also includes the questions users submitted in the experience sampling phase, where participants could imagine a sophisticated system with any or no delay.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1103,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"the set of questions in that phase of the study could further help with generalizability of our results, e.g., to settings where not all questions necessarily experience a delay.it is conceivable that the types of questions about a document may vary with the document type.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1104,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"in phase 2 where we had access to the documents, we observed that the document distribution was in fact very varied and included project proposals and timelines, value propositions, design specifications, service instructions, management training, protocols, faqs, whitepaper reports, strategy planning, customer feedback, research findings, etc. from various domains.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1105,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"with this diverse set of document types, investigating the relationship between types of questions and types of documents would require collecting far more questions by running the study for a long time.the setup of our q&a system was such that users submitted one-shot questions as there were no affordances for following up on previously asked questions.",Finding,https://export.arxiv.org/pdf/2203.15073v2.pdf
1106,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"future work should investigate whether the types of questions that users ask a document q&a system differ if the system provides the users with the means for following up on their previous questions or multi-round conversations with the assistant.another area for future work would be to explore the context of user needs including when users need different types of assistance with their documents, what they do before the seek help, and what they do after they receive answers.",Finding,https://export.arxiv.org/pdf/2203.15073v2.pdf
1107,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"to minimize concerns about the confidentiality of the business data, the contextual information that we collected in our study concerned the metadata of the document (e.g., file size, last modified date, etc.) and not the content.",Finding,https://export.arxiv.org/pdf/2203.15073v2.pdf
1108,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"for the same reason, we did not track a user's modification of the document before or after the user posted a question; the metadata was collected upon the user's submission of a question.",Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1109,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,"therefore, given the data we collected, we cannot examine the context of user needs.",Finding,https://export.arxiv.org/pdf/2203.15073v2.pdf
1110,247779047,Understanding Questions that Arise When Working with Business Documents,limitations and future work,future work can study this question through interviews and user-produced logs.,Finding,https://export.arxiv.org/pdf/2203.15073v2.pdf
1111,247779047,Understanding Questions that Arise When Working with Business Documents,conclusion,we studied users' information needs when working with their business documents as a first step towards building document assistants that can handle a variety of user requests.,Neutral,https://export.arxiv.org/pdf/2203.15073v2.pdf
1112,247779047,Understanding Questions that Arise When Working with Business Documents,conclusion,"to understand users' actual needs, it was important to collect their document-centric questions in-situ. therefore, we conducted two user studies.",ReSolved,https://export.arxiv.org/pdf/2203.15073v2.pdf
1113,247779047,Understanding Questions that Arise When Working with Business Documents,conclusion,"in the first study, we performed experience sampling of users' questions via a microsoft word add-in as users were working with their documents.",ReSolved,https://export.arxiv.org/pdf/2203.15073v2.pdf
1114,247779047,Understanding Questions that Arise When Working with Business Documents,conclusion,"in the second, users submitted their questions via an add-in and received answers from a human-in-the-loop document q&a system that complemented a question-answering ai with human intelligence.",ReSolved,https://export.arxiv.org/pdf/2203.15073v2.pdf
1115,247779047,Understanding Questions that Arise When Working with Business Documents,conclusion,"we characterized the distributions of questions and observed that the types of questions do indeed vary by whether the user is an author, a reviewer, or a reader of the document.",ReSolved,https://export.arxiv.org/pdf/2203.15073v2.pdf
1116,247779047,Understanding Questions that Arise When Working with Business Documents,conclusion,"in addition, the questions gave us insight into what types of request can be automated and whether particular skillsets or roles within the document are needed from human respondents in a document digital assistant that is co-powered by artificial and human intelligence.",ReSolved,https://export.arxiv.org/pdf/2203.15073v2.pdf
1117,231627885,COARSE-GRAINED DECOMPOSITION AND FINE-GRAINED INTERACTION FOR MULTI-HOP QUESTION ANSWERING,conclusion and future work,"in this paper, we propose a mutli-hop question answering model, that contains a coarse-grained decomposition strategy to divide a complex query into multiple single-hop simple queries and a fine- grained interaction strategy to better represent each word in the document and help the model find the sentences needed to answer the question.",ReSolved,https://arxiv.org/pdf/2101.05988v1.pdf
1118,231627885,COARSE-GRAINED DECOMPOSITION AND FINE-GRAINED INTERACTION FOR MULTI-HOP QUESTION ANSWERING,conclusion and future work,"in the experiments, we show that our models significantly and consistently outperform the baseline model.",ReSolved,https://arxiv.org/pdf/2101.05988v1.pdf
1119,246015349,Natural Language Deduction through Search over Statement Compositions,discussion and conclusion,"in this work, we propose a system that performs natural language reasoning through generative deduction and heuristic-guided search.",ReSolved,https://export.arxiv.org/pdf/2201.06028v2.pdf
1120,246015349,Natural Language Deduction through Search over Statement Compositions,limitations,"the baseline approach we consider in this work, end-to-end modeling of entailment tree generation, enjoys the convenience of simple inference and quadratic complexity.",ReSolved,https://export.arxiv.org/pdf/2201.06028v2.pdf
1121,246015349,Natural Language Deduction through Search over Statement Compositions,limitations,"however, the computational overhead of sequence-to-sequence models places a hard limit on the tree size and premise count that can be handled in the end-to-end setting; moreover, recent results call into question how well end-to-end transformers can generalize this type of reasoning (zhang et al., 2022).",Finding,https://export.arxiv.org/pdf/2201.06028v2.pdf
1122,246015349,Natural Language Deduction through Search over Statement Compositions,limitations,our structured approach allows arbitrarily large premise sets and step counts.,ReSolved,https://export.arxiv.org/pdf/2201.06028v2.pdf
1123,246015349,Natural Language Deduction through Search over Statement Compositions,limitations,"however, by discretizing the reasoning in the scsearch procedure, we do face a runtime theoretically exponential in proof size to do exhaustive search.",Finding,https://export.arxiv.org/pdf/2201.06028v2.pdf
1124,246015349,Natural Language Deduction through Search over Statement Compositions,limitations,"in practice, we limit our search to a finite horizon and find that this suffices to provide a practical wall clock runtime, never exceeding 5 seconds for any single example.",Neutral,https://export.arxiv.org/pdf/2201.06028v2.pdf
1125,246015349,Natural Language Deduction through Search over Statement Compositions,limitations,"future work on higher tree depths may have to reckon with the theoretical limitations of this procedure, possibly through the use of better heuristics.our experiments are conducted exclusively on english datasets.",Finding,https://export.arxiv.org/pdf/2201.06028v2.pdf
1126,246015349,Natural Language Deduction through Search over Statement Compositions,limitations,"while we hypothesize that our approach would work equally well for another language given a pretrained sequence-to-sequence model for that language with equivalent capacity, such models are not available universally across languages, representing an obstacle for transferring our results to languages beyond english.furthermore, the entailmentbank dataset on which we train and evaluate targets the elementary science domain, raising a question of domain specificity.",Finding,https://export.arxiv.org/pdf/2201.06028v2.pdf
1127,246015349,Natural Language Deduction through Search over Statement Compositions,limitations,"in future work, we plan to evaluate deduction models on additional datasets with different style, conceptual content, and types of reasoning in order to verify that the factored approach is equally applicable across diverse settings.",Finding,https://export.arxiv.org/pdf/2201.06028v2.pdf
1128,247647041,"Determination of Important Variables in Food Security Classification Using Random Forest 1 Eştürk, Ö. Gıda Güvencesi Düzeyi Sınıflandırılmasında Kullanılan Önemli Göstergelerin Random Forest Yöntemine Göre Belirlenmesi",conclusions,results indicated that seasonal apricot workers suffered from food insecurity.,ReSolved,https://dergipark.org.tr/tr/download/article-file/2139537
1129,247647041,"Determination of Important Variables in Food Security Classification Using Random Forest 1 Eştürk, Ö. Gıda Güvencesi Düzeyi Sınıflandırılmasında Kullanılan Önemli Göstergelerin Random Forest Yöntemine Göre Belirlenmesi",conclusions,food security was largely dependent on the purchasing power of food.,ReSolved,https://dergipark.org.tr/tr/download/article-file/2139537
1130,247647041,"Determination of Important Variables in Food Security Classification Using Random Forest 1 Eştürk, Ö. Gıda Güvencesi Düzeyi Sınıflandırılmasında Kullanılan Önemli Göstergelerin Random Forest Yöntemine Göre Belirlenmesi",conclusions,the auc value of the rf classification model (0.846) indicated its utility in the detection of the driving forces and causation patterns behind household food (in)security of the seasonal agricultural workers in turkey and in the world.,ReSolved,https://dergipark.org.tr/tr/download/article-file/2139537
1131,247647041,"Determination of Important Variables in Food Security Classification Using Random Forest 1 Eştürk, Ö. Gıda Güvencesi Düzeyi Sınıflandırılmasında Kullanılan Önemli Göstergelerin Random Forest Yöntemine Göre Belirlenmesi",conclusions,the findings of this study showed how the families of agricultural workers perceiving food security and necessity of developing different intervention strategies for different populations.,ReSolved,https://dergipark.org.tr/tr/download/article-file/2139537
1132,252918165,Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization,conclusion and future work,"in this work, we investigate performing it with unlabeled data for zero-shot cross-task generalization.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.105.pdf
1133,252918165,Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization,conclusion and future work,"we first empirically find that the it performance is largely restricted by the number of distinct tasks, instructions, and training samples in data-scarce tasks.",Finding,https://www.aclanthology.org/2022.emnlp-main.105.pdf
1134,252918165,Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization,conclusion and future work,"then, we propose udit to take better advantage of the instructions by constructing pseudo-labeled data from the unlabeled plain texts.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.105.pdf
1135,252918165,Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization,conclusion and future work,"through udit, it is possible to perform it with unlabeled data when there are few or no humanannotated samples, which offers a better way to incorporate unlabeled data compared with other approaches.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.105.pdf
1136,252918165,Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization,conclusion and future work,"through comprehensive analysis, we find that the domain diversity and the matching between the pseudo-labeled data and corresponding instructions are essential for udit.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.105.pdf
1137,252918165,Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization,conclusion and future work,"in contrast, noises in individual task clusters and colossal data amount are less influential.",Neutral,https://www.aclanthology.org/2022.emnlp-main.105.pdf
1138,252918165,Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization,conclusion and future work,there are three directions for future work: (1) designing automatic and generalizable methods to construct pseudo-labeled data for instruction tuning.,Finding,https://www.aclanthology.org/2022.emnlp-main.105.pdf
1139,247593935,R E L I C : Retrieving Evidence for Literary Claims,conclusion,"in this work, we introduce the task of literary evidence retrieval and an accompanying dataset, relic.",ReSolved,https://www.aclanthology.org/2022.acl-long.517.pdf
1140,247593935,R E L I C : Retrieving Evidence for Literary Claims,conclusion,we find that direct quotation of primary sources in literary analysis is most commonly used as evidence for literary claims or arguments.,ReSolved,https://www.aclanthology.org/2022.acl-long.517.pdf
1141,247593935,R E L I C : Retrieving Evidence for Literary Claims,conclusion,"we train a dense retriever model for our task; while it significantly outperforms baselines, human performance indicates a large room for improvement.",Neutral,https://www.aclanthology.org/2022.acl-long.517.pdf
1142,247593935,R E L I C : Retrieving Evidence for Literary Claims,conclusion,"important future directions include (1) building better models of primary sources that integrate narrative and discourse structure into the candidate representations instead of computing them out-of-context, and (2) integrating relic models into real tools that can benefit humanities researchers.",Finding,https://www.aclanthology.org/2022.acl-long.517.pdf
1143,119407066,On the Structure of the Yang-Mills Vacuum,conclusions,the results i have presented here are a rst step towards a microscopic understanding of the yang-mills vacuum.,ReSolved,https://export.arxiv.org/pdf/hep-lat/9506033v1.pdf
1144,119407066,On the Structure of the Yang-Mills Vacuum,conclusions,many of the intuitive ideas we have developed in the last years seem to prove to be correct nally.,Neutral,https://export.arxiv.org/pdf/hep-lat/9506033v1.pdf
1145,119407066,On the Structure of the Yang-Mills Vacuum,conclusions,"so, most likely, we are on the right track.",Neutral,https://export.arxiv.org/pdf/hep-lat/9506033v1.pdf
1146,258865288,Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation,conclusion,"we introduce answer-based claim decomposition, which aims to decompose a question into a series of true/false claims.",ReSolved,https://export.arxiv.org/pdf/2305.14750v1.pdf
1147,258865288,Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation,conclusion,"through experiments on three datasets with gpt-3.5, including a new challenge dataset obscureqa, we show how our technique can be used to perform fine-grained self-evaluation.",ReSolved,https://export.arxiv.org/pdf/2305.14750v1.pdf
1148,258865288,Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation,conclusion,"we find that there is a significant difference in the proportion of claims satisfied for incorrect and correct responses, but there is no indication that gpt-3.5 believes that the gold answer satisfies more abcd claims than its incorrect answers.",ReSolved,https://export.arxiv.org/pdf/2305.14750v1.pdf
1149,258865288,Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation,conclusion,"finally, to investigate the reliability of our approach, we conduct an error analysis and based on our findings, suggest remedies to overcome these errors.",ReSolved,https://export.arxiv.org/pdf/2305.14750v1.pdf
1150,258865288,Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation,limitations,"in our preliminary experiments, we apply answerbased claim decomposition to factual trivia questions where answers are entities spanning a few words.",ReSolved,https://export.arxiv.org/pdf/2305.14750v1.pdf
1151,258865288,Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation,limitations,"however, we did not examine if our technique would be effective on other types of qa datasets, such as truthfulqa (lin et al., 2022b), which exploits imitative falsehoods and contains longer desired responses, or boolqa (clark et al., 2019), which has ""yes"" or ""no"" as the only possible answers.further, due to financial constrains, we test abcd and fine-grained self-evaluation through preliminary experiments on a subset of data from our three datasets.",Finding,https://export.arxiv.org/pdf/2305.14750v1.pdf
1152,258865288,Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation,limitations,"however, given that our results were statistically significant ( §5.1), we believe that the number of questions selected were sufficient for our study.",Neutral,https://export.arxiv.org/pdf/2305.14750v1.pdf
1153,258865288,Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation,limitations,"in addition, since we only examined a subset of questions from our newly-collected dataset obscureqa, this opens up future research directions leveraging our dataset.",Finding,https://export.arxiv.org/pdf/2305.14750v1.pdf
1154,258865288,Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation,limitations,"we believe that obscureqa could be used to evaluate llms on a variety of facets, including benchmarking the academic knowledge of state-of-the-art llms, and given that this dataset frequently elicits untruthful responses, studying confidence and uncertainty calibration techniques.",Finding,https://export.arxiv.org/pdf/2305.14750v1.pdf
1155,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"environment complexity is limited, and it's currently difficult to author complex worlds.",Finding,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1156,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"two competing needs are currently at odds: the desire for complex environments to learn complex skills, and the desire for environment variation to encourage robustness in models.",Finding,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1157,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"current tooling emphasizes creating varied procedural environments, but those environments have limited complexity, and require agents to complete straightforward tasks.",Finding,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1158,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"economically creating complex, interactive environments that simulate a significant fraction of real world interactions is still well beyond current simulators or libraries -but required for higher-fidelity interactive worlds that have multiple meaningful paths toward achieving task goals.",Neutral,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1159,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"generating these environments semi-automatically (e.g. ammanabrolu et al., 2020a) may offer a partial solution.",Neutral,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1160,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"independent of tooling, libraries and other middleware offer near-term solutions to more complex environment modeling, much in the same way 3d game engines are regularly coupled with physics engine middleware to dramatically reduce the time required to implement forces, collisions, lighting, and other physics-based modeling.",Neutral,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1161,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"currently, few analogs exist for text worlds.",Finding,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1162,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"the addition of a chemistry engine that knows ice warmed above the freezing point will change to liquid water, or a generator engine that knows the sun is a source of sunlight during sunny days, or an observation engine that knows tools (like microscopes or thermometers) can change the observation model of a pomdp -may offer tractability in the form of modularization.",Neutral,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1163,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"efforts using large-scale crowdsourcing to construct knowledge bases of commonsense knowledge (e.g., atomic, sap et al., 2019) may be required to support these efforts.current planning languages offer a partial solution for environment modelling.",Neutral,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1164,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"while simulators partially implement facilities for world modeling, some (e.g. côté et al., 2018;shridhar et al., 2020b) suggest using mature planning languages like strips (fikes and nilsson, 1971) or pddl (mcdermott et al., 1998) for more full-featured modeling.",Neutral,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1165,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"this would not be without significant development effort -existing implementations of planning languages typically assume full-world observability (in conflict with pomdp modelling), and primarily agent-directed state-space changes, making complex world modeling with partial ob-servability, and complex environment processes (such as plants that require water and light to survive, or a sun that rises and sets causing different items to be observable in day versus night) outside the space of being easily implemented with off-the-shelf solutions.",Neutral,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1166,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"in the near-term, it is likely that a domain-specific language specific to complex text world modeling would be required to address these needs while simultaneously reducing the time investment and barrier-to-entry for end users.analyses of environment complexity can inform agent design and evaluation.",Finding,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1167,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"text world articles frequently emphasize agent modeling contributions over environment, methodological, or analysis contributions -but these contributions are critical, especially in the early stages of this subfield.",Neutral,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1168,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"agent performance in easy environments has increased incrementally, while medium-to-hard environments have seen comparatively modest improvements.",Neutral,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1169,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"agent performance is typically reported as a distribution over a large number of environments, and the methodological groundwork required to understand when different models exceed others in time or performance over these environment distributions is critical to making forward progress.",Finding,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1170,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"transfer learning in the form of training on one set of environments and testing on others has become a standard feature of benchmarks (e.g. hausknecht et al., 2020), but focused contributions that work to precisely characterize the limits of what can be learned from (for example) omniquest and transferred to zork, and what capacities must be learned elsewhere, will help inform research programs in agent modeling and environment design.transfer learning between text world and 3d environments.",Neutral,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1171,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"tasks learned at a high-level in text worlds help speed learning when those same models are transferred to more complex 3d environments (shridhar et al., 2020b).",Neutral,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1172,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,this framing of transfer learning may resemble how humans can converse about plans for future actions in locations remote from those eventual actions (as when we apply knowledge learned in classrooms to the real world).,Neutral,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1173,235790370,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,contemporary limitations and challenges,"as such, text-plus-3d environment rendering shows promise as a manner of controlling for different sources of complexity in multi-modal task learning (from high-level task-specific knowledge to low-level perceptual knowledge), and appears a promising research methodology for imparting complex task knowledge on agents that are able to navigate high-fidelity virtual environments.",Neutral,https://www.aclanthology.org/2022.wordplay-1.1.pdf
1174,215238360,Query Focused Multi-Document Summarization with Distant Supervision,conclusions,"in this work, we proposed a coarse-to-fine estimation framework for query focused multi-document summarization.",ReSolved,https://arxiv.org/pdf/2004.03027v1.pdf
1175,215238360,Query Focused Multi-Document Summarization with Distant Supervision,conclusions,we explored the potential of leveraging distant supervision signals from question answering to better capture the semantic relations between queries and document segments.,ReSolved,https://arxiv.org/pdf/2004.03027v1.pdf
1176,215238360,Query Focused Multi-Document Summarization with Distant Supervision,conclusions,experimental results across datasets show that the proposed model yields results superior to competitive baselines contributing to summaries which are more relevant and less redundant.,ReSolved,https://arxiv.org/pdf/2004.03027v1.pdf
1177,215238360,Query Focused Multi-Document Summarization with Distant Supervision,conclusions,"we have also shown that disentangling the tasks of relevance, evidence, and centrality estimation is beneficial allowing us to progressively specialize the summaries to the semantics of the query.",ReSolved,https://arxiv.org/pdf/2004.03027v1.pdf
1178,215238360,Query Focused Multi-Document Summarization with Distant Supervision,conclusions,"in the future, we would like to generate abstractive summaries following an unsupervised approach (baziotis et al., 2019;chu and liu, 2019) and investigate how recent advances in open domain qa qi et al., 2019) can be adapted for query focused summarization.",Finding,https://arxiv.org/pdf/2004.03027v1.pdf
1179,234741852,TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance,conclusion,"we propose a new challenging qa dataset tat-qa, comprising real-word hybrid contexts where the table contains numbers and has comprehensive dependencies on text in finance domain.",ReSolved,https://www.aclanthology.org/2021.acl-long.254.pdf
1180,234741852,TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance,conclusion,"to answer questions in tat-qa, the close relation between table and paragraphs and numerical reasoning are required.",Neutral,https://www.aclanthology.org/2021.acl-long.254.pdf
1181,234741852,TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance,conclusion,"we also propose a baseline model tagop based on tat-qa, aggregating information from hybrid context and performing numerical reasoning over it with pre-defined operators to compute the final answer.",ReSolved,https://www.aclanthology.org/2021.acl-long.254.pdf
1182,234741852,TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance,conclusion,experiments show tat-qa dataset is very challenging and more effort is demanded for tackling qa tasks over hybrid data.,Finding,https://www.aclanthology.org/2021.acl-long.254.pdf
1183,234741852,TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance,conclusion,"we expect our tat-qa dataset and tagop model would serve as a benchmark and baseline respectively to help build more advanced qa models, facilitating the development of qa technologies to address more complex and realistic hybrid data, especially those requiring numerical reasoning.",Finding,https://www.aclanthology.org/2021.acl-long.254.pdf
1184,246240382,Towards Collaborative Question Answering: A Preliminary Study,conclusion,the fact that knowledge are not shared gives rise to individual diversity and motivates collaboration.,Neutral,https://arxiv.org/pdf/2201.09708v1.pdf
1185,246240382,Towards Collaborative Question Answering: A Preliminary Study,conclusion,we believe natural-language based collaboration system is a domain that has practical implication and holds scientific values.,Neutral,https://arxiv.org/pdf/2201.09708v1.pdf
1186,246240382,Towards Collaborative Question Answering: A Preliminary Study,conclusion,the collabqa task and dataset we proposed in this paper is a small step towards that direction.,ReSolved,https://arxiv.org/pdf/2201.09708v1.pdf
1187,246240382,Towards Collaborative Question Answering: A Preliminary Study,conclusion,figure 6 shows the structure and examples in our proposed knowledge graphs.,Neutral,https://arxiv.org/pdf/2201.09708v1.pdf
1188,246240382,Towards Collaborative Question Answering: A Preliminary Study,conclusion,g 1 contains a list of person entities.,Neutral,https://arxiv.org/pdf/2201.09708v1.pdf
1189,246240382,Towards Collaborative Question Answering: A Preliminary Study,conclusion,the value of a property of the entity is randomly generated within a reasonable range.,Neutral,https://arxiv.org/pdf/2201.09708v1.pdf
1190,246240382,Towards Collaborative Question Answering: A Preliminary Study,conclusion,"for example, the value of a person's height is randomly sampled in the range [160cm, 200cm].",Neutral,https://arxiv.org/pdf/2201.09708v1.pdf
1191,246240382,Towards Collaborative Question Answering: A Preliminary Study,conclusion,"we add a series of constraints to make the kgs more realistic, such as a person who doesn't have job gets no annual income; a person cannot be a mayor and be an employee in some company at the same time; the largest company of a city must be located in that city, and so on.",ReSolved,https://arxiv.org/pdf/2201.09708v1.pdf
1192,204915921,QASC: A Dataset for Question Answering via Sentence Composition,conclusion,"we present qasc, the first qa dataset for multi-hop reasoning beyond a single paragraph where two facts needed to answer a question are annotated for training, but questions cannot be easily syntactically decomposed into these facts.",ReSolved,https://ojs.aaai.org/index.php/AAAI/article/download/6319/6175
1193,204915921,QASC: A Dataset for Question Answering via Sentence Composition,conclusion,"instead, models must learn to retrieve and compose candidate pieces of knowledge.",Neutral,https://ojs.aaai.org/index.php/AAAI/article/download/6319/6175
1194,204915921,QASC: A Dataset for Question Answering via Sentence Composition,conclusion,"qasc is generated via a crowdsourcing process, and further enhanced via multi-adversary distractor choice selection.",ReSolved,https://ojs.aaai.org/index.php/AAAI/article/download/6319/6175
1195,204915921,QASC: A Dataset for Question Answering via Sentence Composition,conclusion,"state-of-the-art bert models, even with massive fine-tuning on over 100k questions from previous relevant datasets and using our proposed two-step retrieval, leave a large margin to human performance levels, thus making qasc a new challenge for the community.",Neutral,https://ojs.aaai.org/index.php/AAAI/article/download/6319/6175
1196,235097535,MULTIPROVER: Generating Multiple Proofs for Improved Interpretability in Rule Reasoning,conclusion,"we proposed multilabel-multiprover and iterative-multiprover, two variants of a proof-set generation model where the former performs implicit conditioning between the proofs to generate them in parallel while the latter generates a proof-set through explicit conditioning on the previously generated proofs.",ReSolved,https://www.aclweb.org/anthology/2021.naacl-main.287.pdf
1197,235097535,MULTIPROVER: Generating Multiple Proofs for Improved Interpretability in Rule Reasoning,conclusion,both models obtain strong proof f1 improvements on synthetic and humanparaphrased datasets and iterative-multiprover also obtains state-of-the-art proof f1 on a zero-shot dataset with single proofs.,ReSolved,https://www.aclweb.org/anthology/2021.naacl-main.287.pdf
1198,235097535,MULTIPROVER: Generating Multiple Proofs for Improved Interpretability in Rule Reasoning,conclusion,multiprover's modeling is fairly generic and similar methods can be used in generating a set of structured explanations for other nlp tasks like multi-hop qa.,Finding,https://www.aclweb.org/anthology/2021.naacl-main.287.pdf
1199,258546701,Query Expansion by Prompting Large Language Models,limitations & future work,"there are a number of limitations in our work: first, we only study sparse retrieval (bm25) which is where query expansion is important.",Finding,https://export.arxiv.org/pdf/2305.03653v1.pdf
1200,258546701,Query Expansion by Prompting Large Language Models,limitations & future work,"dense retrieval systems (e.g. dual encoders) are less prone to the vocabulary gap and, as a result, are less likely to benefit from a query expansion.",Finding,https://export.arxiv.org/pdf/2305.03653v1.pdf
1201,258546701,Query Expansion by Prompting Large Language Models,limitations & future work,[31] has already studied this setting in more detail and we leave the analysis of our prompts for a dense retrieval setting as future work.,Neutral,https://export.arxiv.org/pdf/2305.03653v1.pdf
1202,258546701,Query Expansion by Prompting Large Language Models,limitations & future work,"second, our work focuses on flan [32] instruction-finetuned language models.",ReSolved,https://export.arxiv.org/pdf/2305.03653v1.pdf
1203,258546701,Query Expansion by Prompting Large Language Models,limitations & future work,we chose these models due to their ability to follow instructions and the fact that these models are open-source.,ReSolved,https://export.arxiv.org/pdf/2305.03653v1.pdf
1204,258546701,Query Expansion by Prompting Large Language Models,limitations & future work,"our work can naturally be extended to other language models [3,5,9,28] and we leave the study of such models as a topic for future research.",Neutral,https://export.arxiv.org/pdf/2305.03653v1.pdf
1205,258546701,Query Expansion by Prompting Large Language Models,limitations & future work,"third, we study specific prompt templates (see appendix a) and there may be other ways to formulate the different prompts.",ReSolved,https://export.arxiv.org/pdf/2305.03653v1.pdf
1206,258546701,Query Expansion by Prompting Large Language Models,limitations & future work,"finally, the computational cost of llms may be prohibitive to deploy llm-based query expansions in practice.",Finding,https://export.arxiv.org/pdf/2305.03653v1.pdf
1207,258546701,Query Expansion by Prompting Large Language Models,limitations & future work,it may be possible to distill the output of the large model into a smaller servable model.,Finding,https://export.arxiv.org/pdf/2305.03653v1.pdf
1208,258546701,Query Expansion by Prompting Large Language Models,limitations & future work,how to productionize llm-based query expansions is left as an open problem.,Finding,https://export.arxiv.org/pdf/2305.03653v1.pdf
1209,258546701,Query Expansion by Prompting Large Language Models,conclusion,in this paper we study llm-based query expansions.,ReSolved,https://export.arxiv.org/pdf/2305.03653v1.pdf
1210,258546701,Query Expansion by Prompting Large Language Models,conclusion,"in contrast to traditional prf-based query expansion, llms are not restricted to the initial retrieved set of documents and may be able to generate expansion terms not covered by traditional methods.",Neutral,https://export.arxiv.org/pdf/2305.03653v1.pdf
1211,258546701,Query Expansion by Prompting Large Language Models,conclusion,"our proposed method is simple: we prompt a large language model and provide it a query, then we use the model's output to expand the original query with new terms that help during document retrieval.",ReSolved,https://export.arxiv.org/pdf/2305.03653v1.pdf
1212,245769925,Does Entity Abstraction Help Generative Transformers Rea- son?,conclusion,we presented various ways to incorporate abstract knowledge into transformer language models.,ReSolved,https://export.arxiv.org/pdf/2201.01787v2.pdf
1213,245769925,Does Entity Abstraction Help Generative Transformers Rea- son?,conclusion,"focusing on entity types, this work evaluated model performance on reasoning tasks requiring compositional generalization and multi-hop reasoning.",ReSolved,https://export.arxiv.org/pdf/2201.01787v2.pdf
1214,245769925,Does Entity Abstraction Help Generative Transformers Rea- son?,conclusion,"overall our results demonstrate three things: (i) incorporating abstract knowledge significantly improves reasoning and compositional generalization in both interpolation and extrapolation when the environment is formally defined in a logical reasoning setting; (ii) different ways to incorporate abstraction yields different performance boosts: enc-sum and dec-loss are generally performing better than others; (iii) abstraction is not beneficial when the task at hand is more natural, less procedural, and not requiring long reasoning chains.",ReSolved,https://export.arxiv.org/pdf/2201.01787v2.pdf
1215,245769925,Does Entity Abstraction Help Generative Transformers Rea- son?,conclusion,"this last result is due to the noisy entity tagging from ""off-the-shelf"" taggers, and due to the nature of the task at hand.",Finding,https://export.arxiv.org/pdf/2201.01787v2.pdf
1216,256662612,"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity",conclusion and discussion,"multitask, multilingual, multimodalchatgpt outperforms multiple state-of-the-art zero-shot llms on various tasks and even surpasses fine-tuned models on some tasks.",ReSolved,https://export.arxiv.org/pdf/2302.04023v2.pdf
1217,256662612,"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity",conclusion and discussion,"although chatgpt performs well in most of the tasks, there are still some failure cases on each task ( §3.1).",Finding,https://export.arxiv.org/pdf/2302.04023v2.pdf
1218,256662612,"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity",conclusion and discussion,"in the summarization task, chatgpt sometimes generates a summary that is even longer than the input document.",Finding,https://export.arxiv.org/pdf/2302.04023v2.pdf
1219,256662612,"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity",conclusion and discussion,"in the machine translation task, chatgpt sometimes produces an incorrect translation for some words, making the meaning slightly shifted.",Finding,https://export.arxiv.org/pdf/2302.04023v2.pdf
1220,256662612,"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity",conclusion and discussion,"therefore, dealing with these special cases is a complex but important task.",Finding,https://export.arxiv.org/pdf/2302.04023v2.pdf
1221,258461315,"Search-in-the-Chain: Towards Accurate, Credible and Traceable Large Language Models for Knowledge-intensive Tasks",conclusion,"in this paper, we point out the challenges that should be considered in introducing ir into llm from perspectives of reasoning and knowledge.",Neutral,https://export.arxiv.org/pdf/2304.14732v4.pdf
1222,258461315,"Search-in-the-Chain: Towards Accurate, Credible and Traceable Large Language Models for Knowledge-intensive Tasks",conclusion,"then, we propose a novel framework called searchain for enabling ir and llm to interact with each other effectively.",ReSolved,https://export.arxiv.org/pdf/2304.14732v4.pdf
1223,258461315,"Search-in-the-Chain: Towards Accurate, Credible and Traceable Large Language Models for Knowledge-intensive Tasks",conclusion,"searchain not only stimulates the knowledge-reasoning ability of llm but also uses ir to provide the knowledge that llm really needs based on the external knowledge base, which improves accuracy and credibility.",ReSolved,https://export.arxiv.org/pdf/2304.14732v4.pdf
1224,258461315,"Search-in-the-Chain: Towards Accurate, Credible and Traceable Large Language Models for Knowledge-intensive Tasks",conclusion,"besides, searchain can mark references to supporting documents for the knowledge involved in the generated contents, which improves the traceability of the contents.",ReSolved,https://export.arxiv.org/pdf/2304.14732v4.pdf
1225,258461315,"Search-in-the-Chain: Towards Accurate, Credible and Traceable Large Language Models for Knowledge-intensive Tasks",conclusion,"in addition, the interaction between ir and llm in searchain transforms the topology of reasoning from chain to tree, which enables llm to dynamically modify reasoning direction.",ReSolved,https://export.arxiv.org/pdf/2304.14732v4.pdf
1226,258461315,"Search-in-the-Chain: Towards Accurate, Credible and Traceable Large Language Models for Knowledge-intensive Tasks",conclusion,experimental results on complex knowledge-intensive tasks show searchain performs better than all baselines.,ReSolved,https://export.arxiv.org/pdf/2304.14732v4.pdf
1227,258461315,"Search-in-the-Chain: Towards Accurate, Credible and Traceable Large Language Models for Knowledge-intensive Tasks",conclusion,"in future work, we will consider how to improve the efficiency of the framework and how to introduce more tools to interact with llm for more tasks.",Finding,https://export.arxiv.org/pdf/2304.14732v4.pdf
1228,247476296,Shepherd Pre-trained Language Models to Develop a Train of Thought: An Iterative Prompting Approach,conclusion & future work,"we explore an iterative prompting framework towards driving a ""train of thought"" from plms for multi-step reasoning tasks.",ReSolved,https://export.arxiv.org/pdf/2203.08383v2.pdf
1229,247476296,Shepherd Pre-trained Language Models to Develop a Train of Thought: An Iterative Prompting Approach,conclusion & future work,"we show the superiority of this iterative scheme, and also effectiveness of our proposed context-aware prompter design, which addresses key limitations of previous prompting methods when applied in this new scheme.",ReSolved,https://export.arxiv.org/pdf/2203.08383v2.pdf
1230,247476296,Shepherd Pre-trained Language Models to Develop a Train of Thought: An Iterative Prompting Approach,conclusion & future work,"in addition, we conduct both quantitative & qualitative analysis on the faithfulness of the learned prompting behaviors.",ReSolved,https://export.arxiv.org/pdf/2203.08383v2.pdf
1231,247476296,Shepherd Pre-trained Language Models to Develop a Train of Thought: An Iterative Prompting Approach,conclusion & future work,"in the future, we aim to further extend and apply our ideas to language model pretraining, with the hope that plms can be inherently equipped with stronger multi-step reasoning capabilities.",Finding,https://export.arxiv.org/pdf/2203.08383v2.pdf
1232,247476296,Shepherd Pre-trained Language Models to Develop a Train of Thought: An Iterative Prompting Approach,conclusion & future work,"the iterative framework we explore here also opens the possibility of human intervention and interaction during inference; namely a human can track along the plm's train of thought and make edits and corrections at different steps, which improves the transparency and trustworthiness of inference and also helps reduce error propagation along the reasoning process. we leave these investigations as future work.",Finding,https://export.arxiv.org/pdf/2203.08383v2.pdf
1233,233240947,Time-Stamped Language Model: Teaching Language Models to Understand the Flow of Events,conclusion,"we proposed the time-stamped language model (tslm model), a novel approach based on a simple and effective idea, which enables pre-trained qa models to process procedural texts and produce different outputs based on each step to track entities and their changes.",ReSolved,https://arxiv.org/pdf/2104.07635v1.pdf
1234,233240947,Time-Stamped Language Model: Teaching Language Models to Understand the Flow of Events,conclusion,"tslm utilizes a timestamp function that causes the attention modules in the transformer-based lm architecture to incorporate past, current, and future information by computing a timestamp embedding for each input token.",ReSolved,https://arxiv.org/pdf/2104.07635v1.pdf
1235,233240947,Time-Stamped Language Model: Teaching Language Models to Understand the Flow of Events,conclusion,our experiments show a 3.1% improvement on the f1 score and a 10.4% improvement over the recall metric on propara dataset.,ReSolved,https://arxiv.org/pdf/2104.07635v1.pdf
1236,233240947,Time-Stamped Language Model: Teaching Language Models to Understand the Flow of Events,conclusion,our model further outperforms the state-of-the-art models with a 1.55% margin in the npn-cooking dataset accuracy for the location prediction task.,ReSolved,https://arxiv.org/pdf/2104.07635v1.pdf
1237,238259354,FedNLP: Benchmarking Federated Learning Methods for Natural Language Processing Tasks,conclusion and future directions,our key contribution is providing a thorough and insightful empirical analysis of existing federated learning algorithms in the context of nlp models.,ReSolved,https://arxiv.org/pdf/2104.08815v3.pdf
1238,238259354,FedNLP: Benchmarking Federated Learning Methods for Natural Language Processing Tasks,conclusion and future directions,"notably, we compare typical fl methods for four nlp task formulations under multiple non-iid data partitions.",ReSolved,https://arxiv.org/pdf/2104.08815v3.pdf
1239,238259354,FedNLP: Benchmarking Federated Learning Methods for Natural Language Processing Tasks,conclusion and future directions,our findings reveal both promise and the challenges of fl for nlp.,ReSolved,https://arxiv.org/pdf/2104.08815v3.pdf
1240,238259354,FedNLP: Benchmarking Federated Learning Methods for Natural Language Processing Tasks,conclusion and future directions,"in addition, we also provide a suite of resources to support future research in fl for nlp (e.g., a unifying framework for connecting transformer models with popular fl methods and different non-iid partition strategies).",ReSolved,https://arxiv.org/pdf/2104.08815v3.pdf
1241,238259354,FedNLP: Benchmarking Federated Learning Methods for Natural Language Processing Tasks,conclusion and future directions,"thus, we believe our wellmaintained open-source codebase to support future work in this area.",Neutral,https://arxiv.org/pdf/2104.08815v3.pdf
1242,233189566,Globalizing BERT-based Transformer Architectures for Long Document Summarization,conclusion,"in this paper, we have introduced a novel transformer-based model for long document summarization based on propagation layers that spread information between multiple transformer windows.",ReSolved,https://www.aclweb.org/anthology/2021.eacl-main.154.pdf
1243,233189566,Globalizing BERT-based Transformer Architectures for Long Document Summarization,conclusion,"this model preserves the architecture of commonly used pre-trained language models, thus allowing the transfer of parameters.",ReSolved,https://www.aclweb.org/anthology/2021.eacl-main.154.pdf
1244,233189566,Globalizing BERT-based Transformer Architectures for Long Document Summarization,conclusion,"an evaluation, conducted on top of the bert model in the context of an extractive summarization task, further revealed its effectiveness in dealing with long documents compared to other adaptations of bert and previously proposed models.",ReSolved,https://www.aclweb.org/anthology/2021.eacl-main.154.pdf
1245,233189566,Globalizing BERT-based Transformer Architectures for Long Document Summarization,conclusion,"in the future, we plan to adapt our model to other tasks that require understanding long documents, as question-answering and document-scale machine translation.",Finding,https://www.aclweb.org/anthology/2021.eacl-main.154.pdf
1246,233189566,Globalizing BERT-based Transformer Architectures for Long Document Summarization,conclusion,a baselines: implementation details bertsumext:,Neutral,https://www.aclweb.org/anthology/2021.eacl-main.154.pdf
1247,256358835,Graph Attention with Hierarchies for Multi-hop Question Answering,conclusions and future work,"in this paper, we proposed two extensions to hierarchical graph network (hgn) for the multihop question answering task on hotpotqa.",ReSolved,https://export.arxiv.org/pdf/2301.11792v1.pdf
1248,256358835,Graph Attention with Hierarchies for Multi-hop Question Answering,conclusions and future work,"first, we completed the hierarchical graph structure by adding new edges between the query and context sentence nodes.",ReSolved,https://export.arxiv.org/pdf/2301.11792v1.pdf
1249,256358835,Graph Attention with Hierarchies for Multi-hop Question Answering,conclusions and future work,"second, we introduced gath as the mechanism for neural node updates, a novel extension to gat that can update node representations sequentially, based on hierarchical levels.",ReSolved,https://export.arxiv.org/pdf/2301.11792v1.pdf
1250,256358835,Graph Attention with Hierarchies for Multi-hop Question Answering,conclusions and future work,"to the best of our knowledge, this is the first time the hierarchical graph structure is directly exploited in the update mechanism for information propagation.",ReSolved,https://export.arxiv.org/pdf/2301.11792v1.pdf
1251,248476204,QRelScore: Better Evaluating Generated Questions with Deeper Understanding of Context-aware Relevance,conclusion,"existing evaluation metrics for question generation are still reference-based and ignore the crucial input context of generation, lacking a deep understanding of the relevance between the generated questions and context.",Finding,https://www.aclanthology.org/2022.emnlp-main.37.pdf
1252,248476204,QRelScore: Better Evaluating Generated Questions with Deeper Understanding of Context-aware Relevance,conclusion,"to address these issues, we propose qrelscore, which measures the word-and sentence-level relevance through the off-the-shelf language models.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.37.pdf
1253,248476204,QRelScore: Better Evaluating Generated Questions with Deeper Understanding of Context-aware Relevance,conclusion,extensive experiments demonstrate that qrelscore achieves start-of-the-art correlation with human judgments and makes up for the shortcomings of existing reference-based metrics.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.37.pdf
1254,237502990,Adaptive Information Seeking for Open-Domain Question Answering,conclusion and future work,"this work presents an adaptive informationseeking approach for open-domain question answering, called aiso.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.293.pdf
1255,237502990,Adaptive Information Seeking for Open-Domain Question Answering,conclusion and future work,"it models the open-domain qa task as a pomdp, where the environment contains a large corpus and the agent is asked to sequentially select retrieval function and reformulate query to collect the evidence.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.293.pdf
1256,237502990,Adaptive Information Seeking for Open-Domain Question Answering,conclusion and future work,"aiso achieves stateof-the-art results on two public datasets, which demonstrates the necessity of different retrieval functions for different questions.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.293.pdf
1257,237502990,Adaptive Information Seeking for Open-Domain Question Answering,conclusion and future work,"in the future, we will explore other adaptive retrieval strategies, like directly optimizing various informationseeking metrics by using reinforcement learning techniques.",Finding,https://www.aclanthology.org/2021.emnlp-main.293.pdf
1258,254125744,NIR-Prompt: A Multi-task Generalized Neural Information Retrieval Training Framework,conclusion,"in this paper, we point out that although there are some differences among the various information retrieval tasks, there are still essential matching signals shared by the various tasks, including exact matching, relevance matching and inference matching. if the model can capture and exploit these signals, the generalization ability of the model across tasks and domains will be improved.",Finding,https://export.arxiv.org/pdf/2212.00229v2.pdf
1259,254125744,NIR-Prompt: A Multi-task Generalized Neural Information Retrieval Training Framework,conclusion,"with this intuition, we propose a neural information retrieval training framework called nir-prompt consisting of essential matching module (emm) and matching description module (mdm) based on the idea of decoupling the process of signal capturing and signal combination.",ReSolved,https://export.arxiv.org/pdf/2212.00229v2.pdf
1260,254125744,NIR-Prompt: A Multi-task Generalized Neural Information Retrieval Training Framework,conclusion,mdm uses the method of prompt learning to obtain the description of different tasks in the pre-trained language model.,ReSolved,https://export.arxiv.org/pdf/2212.00229v2.pdf
1261,254125744,NIR-Prompt: A Multi-task Generalized Neural Information Retrieval Training Framework,conclusion,emm is trained on diverse mixed datasets and combined with the guidance from the task descriptions in mdm to capture essential matching signals and adapt these signals to different tasks.,ReSolved,https://export.arxiv.org/pdf/2212.00229v2.pdf
1262,254125744,NIR-Prompt: A Multi-task Generalized Neural Information Retrieval Training Framework,conclusion,"based on this, a generalized neural information retrieval pipeline consisting of retrieval and reranking is constructed.",ReSolved,https://export.arxiv.org/pdf/2212.00229v2.pdf
1263,254125744,NIR-Prompt: A Multi-task Generalized Neural Information Retrieval Training Framework,conclusion,"the experimental results on eighteen public datasets and a heterogeneous benchmark for testing the generalization ability of retrieval models show that our method yields better in-domain multi-task, out-of-domain multi-task and new task adaptation performance for dense retrieval, reranking and the entire neural information retrieval pipeline compared to the traditional fine-tuning paradigm.",ReSolved,https://export.arxiv.org/pdf/2212.00229v2.pdf
1264,248022214,QAGAN: Adversarial Approach To Learning Domain Invariant Language Features,conclusion,we presented a method for training a question-answering language model in an adversarial fashion and showed through various experiments that it helps the model generalize well to out-of-domain dataset.,ReSolved,https://arxiv.org/pdf/2206.12388v1.pdf
1265,237365386,Topic Knowledge Acquisition and Utilization for Machine Reading Comprehension in Social Media Domain,conclusion,"in this paper, we focus on machine reading comprehension in social media domain.",ReSolved,https://www.aclanthology.org/2021.ccl-1.88.pdf
1266,237365386,Topic Knowledge Acquisition and Utilization for Machine Reading Comprehension in Social Media Domain,conclusion,we propose a novel method to address the problem of lacking in background knowledge in this task.,ReSolved,https://www.aclanthology.org/2021.ccl-1.88.pdf
1267,237365386,Topic Knowledge Acquisition and Utilization for Machine Reading Comprehension in Social Media Domain,conclusion,"utilizing the nature of clustering of social media, we retrieve and refine topic knowledge from the relevant messages, and then integrate the knowledge into an mrc model, tkr. experimental results show that our proposed method outperforms the recently proposed models and the bert-based baselines, which proves the method effective overall.",ReSolved,https://www.aclanthology.org/2021.ccl-1.88.pdf
1268,237365386,Topic Knowledge Acquisition and Utilization for Machine Reading Comprehension in Social Media Domain,conclusion,"by introducing different amount of topic knowledge, we demonstrate the effectiveness of our refined knowledge.",ReSolved,https://www.aclanthology.org/2021.ccl-1.88.pdf
1269,237365386,Topic Knowledge Acquisition and Utilization for Machine Reading Comprehension in Social Media Domain,conclusion,"moreover, the ablation study further validates the contribution of the key modules of tkr for utilizing the knowledge.",ReSolved,https://www.aclanthology.org/2021.ccl-1.88.pdf
1270,248227734,Calibrating Trust of Multi-Hop Question Answering Systems with Decompositional Probes,conclusions,we have demonstrated the utility of question decomposition as an effective means to probe pretrained multi-hop question-answering models for supporting evidence.,ReSolved,https://export.arxiv.org/pdf/2204.07693v2.pdf
1271,248227734,Calibrating Trust of Multi-Hop Question Answering Systems with Decompositional Probes,conclusions,"through simulatability experiments, we show the effectiveness of this explanation form at allowing humans to predict model behavior, a sign that it helps humans to form an accurate mental model of the machine learning system (jacovi et al., 2022).",ReSolved,https://export.arxiv.org/pdf/2204.07693v2.pdf
1272,248227734,Calibrating Trust of Multi-Hop Question Answering Systems with Decompositional Probes,conclusions,"this ability to predict system performance occurs at the instance level instead of a sense of trust of the overall system, which can be important if the accuracy of the system is variable based on the question.",Neutral,https://export.arxiv.org/pdf/2204.07693v2.pdf
1273,248227734,Calibrating Trust of Multi-Hop Question Answering Systems with Decompositional Probes,limitations,our simulability study results (section 4) are conducted on silver labels.,ReSolved,https://export.arxiv.org/pdf/2204.07693v2.pdf
1274,248227734,Calibrating Trust of Multi-Hop Question Answering Systems with Decompositional Probes,limitations,"as section 5 reveals, there is a need for higher-quality question decompositions.",Finding,https://export.arxiv.org/pdf/2204.07693v2.pdf
1275,248227734,Calibrating Trust of Multi-Hop Question Answering Systems with Decompositional Probes,limitations,"while we have demonstrated the potential for decomposition probes to help users build mental models of system behavior, these results are not fully realizable in real applications until decompo-sition systems improve.the probing strategy explored in this paper is particular to the qa setting and datasets that don't have predefined categories of answers.",Finding,https://export.arxiv.org/pdf/2204.07693v2.pdf
1276,248227734,Calibrating Trust of Multi-Hop Question Answering Systems with Decompositional Probes,limitations,other probing strategies may exist that are not explored in this paper.it is noted that multi-hop questions do not always require multi-hop reasoning to solve.,Finding,https://export.arxiv.org/pdf/2204.07693v2.pdf
1277,248227734,Calibrating Trust of Multi-Hop Question Answering Systems with Decompositional Probes,limitations,indeed we intentionally use a non-multi-hop questionanswering model to answer the original question to disadvantage the system so that explanations are required.,Finding,https://export.arxiv.org/pdf/2204.07693v2.pdf
1278,248227734,Calibrating Trust of Multi-Hop Question Answering Systems with Decompositional Probes,limitations,multi-hop questions afford the use of a decompositional probing strategy.,Neutral,https://export.arxiv.org/pdf/2204.07693v2.pdf
1279,248227734,Calibrating Trust of Multi-Hop Question Answering Systems with Decompositional Probes,limitations,"our study did not look at non-multi-hop questions, which may require other probing strategies yet to be invented.",Finding,https://export.arxiv.org/pdf/2204.07693v2.pdf
1280,254044526,Dense Text Retrieval based on Pretrained Language Models: A Survey,conclusion,"in this survey, we thoroughly review the recent progress of dense retrieval based on pretrained language models (plm).",ReSolved,https://export.arxiv.org/pdf/2211.14876v1.pdf
1281,254044526,Dense Text Retrieval based on Pretrained Language Models: A Survey,conclusion,"as an important evolution of language intelligence techniques, plms empower dense retrieval models with excellent modeling capacities to capture and represent text semantics for relevance matching.",ReSolved,https://export.arxiv.org/pdf/2211.14876v1.pdf
1282,254044526,Dense Text Retrieval based on Pretrained Language Models: A Survey,conclusion,"our survey has extensively discussed the key issues and the mainstream solutions in four major aspects to develop dense retrieval systems, including architecture, training, indexing and integration.",ReSolved,https://export.arxiv.org/pdf/2211.14876v1.pdf
1283,254044526,Dense Text Retrieval based on Pretrained Language Models: A Survey,conclusion,"next, we briefly summarize the discussions of this survey and introduce some remaining issues for dense retrieval.",ReSolved,https://export.arxiv.org/pdf/2211.14876v1.pdf
1284,218502712,Query Reformulation using Query History for Passage Retrieval in Conversational Search,conclusion,"we present hqe and ntr, both conversational query reformulation methods stacked on a successful multi-stage ir pipeline.",ReSolved,https://arxiv.org/pdf/2005.02230v1.pdf
1285,218502712,Query Reformulation using Query History for Passage Retrieval in Conversational Search,conclusion,"the effectiveness of our methods are attested by experiments on the cast benchmark dataset, the results of which suggest that the two methods have different advantages in fusing context information into conversational user utterances for downstream ir models.",ReSolved,https://arxiv.org/pdf/2005.02230v1.pdf
1286,218502712,Query Reformulation using Query History for Passage Retrieval in Conversational Search,conclusion,"finally, this work elevates the state of the art in cast benchmarks and provides simple but effectives baselines for future research.",ReSolved,https://arxiv.org/pdf/2005.02230v1.pdf
1287,253018873,Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers,conclusion,"this paper stimulates the compositional reasoning process of humans in decision-making, and makes the following hypotheses: (1) the intuitive perception system (system 1) and cognitive reasoning system (system 2) can be decoupled and (2) the complex decision-making can be disentangled into multi-step execution of fundamental reasoning skills.",ReSolved,https://export.arxiv.org/pdf/2210.11265v2.pdf
1288,253018873,Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers,conclusion,"correspondingly, we propose reason-former, a compositional general-purpose reasoning framework.",ReSolved,https://export.arxiv.org/pdf/2210.11265v2.pdf
1289,253018873,Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers,conclusion,"reasonformer decouples the representation module and reasoning modules, which are pre-trained to expert in fundamental reasoning skills.",ReSolved,https://export.arxiv.org/pdf/2210.11265v2.pdf
1290,253018873,Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers,conclusion,the reasoning modules are dynamically composed in parallel and cascaded manner to form a whole reasoning process.,ReSolved,https://export.arxiv.org/pdf/2210.11265v2.pdf
1291,253018873,Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers,conclusion,reasonformer is endto-end and unified in solving multiple tasks with one model.,ReSolved,https://export.arxiv.org/pdf/2210.11265v2.pdf
1292,253018873,Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers,conclusion,extensive experiments on 11 tasks reveal the compositional reasoning ability of reason-former and disentangling of representation and reasoning modules.,ReSolved,https://export.arxiv.org/pdf/2210.11265v2.pdf
1293,252819049,To What Extent Do Natural Language Understanding Datasets Correlate to Logical Reasoning? A Method for Diagnosing Logical Reasoning,conclusions and future work,"in this work, we present a novel framework, which can diagnose the correlation between the nlu dataset and a specific skill and we probe a fundamental reasoning skill, logical reasoning, on 11",ReSolved,https://www.aclanthology.org/2022.coling-1.147.pdf
1294,252819049,To What Extent Do Natural Language Understanding Datasets Correlate to Logical Reasoning? A Method for Diagnosing Logical Reasoning,conclusions and future work,our framework involves a logical probe to conduct diagnosis and defines a qualitative process and a quantitative process to calculate two indicators.,ReSolved,https://www.aclanthology.org/2022.coling-1.147.pdf
1295,252819049,To What Extent Do Natural Language Understanding Datasets Correlate to Logical Reasoning? A Method for Diagnosing Logical Reasoning,conclusions and future work,"from the results, we observe that 1) most nli datasets have a relatively strong correlation with logical reasoning.",ReSolved,https://www.aclanthology.org/2022.coling-1.147.pdf
1296,252819049,To What Extent Do Natural Language Understanding Datasets Correlate to Logical Reasoning? A Method for Diagnosing Logical Reasoning,conclusions and future work,2) the correlations between type 1 mrc datasets and logical reasoning are moderate because logical reasoning is not the only dominant skill in these datasets.,ReSolved,https://www.aclanthology.org/2022.coling-1.147.pdf
1297,252819049,To What Extent Do Natural Language Understanding Datasets Correlate to Logical Reasoning? A Method for Diagnosing Logical Reasoning,conclusions and future work,3) the dependences of type 2 mrc datasets are not always exactly consistent with their intended purpose.,Neutral,https://www.aclanthology.org/2022.coling-1.147.pdf
1298,252819049,To What Extent Do Natural Language Understanding Datasets Correlate to Logical Reasoning? A Method for Diagnosing Logical Reasoning,conclusions and future work,"based on the analysis, although there are several limitations in our proposed method, this work is still a reasonable attempt to deeply understand the relationship between the dataset and a specific nlu skill.",Neutral,https://www.aclanthology.org/2022.coling-1.147.pdf
1299,252819049,To What Extent Do Natural Language Understanding Datasets Correlate to Logical Reasoning? A Method for Diagnosing Logical Reasoning,conclusions and future work,"in future works, we will focus on: 1) exploring the solution to the limitations of the proposed method; 2) build associations for different datasets that require the same nlu capabilities.",ReSolved,https://www.aclanthology.org/2022.coling-1.147.pdf
1300,252070866,FOLIO: Natural Language Reasoning with First-Order Logic,number of premises needed for conclusions,we show the accuracy of the examples with different numbers of premises needed to reach the conclusions in figure 3.,ReSolved,https://export.arxiv.org/pdf/2209.00840v1.pdf
1301,252070866,FOLIO: Natural Language Reasoning with First-Order Logic,number of premises needed for conclusions,"under the few-shot prompting setting, gpt-3 and  confusion matrices in figure 4 for the fine-tuning and 8-shot nl prompt results both show that lms are significantly better at making the correct predictions for conclusions with labels of true than the conclusions with labels of false or unknown.",ReSolved,https://export.arxiv.org/pdf/2209.00840v1.pdf
1302,252070866,FOLIO: Natural Language Reasoning with First-Order Logic,performance on conclusions with different labels,the accuracy on examples with false or unknown conclusions is 54.41% with fine-tuning and 36.91% with few-shot prompting.,ReSolved,https://export.arxiv.org/pdf/2209.00840v1.pdf
1303,252070866,FOLIO: Natural Language Reasoning with First-Order Logic,performance on conclusions with different labels,they also tend to make more predictions of true than the other labels.,ReSolved,https://export.arxiv.org/pdf/2209.00840v1.pdf
1304,252070866,FOLIO: Natural Language Reasoning with First-Order Logic,conclusion,"we introduced folio, an expert-written dataset for first-order logic (fol) reasoning equipped with parallel fol formulas.",ReSolved,https://export.arxiv.org/pdf/2209.00840v1.pdf
1305,252070866,FOLIO: Natural Language Reasoning with First-Order Logic,conclusion,the examples in folio are created based on real-world knowledge with natural language.,ReSolved,https://export.arxiv.org/pdf/2209.00840v1.pdf
1306,252070866,FOLIO: Natural Language Reasoning with First-Order Logic,conclusion,it exhibits a large number of distinct logic patterns and a large vocabulary.,ReSolved,https://export.arxiv.org/pdf/2209.00840v1.pdf
1307,252070866,FOLIO: Natural Language Reasoning with First-Order Logic,conclusion,"experiments show that the performance of one of the most capable llms publicly available is only slightly better than chance with few-shot prompting on hyblogic, a subset of folio, and llms are especially bad at predicting the correct truth values for false and unknown conclusions.",ReSolved,https://export.arxiv.org/pdf/2209.00840v1.pdf
1308,248779897,Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension,conclusion,this paper addresses answer uncertainty and unanswerability in multiple-choice mrc.,ReSolved,https://www.aclanthology.org/2022.findings-acl.82.pdf
1309,248779897,Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension,conclusion,measures of answer uncertainty are required to identify examples that the system may struggle to get correct and hence should abstain from answering such questions.,Neutral,https://www.aclanthology.org/2022.findings-acl.82.pdf
1310,248779897,Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension,conclusion,unanswerability detection is required for when the answer cannot be deduced using the information provided.,Neutral,https://www.aclanthology.org/2022.findings-acl.82.pdf
1311,248779897,Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension,conclusion,"an electra prlm achieve competitive results on the default reclor dataset, achieving up to 67.1% accuracy on the evaluation split.",ReSolved,https://www.aclanthology.org/2022.findings-acl.82.pdf
1312,248779897,Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension,conclusion,ensemble-based predictive uncertainty measures are explored for both modes of operation: answer uncertainty for negative marking schemes and the presence of unanswerability.,ReSolved,https://www.aclanthology.org/2022.findings-acl.82.pdf
1313,248779897,Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension,conclusion,it is shown that uncertainty in the prediction such as expected entropy is correlated with the error rate of the mrc system allowing better than vanilla performance with an aggressive negative marking scheme for reclor and race.,ReSolved,https://www.aclanthology.org/2022.findings-acl.82.pdf
1314,248779897,Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension,conclusion,"interestingly, it is found that expected entropy from the predictions of an implicitly trained system is competitive at unanswerability detection and is able to out-compete map decoding from an explicitly trained system that has been trained with unanswerable examples for reclor.",ReSolved,https://www.aclanthology.org/2022.findings-acl.82.pdf
1315,228375214,Multilingual Transfer Learning for QA Using Translation as Data Augmentation,conclusion,"in this work, we highlight open challenges in the existing multilingual approach by (lewis et al. 2020) and (clark et al. 2020).",Neutral,https://arxiv.org/pdf/2012.05958v1.pdf
1316,228375214,Multilingual Transfer Learning for QA Using Translation as Data Augmentation,conclusion,"specifically, we show that large pretrained multi-lingual lms are not enough for this task.",Finding,https://arxiv.org/pdf/2012.05958v1.pdf
1317,228375214,Multilingual Transfer Learning for QA Using Translation as Data Augmentation,conclusion,we produce several novel strategies for multilingual qa that go beyond zero-shot training and outshine the previous baseline built on top of mbert.,ReSolved,https://arxiv.org/pdf/2012.05958v1.pdf
1318,228375214,Multilingual Transfer Learning for QA Using Translation as Data Augmentation,conclusion,we present a translation model that has 14 times more training data.,ReSolved,https://arxiv.org/pdf/2012.05958v1.pdf
1319,228375214,Multilingual Transfer Learning for QA Using Translation as Data Augmentation,conclusion,"further, our at and laf strategies utilize translation as data augmentation to bring the language-specific embeddings of the lm closer to each other.",ReSolved,https://arxiv.org/pdf/2012.05958v1.pdf
1320,228375214,Multilingual Transfer Learning for QA Using Translation as Data Augmentation,conclusion,these approaches help us significantly improve the cross-lingual transfer.,ReSolved,https://arxiv.org/pdf/2012.05958v1.pdf
1321,228375214,Multilingual Transfer Learning for QA Using Translation as Data Augmentation,conclusion,"empirically, our models demonstrate strong results and all approaches improve over the previous zs strategy.",ReSolved,https://arxiv.org/pdf/2012.05958v1.pdf
1322,228375214,Multilingual Transfer Learning for QA Using Translation as Data Augmentation,conclusion,we hope these techniques spur further research in the field such as exploring other multilingual lms and invoking additional networks on top of large lms for multilingual nlp.,Finding,https://arxiv.org/pdf/2012.05958v1.pdf
1323,235352906,Prediction or Comparison: Toward Interpretable Qualitative Reasoning,conclusion,"in this paper, we aimed to solve the qualitative reasoning task in an interpretable manner. inspired by human cognition, we first summarized the questions into two categories, prediction and comparison.",ReSolved,https://arxiv.org/pdf/2106.02399v1.pdf
1324,235352906,Prediction or Comparison: Toward Interpretable Qualitative Reasoning,conclusion,then an end-to-end trained reasoning component that contains two reasoning chains was designed.,ReSolved,https://arxiv.org/pdf/2106.02399v1.pdf
1325,235352906,Prediction or Comparison: Toward Interpretable Qualitative Reasoning,conclusion,both reasoning chains contained multiple neural modules that provide transparent intermediate predictions for the understanding and reasoning process.,ReSolved,https://arxiv.org/pdf/2106.02399v1.pdf
1326,235352906,Prediction or Comparison: Toward Interpretable Qualitative Reasoning,conclusion,"the experimental results showed the effectiveness of our approach, and the analysis of each module and case study demonstrated the superior interpretability compared with the ""blackbox"" model.",ReSolved,https://arxiv.org/pdf/2106.02399v1.pdf
1327,235352906,Prediction or Comparison: Toward Interpretable Qualitative Reasoning,conclusion,"moreover, we found that some questions could be solved by both reasoning chains, thus increasing the default tolerance and generalization capability.",ReSolved,https://arxiv.org/pdf/2106.02399v1.pdf
1328,235352906,Prediction or Comparison: Toward Interpretable Qualitative Reasoning,conclusion,"furthermore, a human evaluation was conducted to validate the function of the synthetic text and provide an additional explanation for the superior performance achieved by our method.",ReSolved,https://arxiv.org/pdf/2106.02399v1.pdf
1329,235352906,Prediction or Comparison: Toward Interpretable Qualitative Reasoning,conclusion,"however, the error analysis showed the inadequacy under complicated scenarios.",Finding,https://arxiv.org/pdf/2106.02399v1.pdf
1330,235352906,Prediction or Comparison: Toward Interpretable Qualitative Reasoning,conclusion,"therefore, our future work will focus on applying interpretable reasoning on complex reasoning tasks.",Finding,https://arxiv.org/pdf/2106.02399v1.pdf
1331,235352906,Prediction or Comparison: Toward Interpretable Qualitative Reasoning,conclusion,the annotated data and models are shared publicly.,Neutral,https://arxiv.org/pdf/2106.02399v1.pdf
1332,237373991,Interactive Machine Comprehension with Dynamic Knowledge Graphs,conclusion,we explore to leverage graph representations in the challenging imrc tasks.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.540.pdf
1333,237373991,Interactive Machine Comprehension with Dynamic Knowledge Graphs,conclusion,we investigate different categories of graph structures that can capture text information at various levels.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.540.pdf
1334,237373991,Interactive Machine Comprehension with Dynamic Knowledge Graphs,conclusion,we describe methods that dynamically generate the graphs during information gathering.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.540.pdf
1335,237373991,Interactive Machine Comprehension with Dynamic Knowledge Graphs,conclusion,experiment results show that graph representations provide consistent improvement across settings.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.540.pdf
1336,237373991,Interactive Machine Comprehension with Dynamic Knowledge Graphs,conclusion,this evinces our hypothesis that graph representations are proper inductive biases in imrc.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.540.pdf
1337,202572622,PubMedQA: A Dataset for Biomedical Research Question Answering,conclusion,"we present pubmedqa, a novel dataset aimed at biomedical research question answering using yes/no/maybe, where complex quantitative reasoning is required to solve the task.",ReSolved,https://www.aclweb.org/anthology/D19-1259.pdf
1338,202572622,PubMedQA: A Dataset for Biomedical Research Question Answering,conclusion,pubmedqa has substantial automatically collected instances as well as the largest size of expert annotated yes/no/maybe questions in biomedical domain.,ReSolved,https://www.aclweb.org/anthology/D19-1259.pdf
1339,202572622,PubMedQA: A Dataset for Biomedical Research Question Answering,conclusion,"we provide a strong baseline using multi-phase fine-tuning of biobert with long answer as additional supervision, but it's still much worse than just single human performance.",Finding,https://www.aclweb.org/anthology/D19-1259.pdf
1340,202572622,PubMedQA: A Dataset for Biomedical Research Question Answering,conclusion,"there are several interesting future directions to explore on pubmedqa, e.g.: (1) about 21% of pubmedqa contexts contain no natural language descriptions of numbers, so how to properly handle these numbers is worth studying; (2) we use binary bow statistics prediction as a simple demonstration for additional supervision of long answers.",Finding,https://www.aclweb.org/anthology/D19-1259.pdf
1341,202572622,PubMedQA: A Dataset for Biomedical Research Question Answering,conclusion,learning a harder but more informative auxiliary task of long answer generation might lead to further improvements.,Finding,https://www.aclweb.org/anthology/D19-1259.pdf
1342,252280663,Prompt-based Conservation Learning for Multi-hop Question Answering,conclusions and future work,"in this paper, we introduce a novel prompt-based conservation learning framework for multi-hop qa -a framework that retains knowledge from previous component tasks -able to answer questions in a principled way that matches human expectations by answering sub-questions and integrating the answers.",ReSolved,https://www.aclanthology.org/2022.coling-1.154.pdf
1343,252280663,Prompt-based Conservation Learning for Multi-hop Question Answering,conclusions and future work,"by developing soft prompts related to reasoning types during training, we also show that we can condition plms to stimulate and apply the reasoning knowledge required for specific multihop questions.",ReSolved,https://www.aclanthology.org/2022.coling-1.154.pdf
1344,252280663,Prompt-based Conservation Learning for Multi-hop Question Answering,conclusions and future work,experimental results on multiple multi-hop qa datasets demonstrate the improved performance of pcl over previous multi-hop qa models in multi-hop qa.,ReSolved,https://www.aclanthology.org/2022.coling-1.154.pdf
1345,258866060,Prompt Optimization of Large Language Model for Interactive Tasks without Gradient and Demonstrations,conclusion,"we propose llm-po , a prompt optimization method, to make llm learn to solve interactive tasks without gradient computation or in-context demonstrations.",ReSolved,https://export.arxiv.org/pdf/2305.15064v1.pdf
1346,258866060,Prompt Optimization of Large Language Model for Interactive Tasks without Gradient and Demonstrations,conclusion,experiments show that llm-po is competitive to icl baselines in task success rates while requiring no diverse and high-quality demonstrations and achieves at least twice as lower inference cost.,ReSolved,https://export.arxiv.org/pdf/2305.15064v1.pdf
1347,258887816,Linguistic Properties of Truthful Response,limitation,our main limitation comes from dataset size.,Finding,https://export.arxiv.org/pdf/2305.15875v2.pdf
1348,258887816,Linguistic Properties of Truthful Response,limitation,this was limited because we used human evaluation to label model responses as truthful or untruthful.,Finding,https://export.arxiv.org/pdf/2305.15875v2.pdf
1349,258887816,Linguistic Properties of Truthful Response,limitation,"that is, we have manually confirmed gpt-judge labels on davinci responses, and extrapolated the system to ada, babbage, and curie.",Neutral,https://export.arxiv.org/pdf/2305.15875v2.pdf
1350,258887816,Linguistic Properties of Truthful Response,limitation,"frankly, the limitations caused by the small size of the dataset were quite evident because the truthfulness detector was often biased towards producing one label (either 1 or 0).",Finding,https://export.arxiv.org/pdf/2305.15875v2.pdf
1351,258887816,Linguistic Properties of Truthful Response,limitation,"we attempted to solve this problem using lower regularization parameters, but this often produced models with lower performances.",Finding,https://export.arxiv.org/pdf/2305.15875v2.pdf
1352,258887816,Linguistic Properties of Truthful Response,limitation,"an ideal solution to this problem would be training the truthfulness detector on a large set of training instances, which is also our future direction.",Finding,https://export.arxiv.org/pdf/2305.15875v2.pdf
1353,256597851,LIQUID: A Framework for List Question Answering Dataset Generation,conclusion,"herein, we introduced liquid, a framework that automatically generates list qa datasets from unlabeled corpora to alleviate the data scarcity problem in this field.",ReSolved,https://export.arxiv.org/pdf/2302.01691v2.pdf
1354,256597851,LIQUID: A Framework for List Question Answering Dataset Generation,conclusion,our synthetic data significantly improved the performance of the current supervised models on five benchmark datasets.,ReSolved,https://export.arxiv.org/pdf/2302.01691v2.pdf
1355,256597851,LIQUID: A Framework for List Question Answering Dataset Generation,conclusion,we thoroughly analyzed the effect of each component in liq-uid and generated data quantitatively and qualitatively.,ReSolved,https://export.arxiv.org/pdf/2302.01691v2.pdf
1356,256597851,LIQUID: A Framework for List Question Answering Dataset Generation,conclusion,table 10: distribution of answer types for the synthetic and bioasq 9b data.,Neutral,https://export.arxiv.org/pdf/2302.01691v2.pdf
1357,256597851,LIQUID: A Framework for List Question Answering Dataset Generation,conclusion,table 9 presents the distribution of the number of answers.,Neutral,https://export.arxiv.org/pdf/2302.01691v2.pdf
1358,256597851,LIQUID: A Framework for List Question Answering Dataset Generation,conclusion,"similar to the results in the general domain (table 5), the synthetic data were more skewed toward smaller numbers of answers than the labeled data, but some answers (14.2%) had four or more spans.",Neutral,https://export.arxiv.org/pdf/2302.01691v2.pdf
1359,237940861,Paradigm Shift in Natural Language Processing,conclusion,"recently, prompt-based tuning, which is to formulate some nlp task into a (m)lm task, has exploded in popularity.",Neutral,https://arxiv.org/pdf/2109.12575v2.pdf
1360,237940861,Paradigm Shift in Natural Language Processing,conclusion,they can achieve considerable performance with much less training data.,Neutral,https://arxiv.org/pdf/2109.12575v2.pdf
1361,237940861,Paradigm Shift in Natural Language Processing,conclusion,"in contrast, other potential unified paradigms, i.e. matching, mrc, and seq2seq, are underexplored in the context of pre-training.",Finding,https://arxiv.org/pdf/2109.12575v2.pdf
1362,237940861,Paradigm Shift in Natural Language Processing,conclusion,"one of the main reasons is that these paradigms require large-scale annotated data to conduct pre-training, especially seq2seq is notorious for data hungry.",Finding,https://arxiv.org/pdf/2109.12575v2.pdf
1363,258833055,Reflexion: Language Agents with Verbal Reinforcement Learning,limitations,"at its core, reflexion is an optimization technique that uses natural language to do policy optimization.",ReSolved,https://export.arxiv.org/pdf/2303.11366v2.pdf
1364,258833055,Reflexion: Language Agents with Verbal Reinforcement Learning,limitations,"policy optimization is a powerful approach to improve action choice through experience, but it may still succumb to non-optimal local minima solutions.",ReSolved,https://export.arxiv.org/pdf/2303.11366v2.pdf
1365,258833055,Reflexion: Language Agents with Verbal Reinforcement Learning,limitations,"in this study, we limit long-term memory to a sliding window with maximum capacity, but we encourage future work to extend the memory component of reflexion with more advanced structures such as vector embedding databases or traditional sql databases.",Finding,https://export.arxiv.org/pdf/2303.11366v2.pdf
1366,258833055,Reflexion: Language Agents with Verbal Reinforcement Learning,limitations,"specific to code generation, there are many practical limitations to testdriven development in specifying accurate input-output mappings such as non-deterministic generator functions, impure functions that interact with apis, functions that vary output according to hardware specifications, or functions that invoke parallel or concurrent behavior that may be difficult to predict.",Finding,https://export.arxiv.org/pdf/2303.11366v2.pdf
1367,258833055,Reflexion: Language Agents with Verbal Reinforcement Learning,conclusion,"in this work, we present reflexion, an approach that leverages verbal reinforcement to teach agents to learn from past mistakes.",ReSolved,https://export.arxiv.org/pdf/2303.11366v2.pdf
1368,258833055,Reflexion: Language Agents with Verbal Reinforcement Learning,conclusion,we empirically show that reflexion agents significantly outperform currently widely-used decision-making approaches by utilizing self-reflection.,ReSolved,https://export.arxiv.org/pdf/2303.11366v2.pdf
1369,258833055,Reflexion: Language Agents with Verbal Reinforcement Learning,conclusion,"in future work, reflexion could be used to employ more advanced techniques that have been thoroughly studied in traditional rl settings, such as value learning in natural language or off-policy exploration techniques.",Finding,https://export.arxiv.org/pdf/2303.11366v2.pdf
1370,233296336,Identifying the Limits of Cross-Domain Knowledge Transfer for Pretrained Models,conclusion,"in this paper, we propose an evaluation pipeline for pretrained models by testing their transferability without word identity information.",ReSolved,https://arxiv.org/pdf/2104.08410v1.pdf
1371,233296336,Identifying the Limits of Cross-Domain Knowledge Transfer for Pretrained Models,conclusion,"specifically, we take an english pretrained bert off-the-shelf and fine-tune it with a scrambled english dataset.",ReSolved,https://arxiv.org/pdf/2104.08410v1.pdf
1372,233296336,Identifying the Limits of Cross-Domain Knowledge Transfer for Pretrained Models,conclusion,we conduct analyses across six tasks covering both classification and sequence labeling.,ReSolved,https://arxiv.org/pdf/2104.08410v1.pdf
1373,233296336,Identifying the Limits of Cross-Domain Knowledge Transfer for Pretrained Models,conclusion,"by evaluating performance against multiple baselines, we aim to assess where bert can transfer knowledge even without word identities.",Neutral,https://arxiv.org/pdf/2104.08410v1.pdf
1374,233296336,Identifying the Limits of Cross-Domain Knowledge Transfer for Pretrained Models,conclusion,"we find considerable transfer for bert as compared to even powerful baselines, by only for classification tasks.",ReSolved,https://arxiv.org/pdf/2104.08410v1.pdf
1375,248496003,Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning,conclusion and future work,"we propose a two-branch graph transformer network for logical reasoning of text, which is named as logiformer.",ReSolved,https://arxiv.org/pdf/2205.00731v2.pdf
1376,248496003,Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning,conclusion and future work,"firstly, we introduce two different strategies to construct the logical graph and syntax graph respectively.",ReSolved,https://arxiv.org/pdf/2205.00731v2.pdf
1377,248496003,Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning,conclusion and future work,"especially for the logical graph, we are the first to model both causal relations and negations in the logical reasoning task.",ReSolved,https://arxiv.org/pdf/2205.00731v2.pdf
1378,248496003,Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning,conclusion and future work,"secondly, we feed the extracted node sequences to the fully connected graph transformer for each graph.",ReSolved,https://arxiv.org/pdf/2205.00731v2.pdf
1379,248496003,Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning,conclusion and future work,the topology of the graph is utilized to form the attention bias for the self-attention layers.,Neutral,https://arxiv.org/pdf/2205.00731v2.pdf
1380,248496003,Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning,conclusion and future work,"thirdly, a dynamic gate mechanism is applied to make a fusion of the features from two branches.",Neutral,https://arxiv.org/pdf/2205.00731v2.pdf
1381,248496003,Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning,conclusion and future work,"to improve the awareness of different question types, the question feature is updated based on the self-attention module.",Neutral,https://arxiv.org/pdf/2205.00731v2.pdf
1382,248496003,Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning,conclusion and future work,"finally, the concatenated text sequence is passed through the feed forward layer and obtains the answer prediction.",Neutral,https://arxiv.org/pdf/2205.00731v2.pdf
1383,248496003,Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning,conclusion and future work,"the whole reasoning process provides the interpretability, reflected by logical units with explicit relations and the visualization of the attention maps.",Neutral,https://arxiv.org/pdf/2205.00731v2.pdf
1384,233297051,Explaining Answers with Entailment Trees,summary and conclusion,"our goal is to enable machines to generate richer, more systematic explanations.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.585.pdf
1385,233297051,Explaining Answers with Entailment Trees,summary and conclusion,"to this end, we have developed a novel formulation of explanations as multistep entailment trees, and created entail-mentbank, the first large dataset of such trees.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.585.pdf
1386,258685562,Answering Complex Questions over Text by Hybrid Question Parsing and Execution,conclusion,"we propose hpe for answering complex questions over text, which combines the strengths of neural network approaches and symbolic approaches.",ReSolved,https://export.arxiv.org/pdf/2305.07789v1.pdf
1387,258685562,Answering Complex Questions over Text by Hybrid Question Parsing and Execution,conclusion,we parse the question into h-expressions followed by the hybrid execution to get the final answer.,ReSolved,https://export.arxiv.org/pdf/2305.07789v1.pdf
1388,258685562,Answering Complex Questions over Text by Hybrid Question Parsing and Execution,conclusion,"our extensive empirical results demonstrate that hpe has a strong performance on various datasets under supervised, few-shot, and zero-shot settings.",ReSolved,https://export.arxiv.org/pdf/2305.07789v1.pdf
1389,258685562,Answering Complex Questions over Text by Hybrid Question Parsing and Execution,conclusion,"moreover, our model has a strong interpretability exposing its underlying reasoning process, which facilitates understanding and possibly fixing its errors. by replacing our text reader with kb or",ReSolved,https://export.arxiv.org/pdf/2305.07789v1.pdf
1390,237194607,MeDiaQA: A Question Answering Dataset on Medical Dialogues,conclusion,"in this paper, we construct mediaqa, a novel dataset for qa on medical dialogues and propose a method media-bert based on the state-of-the-art pretrained language model.",ReSolved,https://arxiv.org/pdf/2108.08074v1.pdf
1391,237194607,MeDiaQA: A Question Answering Dataset on Medical Dialogues,conclusion,the proposed dataset shows the distinctiveness of medical dialogues compared with other normal domains in the context of qa.,ReSolved,https://arxiv.org/pdf/2108.08074v1.pdf
1392,237194607,MeDiaQA: A Question Answering Dataset on Medical Dialogues,conclusion,"due to the unique characteristics, it is challenging for existing qa models compared with human performance.",Finding,https://arxiv.org/pdf/2108.08074v1.pdf
1393,237194607,MeDiaQA: A Question Answering Dataset on Medical Dialogues,conclusion,we hope our dataset will lead a deeper research on machine reading comprehension in medical domain.,Neutral,https://arxiv.org/pdf/2108.08074v1.pdf
1394,249888962,A Dense Representation Framework for Lexical and Semantic Matching,conclusions and future work,we present a simple yet effective approach to densifying lexical representations for passage retrieval.,ReSolved,https://export.arxiv.org/pdf/2206.09912v2.pdf
1395,249888962,A Dense Representation Framework for Lexical and Semantic Matching,conclusions and future work,this work introduces a dense representation framework and proposes a new scoring function to compute relevance scores between dense lexical representations (dlrs) derived from queries and passages.,ReSolved,https://export.arxiv.org/pdf/2206.09912v2.pdf
1396,249888962,A Dense Representation Framework for Lexical and Semantic Matching,conclusions and future work,"using our framework, we can combine lexical and semantic representations into dense hybrid representations (dhrs) for hybrid retrieval.",ReSolved,https://export.arxiv.org/pdf/2206.09912v2.pdf
1397,249888962,A Dense Representation Framework for Lexical and Semantic Matching,conclusions and future work,"our experiments show that dlrs can accurately approximate any ""off-the-shelf"" lexical model.",ReSolved,https://export.arxiv.org/pdf/2206.09912v2.pdf
1398,249888962,A Dense Representation Framework for Lexical and Semantic Matching,conclusions and future work,"furthermore, when combined with other semantic representations (as dhrs), the resulting models can achieve comparable effectiveness to existing state-of-the-art hybrid retrieval methods.",ReSolved,https://export.arxiv.org/pdf/2206.09912v2.pdf
1399,256739246,Recent Advances in Long Documents Classification Using Deep-Learning,conclusion and future directions,"it is beyond doubt that transformer architecture changed the way linguistic analysis is performed, and in a very short time bert has been widely accepted as the golden standard of semantic understanding.",Neutral,https://www.aclanthology.org/2022.icnlsp-1.12.pdf
1400,256739246,Recent Advances in Long Documents Classification Using Deep-Learning,conclusion and future directions,"however, the greatest value of this concept may be tied to its flexibility, as it allows for extensive customization and specialization with only minimal modifications of the training procedure.",Neutral,https://www.aclanthology.org/2022.icnlsp-1.12.pdf
1401,256739246,Recent Advances in Long Documents Classification Using Deep-Learning,conclusion and future directions,"while there have been numerous adaptations of successful transformer models in the past, it's highly likely that the number and quality of derivative work will increase in the near future.",Neutral,https://www.aclanthology.org/2022.icnlsp-1.12.pdf
1402,256739246,Recent Advances in Long Documents Classification Using Deep-Learning,conclusion and future directions,"figuring out ways to improve an already impressive model is not easy, but growing presence of this topic in the online forums and greater availability of research papers dealing with some of the outstanding challenges could power the next wave of research in this direction.",Neutral,https://www.aclanthology.org/2022.icnlsp-1.12.pdf
1403,256739246,Recent Advances in Long Documents Classification Using Deep-Learning,conclusion and future directions,"this process is already underway, and a breakthrough achieved with transformers is being actively exploited by research teams from around the world.",Neutral,https://www.aclanthology.org/2022.icnlsp-1.12.pdf
1404,236428903,Graph-free Multi-hop Reading Comprehension: A Select-to-Guide Strategy,conclusion,"this paper proposes a novel ""select-to-guide"" model (s2g) for multi-hop reading comprehension in more effective and convenient way.",ReSolved,https://arxiv.org/pdf/2107.11823v1.pdf
1405,236428903,Graph-free Multi-hop Reading Comprehension: A Select-to-Guide Strategy,conclusion,"as an alternative of the existing graph modeling, the proposed graph-free s2g model consists of an evidence paragraph retrieval module which selects evidence paragraphs in a step-by-step multihop manner, and a multi-task module that simultaneously extracts evidence sentences and answer spans.",ReSolved,https://arxiv.org/pdf/2107.11823v1.pdf
1406,258841780,Efficient Open Domain Multi-Hop Question Answering with Few-Shot Data Synthesis,conclusion,we propose a few-shot data synthesis framework to training smaller models for efficient open domain multi-hop question answering with less than 10 human annotations.,ReSolved,https://export.arxiv.org/pdf/2305.13691v1.pdf
1407,258841780,Efficient Open Domain Multi-Hop Question Answering with Few-Shot Data Synthesis,conclusion,"our framework consists of generation functions parameterized by llms and prompts, which requires less hand-crafted features than prior work while still achieving better performance.",ReSolved,https://export.arxiv.org/pdf/2305.13691v1.pdf
1408,258841780,Efficient Open Domain Multi-Hop Question Answering with Few-Shot Data Synthesis,conclusion,we show that our approach is general by extending to fact verification tasks.,ReSolved,https://export.arxiv.org/pdf/2305.13691v1.pdf
1409,258841780,Efficient Open Domain Multi-Hop Question Answering with Few-Shot Data Synthesis,conclusion,"in experiments, we benchmark our approach on three multihop question answering and one fact verification benchmarks.",ReSolved,https://export.arxiv.org/pdf/2305.13691v1.pdf
1410,258841780,Efficient Open Domain Multi-Hop Question Answering with Few-Shot Data Synthesis,conclusion,the results show that our approach leads to significantly better models that rival the performance of previous methods employing models nearly three times larger in terms of parameter counts.,ReSolved,https://export.arxiv.org/pdf/2305.13691v1.pdf
1411,258841780,Efficient Open Domain Multi-Hop Question Answering with Few-Shot Data Synthesis,conclusion,the analysis shows the importance of the filtering steps and our approach benefits models of various sizes.,ReSolved,https://export.arxiv.org/pdf/2305.13691v1.pdf
1412,258841780,Efficient Open Domain Multi-Hop Question Answering with Few-Shot Data Synthesis,limitation,"we highlight three limitations on our work: (1) our approach depends on synthesizing large amounts of data, which are expensive even if we used llama 65b which are much smaller than palm 540b and gpt-3.5;(2)",Finding,https://export.arxiv.org/pdf/2305.13691v1.pdf
1413,258841780,Efficient Open Domain Multi-Hop Question Answering with Few-Shot Data Synthesis,limitation,"our approach finetunes language models and thus is not applicable to the closedsource language models, e.g., gpt-3 and palm; and (3) our approach depends on the availability of powerful llms for synthesizing finetuning data.",Finding,https://export.arxiv.org/pdf/2305.13691v1.pdf
1414,256827065,Analyzing the Effectiveness of the Underlying Reasoning Tasks in Multi-hop Question Answering,conclusion,we analyze the effectiveness of the underlying reasoning tasks using two multi-hop datasets: 2wiki and hotpotqa-small.,ReSolved,https://export.arxiv.org/pdf/2302.05963v1.pdf
1415,256827065,Analyzing the Effectiveness of the Underlying Reasoning Tasks in Multi-hop Question Answering,conclusion,the results reveal that the underlying reasoning tasks can improve qa performance.,ReSolved,https://export.arxiv.org/pdf/2302.05963v1.pdf
1416,256827065,Analyzing the Effectiveness of the Underlying Reasoning Tasks in Multi-hop Question Answering,conclusion,"using four debiased sets, we demonstrate that the underlying reasoning tasks can reduce the reasoning shortcuts of the qa task.",ReSolved,https://export.arxiv.org/pdf/2302.05963v1.pdf
1417,256827065,Analyzing the Effectiveness of the Underlying Reasoning Tasks in Multi-hop Question Answering,conclusion,"the results also reveal that the underlying reasoning tasks do not make the models more robust on adversarial examples, such as sub-questions and inverted questions.",ReSolved,https://export.arxiv.org/pdf/2302.05963v1.pdf
1418,256827065,Analyzing the Effectiveness of the Underlying Reasoning Tasks in Multi-hop Question Answering,conclusion,we encourage future studies to investigate the effectiveness of the entity-level reasoning task in the form of sub-questions.,Finding,https://export.arxiv.org/pdf/2302.05963v1.pdf
1419,251135345,Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation,conclusion,we provide insights into an rnn-based iterative memory model that incorporates gate attention on multi-step reasoning over natural language.,ReSolved,https://export.arxiv.org/pdf/2207.14000v1.pdf
1420,251135345,Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation,conclusion,"instead of using the original gru and dotproduct attention, we integrate gate attention to update hidden states.",ReSolved,https://export.arxiv.org/pdf/2207.14000v1.pdf
1421,251135345,Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation,conclusion,the experiment results show the model with gate attention achieves generally better performance than the original rnnbased iterative-memory model with dot-product attention and other rnn-based models.,ReSolved,https://export.arxiv.org/pdf/2207.14000v1.pdf
1422,251135345,Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation,conclusion,the performance of our model is comparable or better than the much larger and pretrained roberta-large in some scenarios.,ReSolved,https://export.arxiv.org/pdf/2207.14000v1.pdf
1423,251135345,Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation,conclusion,"furthermore, our model shows better out-of-distribution generalisation performance than the pretained roberta.",ReSolved,https://export.arxiv.org/pdf/2207.14000v1.pdf
1424,251135345,Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation,conclusion,"to address the issue of depth-imbalance in the existing datasets on multi-step reasoning over natural language, we develop a large-scale multi-step reasoning dataset called pararule-plus, with more examples of deep reasoning depths than previous datasets.",ReSolved,https://export.arxiv.org/pdf/2207.14000v1.pdf
1425,251135345,Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation,conclusion,"we find that the performance of the models in our experiments improves when we add pararule-plus in the training, especially on examples that require deeper reasoning depths and extra out-of-distribution examples.",ReSolved,https://export.arxiv.org/pdf/2207.14000v1.pdf
1426,251135345,Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation,conclusion,table 4 we use glove,Neutral,https://export.arxiv.org/pdf/2207.14000v1.pdf
1427,251135345,Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation,conclusion,[16] as the word vector representation.,Neutral,https://export.arxiv.org/pdf/2207.14000v1.pdf
1428,251135345,Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation,conclusion,we use pararules with all depths as the training set for all models and then test them on examples with different reasoning depths (d).,ReSolved,https://export.arxiv.org/pdf/2207.14000v1.pdf
1429,251135345,Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation,conclusion,"comparison among our ima-glove-ga, ima-glove, mac-glove, dmn-glove, imasm-glove, lstm-glove, and roberta-large on pararules test sets with different reasoning depths.",Neutral,https://export.arxiv.org/pdf/2207.14000v1.pdf
1430,246016282,Reasoning over Hybrid Chain for Table-and-Text Open Domain QA,conclusion,"in this paper, we present a chain-centric reasoning and pre-training (carp) framework for table-andtext question answering.",ReSolved,https://arxiv.org/pdf/2201.05880v1.pdf
1431,246016282,Reasoning over Hybrid Chain for Table-and-Text Open Domain QA,conclusion,"when answering the questions given retrieved table and passages, carp first extracts explicit hybrid chain to reveal the intermediate reasoning process leading to the answer across table and text.",ReSolved,https://arxiv.org/pdf/2201.05880v1.pdf
1432,246016282,Reasoning over Hybrid Chain for Table-and-Text Open Domain QA,conclusion,"the hybrid chain provides a guidance for qa, and explanation of the intermediate reasoning process.",ReSolved,https://arxiv.org/pdf/2201.05880v1.pdf
1433,246016282,Reasoning over Hybrid Chain for Table-and-Text Open Domain QA,conclusion,"to enhance the extraction model with better reasoning ability and alleviate data sparsity problem, we design a novel chaincentric pre-training method.",ReSolved,https://arxiv.org/pdf/2201.05880v1.pdf
1434,246016282,Reasoning over Hybrid Chain for Table-and-Text Open Domain QA,conclusion,"this method synthesizes the reasoning corpus in a larger scale and of higher reasoning complexity, which is achieved by automatically synthesizing heterogeneous reasoning paths from tables and passages in wikipedia and reversely generating multi-hop questions.",ReSolved,https://arxiv.org/pdf/2201.05880v1.pdf
1435,246016282,Reasoning over Hybrid Chain for Table-and-Text Open Domain QA,conclusion,"we find that the pre-training task boosts performance on the hybrid chain extraction model, especially for questions requiring more complex reasoning, which leads to significant improvement on the performance of the qa model.",ReSolved,https://arxiv.org/pdf/2201.05880v1.pdf
1436,246016282,Reasoning over Hybrid Chain for Table-and-Text Open Domain QA,conclusion,the hybrid chain also provides better interpretability of the reasoning process.,ReSolved,https://arxiv.org/pdf/2201.05880v1.pdf
1437,253237103,RLET: A Reinforcement Learning Based Approach for Explainable QA with Entailment Trees,conclusion,"we presented rlet, a rl-based entailment tree generation framework, which contains sentences selection and deduction generation modules and can be trained with cumulative signals across the entire reasoning tree.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.483.pdf
1438,253237103,RLET: A Reinforcement Learning Based Approach for Explainable QA with Entailment Trees,conclusion,experiments show that rlet outperforms existing baselines on structure correctness and is applicable in practical scenarios.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.483.pdf
1439,253237103,RLET: A Reinforcement Learning Based Approach for Explainable QA with Entailment Trees,conclusion,future directions include applying rl framework on other stepwise methods with more stable and sophisticated rl algorithms.,Finding,https://www.aclanthology.org/2022.emnlp-main.483.pdf
1440,58008636,Genetic variability of myostatin and prolactin genes in popular goat breeds in Egypt,conclusion,"in the end, this study is considered to be a step advancing for further studies that may add to give additional information about the genetic polymorphism of meat and growth characters of egyptian goat breeds and the improvement of these economically important traits.",ReSolved,
1441,14182996,Integrating miRNA and mRNA Expression Profiling Uncovers miRNAs Underlying Fat Deposition in Sheep,conclusion,"in conclusion, we identified a number of mirnas that are differentially expressed between the fat-tailed and short-tailed sheep breeds.",ReSolved,
1442,14182996,Integrating miRNA and mRNA Expression Profiling Uncovers miRNAs Underlying Fat Deposition in Sheep,conclusion,"we further highlighted gene targets of related mirnas that may be involved in regulating fat deposition and adiposeness, in sheep and other livestock.",ReSolved,
1443,14182996,Integrating miRNA and mRNA Expression Profiling Uncovers miRNAs Underlying Fat Deposition in Sheep,conclusion,"this occurs via the key signaling pathways including focal adhesion, pyruvate metabolism, and the mapk, foxo, and tnf signaling pathway.",Neutral,
1444,14182996,Integrating miRNA and mRNA Expression Profiling Uncovers miRNAs Underlying Fat Deposition in Sheep,conclusion,further studies are needed to verify the correlation between key mirnas and their target genes by in vitro approach and elucidate the functional impacts that mirnas serve during adiposeness.,Finding,
1445,14182996,Integrating miRNA and mRNA Expression Profiling Uncovers miRNAs Underlying Fat Deposition in Sheep,conclusion,"our results also provide evidence for the interaction of mirnas and genes in the regulation of obesity and metabolic syndromes, which suggests that this may serve as an animal model for human' obesity and metabolic syndromes researches.",ReSolved,
1446,160009340,Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction,conclusion,"we consider that the main contributions of our study are (1) the proposed qfe model that is based on a summarization model for the explainable multi-hop qa, (2) the dependency among the evidence and the coverage of the question due to the usage of the summarization model, and (3) the state-of-the-art performance in evidence extraction in both rc and rte tasks.",ReSolved,https://arxiv.org/pdf/1905.08511v1.pdf
1447,102352338,Tracking Discrete and Continuous Entity State for Process Understanding,conclusion,"in this paper, we present a structured architecture for entity tracking which leverages both the discrete and continuous characterization of the entity evolution.",ReSolved,https://www.aclweb.org/anthology/W19-1502.pdf
1448,102352338,Tracking Discrete and Continuous Entity State for Process Understanding,conclusion,we use a neural crf approach to model our discrete constraints while tracking entities and locations recurrently.,ReSolved,https://www.aclweb.org/anthology/W19-1502.pdf
1449,102352338,Tracking Discrete and Continuous Entity State for Process Understanding,conclusion,our model achieves state of the art results on the propara dataset.,ReSolved,https://www.aclweb.org/anthology/W19-1502.pdf
1450,234334015,ExpMRC: explainability evaluation for machine reading comprehension,conclusion,"in this paper, we propose a comprehensive benchmark for evaluating the explainability of mrc systems.",ReSolved,https://arxiv.org/pdf/2105.04126v1.pdf
1451,234334015,ExpMRC: explainability evaluation for machine reading comprehension,conclusion,"the proposed expmrc benchmark contains four datasets, including squad, cmrc 2018, race + , c 3 , covering span-extraction mrc and multiple-choice mrc in both en- glish and chinese.",ReSolved,https://arxiv.org/pdf/2105.04126v1.pdf
1452,234334015,ExpMRC: explainability evaluation for machine reading comprehension,conclusion,expmrc aims to evaluate the mrc system to give not only correct predictions on the final answer but also extract correct evidence for the answer.,ReSolved,https://arxiv.org/pdf/2105.04126v1.pdf
1453,234334015,ExpMRC: explainability evaluation for machine reading comprehension,conclusion,we set up several baseline systems to thoroughly evaluate the difficulties of expmrc.,ReSolved,https://arxiv.org/pdf/2105.04126v1.pdf
1454,234334015,ExpMRC: explainability evaluation for machine reading comprehension,conclusion,"the experimental results show that both traditional and state-of-the-art pre-trained language models still underperform human performance by a large margin on most of the subsets, indicating that more efforts should be made on designing an effective approach for evidence extraction.",ReSolved,https://arxiv.org/pdf/2105.04126v1.pdf
1455,234334015,ExpMRC: explainability evaluation for machine reading comprehension,conclusion,"we hope the release of the dataset will further accelerate the research on the explainability and interpretability of mrc systems, especially for the unsupervised approaches.",Neutral,https://arxiv.org/pdf/2105.04126v1.pdf
1456,2787275,A Model Approximation Scheme for Planning in Partially Observable Stochastic Domains,conclusions,we propose to approximate a pomdp by using a region observable pomdp.,ReSolved,https://arxiv.org/pdf/cs/9711103v1.pdf
1457,2787275,A Model Approximation Scheme for Planning in Partially Observable Stochastic Domains,conclusions,the region observable pomdp has more informative observations and hence is easier to solve.,Neutral,https://arxiv.org/pdf/cs/9711103v1.pdf
1458,2787275,A Model Approximation Scheme for Planning in Partially Observable Stochastic Domains,conclusions,"a method for determining approximation quality is described, which allows one to make the tradeo between approximation quality and computational time by starting with a coarse approximation and re ning it gradually.",ReSolved,https://arxiv.org/pdf/cs/9711103v1.pdf
1459,2787275,A Model Approximation Scheme for Planning in Partially Observable Stochastic Domains,conclusions,"simulation experiments have shown that when there is not much uncertainty in the e ects of actions and observations are informative, a pomdp can be accurately approximated by a region observable pomdp that can be solved exactly.",ReSolved,https://arxiv.org/pdf/cs/9711103v1.pdf
1460,2787275,A Model Approximation Scheme for Planning in Partially Observable Stochastic Domains,conclusions,"however, this becomes infeasible as the degree of uncertainty increases.",Finding,https://arxiv.org/pdf/cs/9711103v1.pdf
1461,2787275,A Model Approximation Scheme for Planning in Partially Observable Stochastic Domains,conclusions,"other approximate methods need to be incorporated in order to solve region observable pomdps whose radiuses are not small. proof of proposition 3: because of proposition 1 and lemma 4, it su ces to show that 3.",Neutral,https://arxiv.org/pdf/cs/9711103v1.pdf
1462,2787275,A Model Approximation Scheme for Planning in Partially Observable Stochastic Domains,conclusions,"if x , return nil, else return b.",Neutral,https://arxiv.org/pdf/cs/9711103v1.pdf
1463,247762238,Lite Unified Modeling for Discriminative Reading Comprehension,conclusion,"in this work, we propose pos-enhanced iterative co-attention network (poi-net), as a lightweight unified modeling for multiple subcategories of discriminative mrc.",ReSolved,https://www.aclanthology.org/2022.acl-long.594.pdf
1464,247762238,Lite Unified Modeling for Discriminative Reading Comprehension,conclusion,"poi-net utilizes pos embedding to encode pos attributes for the preciseness of answer boundary, and iterative co-attention mechanism with integration strategy is employed to highlight and integrate critical information at decoding aspect, with almost no additional parameter.",ReSolved,https://www.aclanthology.org/2022.acl-long.594.pdf
1465,247762238,Lite Unified Modeling for Discriminative Reading Comprehension,conclusion,"as the first effective and unified modeling with pertinence for different types of discriminative mrc, evaluation results on four extractive and multi-choice mrc benchmarks consistently indicate the general effectiveness and applicability of our model.",ReSolved,https://www.aclanthology.org/2022.acl-long.594.pdf
1466,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"in this paper, we proposed a novel uni-encoder model, sparse retriever using a dual document encoder (spade), to alleviate the trade-off between effectiveness and efficiency of the ir system.",ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1467,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,we adopted a dual document encoder for lexical and semantic matching and developed a co-training strategy to mitigate the training intervention between encoders.,ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1468,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"we also utilized document-and corpus-level pruning during model training, enabling efficient retrieval using the inverted index.",ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1469,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"experimental results showed that spade achieves state-of-the-art performance among uni-encoder models with acceptable query latency, notably preferable for commercial ir systems.  ",ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1470,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,a document retrieval table 7 shows the performance of spade with other baselines on the ms marco document ranking dataset.,Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1471,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"dr (random neg) and dr (bm25 neg) represent dense retrieval models trained with random and bm25 negatives, respectively.",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1472,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,all dense retrieval models use roberta-base [36] as an encoder and [cls] token embedding for query and document representations.,Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1473,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"the experimental results of them are copied from [74,75]. unicoil and unicoil-dt5q performed indexing on segmented passages, and the score of the segmented passage that obtained the highest score is used as the score of the document, i.e., maxp technique [10].",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1474,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"other models, including spade, use only the first part of the document truncated to bert's max length.",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1475,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"we use official metrics for ms marco document ranking task, i.e., mrr@100 and recall@100.",ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1476,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"as a result, spade achieves the best performance among baselines using sparse representations.",ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1477,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"it may seem similar to the passage ranking task results, but spade's effectiveness is more highlighted in long documents.",ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1478,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"for example, in the passage ranking, mrr@10 performance of unicoil and spade were 0.351 and 0.353, respectively, but in the document ranking, spade significantly outperforms it by 0.369 versus 0.353.",ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1479,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"secondly, ance shows high ranking performance, i.e., mrr, compared to spade, but spade has better recall performance.",ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1480,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"if compared considering the same mrr performance, uni-encoder outperforms bi-encoder in terms of recall.",ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1481,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"this trend, which was not shown before, suggests that focusing on intrinsic lexical matching signals may be more effective than learning representations of both documents and queries in the long document environment where vocabulary mismatching occurs relatively less.",Finding,https://export.arxiv.org/pdf/2209.05917v2.pdf
1482,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"in other words, as the first-stage retriever in document ranking, the uni-encoder method may be more favorable than the bi-encoder method.",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1483,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,b effects of figure 5 shows the effect of the aggregating hyperparameter .,Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1484,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"using the dual encoder, i.e., 0 < < 1, mostly shows better performance than using a mere single encoder, i.e., = 0 or = 1, depicting that each encoder only captures complementary information to another.",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1485,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"spade (k=10) shows the best performance at = 0.4 with 0.352 in mrr@10, implying that the term weighting encoder is more dominant than the term expansion encoder.",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1486,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,figure 6 shows the effect of corpus-level pruning of spade.,Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1487,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"since new relevant terms are appended through the term expansion component without cutoff based on an approximate document frequency, the number of elements in the term-document matrix is enormous, at about 1.1 billion, implying query processing is very costly, e.g., 510 ms per query.",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1488,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"to reduce the query latency, we use corpus-level pruning introduced in section 3.4.",ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1489,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"specifically, during the model training, terms with high document frequency are pruned, and the model learns document representations only with the remaining terms.",ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1490,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,there is a trade-off between effectiveness and efficiency depending on the cutoff ratio.,Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1491,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,when the threshold is set   figure 7 shows the ndcg@10 on each query of spade and deep-impact [43].,Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1492,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"while deepimpact [43] is better than spade in trec dl 2019, spade is better than deepimpact [43] in trec dl 2020.",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1493,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,our analysis found that incorrect queries of spade on trec dl 2019 mostly include relatively rare words.,ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1494,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,we conjecture that the term weighting component is difficult to assign high weighting scores on rare words because our learning scheme heavily depends on the document corpus.,Finding,https://export.arxiv.org/pdf/2209.05917v2.pdf
1495,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,table 8 shows the weighted document terms and expanded terms.,Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1496,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,spade can identify important terms and expand new terms of spade and deepimpact [43].,ReSolved,https://export.arxiv.org/pdf/2209.05917v2.pdf
1497,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"for the query ""what is a nonconformity? earth science"", spade gives high scores for the important terms, e.g., ""nonconformity"" and expanding the terms, e.g., ""science"", which are matched to the query.",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1498,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"owing to enriched document representations, spade can rank a given relevant document in the 27th place, where the core terms of the query, e.g., ""earth"", ""science"", do not appear in the document.",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1499,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"meanwhile, even though deepimpact [43] identifies important document terms, the given document is ranked 77th since query terms are not properly expanded by doct5query",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1500,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,spade accurately expands the query terms by inferring the relevant words.,Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1501,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"for the query ""dog day afternoon meaning"", spade weights for the important terms, e.g., ""dog"", ""day"", ""afternoon"".",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1502,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"moreover, spade successfully expands terms such as ""warm"", ""weather"", ""hottest"", which are highly related to the query.",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1503,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"for the query ""what is the most popular food in switzerland"", both deepimpact and spade give high weights for the important terms and expand relevant terms which are matched to the query, e.g., ""switzerland"", ""popular"", ""most"".",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1504,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,1 lack of conformity ; nonconformity .,Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1505,252212320,SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval Young-In Song a Dual Document Encoder for First-stage Retrieval. In Proceedings of the 31st ACM International Conference on Information and Knowledge Management * Equal contribution † Corresponding author Figure 1: MRR@10 and average query latency (in ms) on MS MARCO development set of SpaDE varying the size of top-masking for the document-level pruning and existing retrievers with sparse representations. The latency is mea- sured with PISA [44] using Block-Max WAND [14],conclusion,"2 geology a surface between successive strata representing a missing interval in the geologic record of time , and produced either by an interruption in deposition or by the erosion of depositionally continuous strata followed by renewed deposition .",Neutral,https://export.arxiv.org/pdf/2209.05917v2.pdf
1506,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,limitation discussion,we provide a new interpretability evaluation benchmark which contains three tasks with both english and chinese annotated data.,ReSolved,https://www.aclanthology.org/2022.conll-1.6.pdf
1507,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,limitation discussion,there are three limitations in our work.• how to evaluate the quality of human-annotated rationales is still open.,Finding,https://www.aclanthology.org/2022.conll-1.6.pdf
1508,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,limitation discussion,we have several annotators to perform quality control based on human intuitions and experiences.,ReSolved,https://www.aclanthology.org/2022.conll-1.6.pdf
1509,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,limitation discussion,"meanwhile, we compare model behaviors on full inputs and human annotated rationales to evaluate the sufficiency and comprehensiveness of rationales, as shown in table 4 and table 7.",ReSolved,https://www.aclanthology.org/2022.conll-1.6.pdf
1510,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,limitation discussion,"however, this manner has damaged the original input distribution and brings uncontrollable factors on model behaviors.",Finding,https://www.aclanthology.org/2022.conll-1.6.pdf
1511,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,limitation discussion,"therefore, how to automatically and effectively evaluate the quality of human-annotated rationales should be studied in the future.• we find that the interpretability of model architectures and saliency methods vary with tasks, especially with the input form of the task.",Finding,https://www.aclanthology.org/2022.conll-1.6.pdf
1512,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,limitation discussion,"thus our benchmark should contain more datasets of each task type ( e.g., single-sentence task, sentencepair similarity task and sentence-pair inference task) to further verify these findings.",Finding,https://www.aclanthology.org/2022.conll-1.6.pdf
1513,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,limitation discussion,"and we will build evaluation datasets for more tasks in the future.• due to space limitation, there is no analysis of the relationships between metrics, e.g., the relationship between plausibility and accuracy, and the relationship between faithfulness and robustness.",Finding,https://www.aclanthology.org/2022.conll-1.6.pdf
1514,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,limitation discussion,"we will take these analyses in our future work.finally, we hope more evaluation metrics and analyses are proposed based on our benchmark.",Finding,https://www.aclanthology.org/2022.conll-1.6.pdf
1515,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,limitation discussion,and we hope our benchmark can facilitate the research progress of interpertability.,Neutral,https://www.aclanthology.org/2022.conll-1.6.pdf
1516,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,conclusion,"we propose a new fine-grained interpretability evaluation benchmark, containing token-level rationales, a new evaluation metric and corresponding perturbed examples for three typical nlp tasks, i.e., sentiment analysis, textual similarity and machine reading comprehension.",ReSolved,https://www.aclanthology.org/2022.conll-1.6.pdf
1517,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,conclusion,"the rationales in this benchmark meet primary properties that a rationale should satisfy, i.e., sufficiency, compactness and comprehensiveness.",Neutral,https://www.aclanthology.org/2022.conll-1.6.pdf
1518,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,conclusion,the experimental results on three models and three saliency methods prove that our benchmark can be used to evaluate interpretability of both models and saliency methods.,ReSolved,https://www.aclanthology.org/2022.conll-1.6.pdf
1519,248987702,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,conclusion,"we will release this benchmark and hope it can facilitate progress on several directions, such as better interpretability evaluation metrics and causal analysis of nlp models.",ReSolved,https://www.aclanthology.org/2022.conll-1.6.pdf
1520,258418300,A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning,conclusion,"we have proposed ugr, a novel unified generative retriever, which can robustly serve different retrieval tasks for knowledge-intensive language tasks.",ReSolved,https://export.arxiv.org/pdf/2304.14856v1.pdf
1521,258418300,A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning,conclusion,"to unify retrieval tasks, we formulated the retrieval problem as a conditional generation problem and introduced an n-gram-based identifier for relevant contexts at different levels of granularity.",ReSolved,https://export.arxiv.org/pdf/2304.14856v1.pdf
1522,258418300,A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning,conclusion,"to learn different retrieval tasks with a single model, we mapped the descriptions of tasks to a few prompt tokens for keeping task specifications.",Neutral,https://export.arxiv.org/pdf/2304.14856v1.pdf
1523,258418300,A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning,conclusion,empirical results on the kilt benchmark demonstrated the superiority of the proposed method.,ReSolved,https://export.arxiv.org/pdf/2304.14856v1.pdf
1524,258418300,A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning,conclusion,efficiently integrating knowledge from different retrieval tasks in ugr has the potential to save significant time and computational resources in both academic and industrial environments.,Finding,https://export.arxiv.org/pdf/2304.14856v1.pdf
1525,258418300,A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning,conclusion,"however, ugr needs a complex scoring function to solve the identifier repetition problem; we encourage future work that explores other effective and efficient semantic identifiers for generative retrieval.",Finding,https://export.arxiv.org/pdf/2304.14856v1.pdf
1526,258418300,A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning,conclusion,"beyond kilt, training a more general unified generative retrieval model to serve different retrieval applications under multiple corpora and modalities seems a promising future direction.",Finding,https://export.arxiv.org/pdf/2304.14856v1.pdf
1527,218487313,Unsupervised Alignment-based Iterative Evidence Retrieval for Multi-hop Question Answering,conclusion,"we introduced a simple, unsupervised approach for evidence retrieval for question answering.",ReSolved,https://www.aclweb.org/anthology/2020.acl-main.414.pdf
1528,218487313,Unsupervised Alignment-based Iterative Evidence Retrieval for Multi-hop Question Answering,conclusion,"our approach combines three ideas: (a) an unsupervised alignment approach to soft-align questions and answers with justification sentences using glove embeddings, (b) an iterative process that reformulates queries focusing on terms that are not covered by existing justifications, and (c) a simple stopping condition that concludes the iterative process when all terms in the given question and candidate answers are covered by the retrieved justifications.",ReSolved,https://www.aclweb.org/anthology/2020.acl-main.414.pdf
1529,218487313,Unsupervised Alignment-based Iterative Evidence Retrieval for Multi-hop Question Answering,conclusion,"overall, despite its simplicity, unsupervised nature, and its sole reliance on glove embeddings, our approach outperforms all previous methods (including supervised ones) on the evidence selection task on two datasets: multirc and qasc.",ReSolved,https://www.aclweb.org/anthology/2020.acl-main.414.pdf
1530,218487313,Unsupervised Alignment-based Iterative Evidence Retrieval for Multi-hop Question Answering,conclusion,"when these evidence sentences are fed into a roberta answer classification component, we achieve the best qa performance on these two datasets.",ReSolved,https://www.aclweb.org/anthology/2020.acl-main.414.pdf
1531,218487313,Unsupervised Alignment-based Iterative Evidence Retrieval for Multi-hop Question Answering,conclusion,"further, we show that considerable improvements can be obtained by aggregating knowledge from parallel evidence chains retrieved by our method.",ReSolved,https://www.aclweb.org/anthology/2020.acl-main.414.pdf
1532,218487313,Unsupervised Alignment-based Iterative Evidence Retrieval for Multi-hop Question Answering,conclusion,"in addition of improving qa, we hypothesize that these simple unsupervised components of air will benefit future work on supervised neural iterative retrieval approaches by improving their query reformulation algorithms and termination criteria.",Finding,https://www.aclweb.org/anthology/2020.acl-main.414.pdf
1533,244799249,ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction,conclusion,"we introduced colbertv2, a retriever that advances the quality and space efficiency of multivector representations.",ReSolved,https://www.aclanthology.org/2022.naacl-main.272.pdf
1534,244799249,ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction,conclusion,we hypothesized that cluster centroids capture context-aware semantics of the token-level representations and proposed a residual representation that leverages these patterns to dramatically reduce the footprint of multi-vector systems off-the-shelf.,ReSolved,https://www.aclanthology.org/2022.naacl-main.272.pdf
1535,244799249,ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction,conclusion,we then explored improved supervision for multi-vector retrieval and found that their quality improves considerably upon distillation from a cross-encoder system.,ReSolved,https://www.aclanthology.org/2022.naacl-main.272.pdf
1536,244799249,ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction,conclusion,"the proposed colbertv2 considerably outperforms existing retrievers in within-domain and out-of-domain evaluations, which we conducted extensively across 28 datasets, establishing state-of-the-art quality while exhibiting competitive space footprint.",ReSolved,https://www.aclanthology.org/2022.naacl-main.272.pdf
1537,254877343,HYRR: Hybrid Infused Reranking for Passage Retrieval,conclusion,we proposed a generic training framework for rerankers based on a hybrid retriever.,ReSolved,https://export.arxiv.org/pdf/2212.10528v1.pdf
1538,254877343,HYRR: Hybrid Infused Reranking for Passage Retrieval,conclusion,"while the hybrid retriever is composed of term-based and neural models, the reranker is a neural cross-attention model which learns from negatives examples generated by the hybrid retriever.",Neutral,https://export.arxiv.org/pdf/2212.10528v1.pdf
1539,254877343,HYRR: Hybrid Infused Reranking for Passage Retrieval,conclusion,"the proposed approach is robust and outperforms several strong baselines on ms marco passage ranking task and beir benchmark dataset, which demonstrates that it is practical and generalized.",ReSolved,https://export.arxiv.org/pdf/2212.10528v1.pdf
1540,254877343,HYRR: Hybrid Infused Reranking for Passage Retrieval,conclusion,"we observe that a model trained with robust training instances (in this case, from the hybrid retriever) produces a reranker that outperforms matched-training rerankers for termbased or neural retrievers.",ReSolved,https://export.arxiv.org/pdf/2212.10528v1.pdf
1541,257921404,Rethinking the Role of Token Retrieval in Multi-Vector Retrieval,conclusion,multi-vector retrieval leverages query and document token representations for effective information retrieval.,Neutral,https://export.arxiv.org/pdf/2304.01982v2.pdf
1542,257921404,Rethinking the Role of Token Retrieval in Multi-Vector Retrieval,conclusion,"in this paper, we propose xtr that simplifies the existing three-stage inference of multivector models by improving the initial token retrieval stage.",ReSolved,https://export.arxiv.org/pdf/2304.01982v2.pdf
1543,257921404,Rethinking the Role of Token Retrieval in Multi-Vector Retrieval,conclusion,"specifically, xtr scores documents solely based on the retrieved tokens, which is also optimized during training with in-batch document tokens.",Neutral,https://export.arxiv.org/pdf/2304.01982v2.pdf
1544,257921404,Rethinking the Role of Token Retrieval in Multi-Vector Retrieval,conclusion,"as a result, xtr achieves state-of-the-art performances on zero-shot information retrieval benchmarks while greatly reducing the flops of the scoring stage.",ReSolved,https://export.arxiv.org/pdf/2304.01982v2.pdf
1545,257921404,Rethinking the Role of Token Retrieval in Multi-Vector Retrieval,conclusion,"we further show that indeed our objective encourages better token retrieval, retrieving more tokens from gold documents, whose contexts are better aligned with the query.",ReSolved,https://export.arxiv.org/pdf/2304.01982v2.pdf
1546,232380161,DAGN: Discourse-Aware Graph Network for Logical Reasoning,conclusion,"in this paper, we introduce a discourse-aware graph network (dagn) to addressing logical reasoning qa tasks.",ReSolved,https://www.aclweb.org/anthology/2021.naacl-main.467.pdf
1547,232380161,DAGN: Discourse-Aware Graph Network for Logical Reasoning,conclusion,we first treat elementary discourse units (edus) that are split by discourse relations as basic reasoning units.,Neutral,https://www.aclweb.org/anthology/2021.naacl-main.467.pdf
1548,232380161,DAGN: Discourse-Aware Graph Network for Logical Reasoning,conclusion,we then build discourse-based logic graphs with edus as nodes and discourse relations as edges.,Neutral,https://www.aclweb.org/anthology/2021.naacl-main.467.pdf
1549,232380161,DAGN: Discourse-Aware Graph Network for Logical Reasoning,conclusion,dagn then learns the discourse-based features and enhances them with contextual token embeddings.,ReSolved,https://www.aclweb.org/anthology/2021.naacl-main.467.pdf
1550,232380161,DAGN: Discourse-Aware Graph Network for Logical Reasoning,conclusion,dagn reaches competitive performances on two recent logical reasoning datasets reclor and logiqa.,ReSolved,https://www.aclweb.org/anthology/2021.naacl-main.467.pdf
1551,252819276,Modeling Hierarchical Reasoning Chains by Linking Discourse Units and Key Phrases for Reading Comprehension,conclusion,this paper presents a novel method to guide the mrc model to better perform logical reasoning tasks.,ReSolved,https://www.aclanthology.org/2022.coling-1.126.pdf
1552,252819276,Modeling Hierarchical Reasoning Chains by Linking Discourse Units and Key Phrases for Reading Comprehension,conclusion,we propose a holistic graph-based system to model hierarchical logical reasoning chains.,ReSolved,https://www.aclanthology.org/2022.coling-1.126.pdf
1553,252819276,Modeling Hierarchical Reasoning Chains by Linking Discourse Units and Key Phrases for Reading Comprehension,conclusion,"to our best knowledge, we are the first to deal with context at both discourse level and phrase level as the basis for logical reasoning.",ReSolved,https://www.aclanthology.org/2022.coling-1.126.pdf
1554,252819276,Modeling Hierarchical Reasoning Chains by Linking Discourse Units and Key Phrases for Reading Comprehension,conclusion,"to decouple the interaction between the node features and type features, we apply hierarchical interaction mechanism to yield the appropriate representation for reading comprehension.",ReSolved,https://www.aclanthology.org/2022.coling-1.126.pdf
1555,252819276,Modeling Hierarchical Reasoning Chains by Linking Discourse Units and Key Phrases for Reading Comprehension,conclusion,"on the logical qa benchmarks (reclor, logiqa) and natural language inference benchmarks (snli and anli), our proposed model has been shown effective by significantly outperforming the strong baselines.",ReSolved,https://www.aclanthology.org/2022.coling-1.126.pdf
1556,248218748,Towards Fine-grained Causal Reasoning and QA,conclusion,we explored the efficacy of current state-of-the-art methods for causal reasoning tasks by considering a novel fine-grained reasoning setting and developing a dataset with rich human labels.,ReSolved,https://arxiv.org/pdf/2204.07408v1.pdf
1557,248218748,Towards Fine-grained Causal Reasoning and QA,conclusion,"experimental results using the state-of-the-art pre-trained language models provide the evidence that there is much room for improvement on causal reasoning tasks, and a need for designing better solutions to correlation discovery related to event causality analysis and why/what-if qa tasks.",Finding,https://arxiv.org/pdf/2204.07408v1.pdf
1558,202573071,CTRL: A CONDITIONAL TRANSFORMER LANGUAGE MODEL FOR CONTROLLABLE GENERATION,conclusion,"with 1.63 billion parameters, ctrl is the largest publicly released language model to date.",ReSolved,https://arxiv.org/pdf/1909.05858v2.pdf
1559,202573071,CTRL: A CONDITIONAL TRANSFORMER LANGUAGE MODEL FOR CONTROLLABLE GENERATION,conclusion,it is trained with control codes so that text generation can be more easily controlled by human users.,ReSolved,https://arxiv.org/pdf/1909.05858v2.pdf
1560,202573071,CTRL: A CONDITIONAL TRANSFORMER LANGUAGE MODEL FOR CONTROLLABLE GENERATION,conclusion,"these codes allow users to explicitly specify domain, subdomain, entities, relationships between entities, dates, and task-specific behavior.",ReSolved,https://arxiv.org/pdf/1909.05858v2.pdf
1561,202573071,CTRL: A CONDITIONAL TRANSFORMER LANGUAGE MODEL FOR CONTROLLABLE GENERATION,conclusion,"we hope that the release of this model at https://github.com/salesforce/ctrl pushes towards more controllable, general models for natural language processing, and we encourage future discussion about artificial generation with our team by emailing ctrl-monitoring@salesforce.com.   table 3).",Neutral,https://arxiv.org/pdf/1909.05858v2.pdf
1562,202573071,CTRL: A CONDITIONAL TRANSFORMER LANGUAGE MODEL FOR CONTROLLABLE GENERATION,conclusion,"for all the reddit data, the secondary code can be title: or text:, which is the title and text of the article, respectively.",Neutral,https://arxiv.org/pdf/1909.05858v2.pdf
1563,235727345,Springer Nature 2021 L A T E X template A Heterogeneous Graph Attention Network for Multi-hop Machine Reading Comprehension,conclusion,"we present the cluereader, a heterogeneous graph attention network for multi-hop machine reading comprehension, which is inspired by the grandmother cells concept from cognitive neuroscience.",ReSolved,https://export.arxiv.org/pdf/2107.00841v2.pdf
1564,235727345,Springer Nature 2021 L A T E X template A Heterogeneous Graph Attention Network for Multi-hop Machine Reading Comprehension,conclusion,the network contains several clue reading paths from the subject of the question and ends with the given candidates' entities.,Neutral,https://export.arxiv.org/pdf/2107.00841v2.pdf
1565,235727345,Springer Nature 2021 L A T E X template A Heterogeneous Graph Attention Network for Multi-hop Machine Reading Comprehension,conclusion,we take the reasoning nodes and mention nodes to complete the process and use document nodes to add supernumerary semantic information.,ReSolved,https://export.arxiv.org/pdf/2107.00841v2.pdf
1566,235727345,Springer Nature 2021 L A T E X template A Heterogeneous Graph Attention Network for Multi-hop Machine Reading Comprehension,conclusion,"we apply our methodology in qanga-roo, a multi-hop mrc dataset, and the official evaluation supports the effectiveness of our model in open-domain qa and molecular biology domain usage.",ReSolved,https://export.arxiv.org/pdf/2107.00841v2.pdf
1567,234479457,"A Multilingual Modeling Method for Span-Extraction Reading Comprehension CCS CONCEPTS • Computing methodologies → Natural language processing; Multilingual modeling KEYWORDS multilingual modeling, span-extraction reading comprehension, multilingual attention, self-adaptive attention",conclusion,"despite tremendous advances have been made in the field of spanextraction reading comprehension in recent years, large-scale highquality extractive qa datasets in languages other than english remain scarce, and collecting such a sufficient amount of training data for each language is costly, and even impossible, making training reading comprehension systems in other languages challenging.",Finding,https://arxiv.org/pdf/2105.14880v1.pdf
1568,234479457,"A Multilingual Modeling Method for Span-Extraction Reading Comprehension CCS CONCEPTS • Computing methodologies → Natural language processing; Multilingual modeling KEYWORDS multilingual modeling, span-extraction reading comprehension, multilingual attention, self-adaptive attention",conclusion,"to make full use of all existing extractive training datasets in various languages and to learn the rich hidden semantic knowledge from different language families, we propose xlrc, a multilingual extractive reading comprehension method, to simultaneously model the existing extractive reading comprehension training data in a multilingual environment by using multilingual bert and multilingual attention.",ReSolved,https://arxiv.org/pdf/2105.14880v1.pdf
1569,234479457,"A Multilingual Modeling Method for Span-Extraction Reading Comprehension CCS CONCEPTS • Computing methodologies → Natural language processing; Multilingual modeling KEYWORDS multilingual modeling, span-extraction reading comprehension, multilingual attention, self-adaptive attention",conclusion,experimental results demonstrate the effectiveness of our proposed multilingual modelling by transferring the semantic knowledge learned from various existing datasets in different languages.,ReSolved,https://arxiv.org/pdf/2105.14880v1.pdf
1570,256827818,Few-shot Reranking for Multi-hop QA via Language Model Prompting,conclusion,"we introduced promptrank, a method to perform few-shot reranking of multi-document paths for multi-hop question answering based on large language models.",ReSolved,https://export.arxiv.org/pdf/2205.12650v2.pdf
1571,256827818,Few-shot Reranking for Multi-hop QA via Language Model Prompting,conclusion,experiments on a standard multihop qa benchmark show the strong performance of promptrank in the few-shot setting compared to fully-supervised multi-hop reranking systems.,ReSolved,https://export.arxiv.org/pdf/2205.12650v2.pdf
1572,256827818,Few-shot Reranking for Multi-hop QA via Language Model Prompting,conclusion,future avenues of exploration include combining promptrank with efficient tuning techniques such as prefix tuning and efficient strategies for instruction search.,Finding,https://export.arxiv.org/pdf/2205.12650v2.pdf
1573,253157773,COCO-DR: Combating Distribution Shifts in Zero-Shot Dense Retrieval with Contrastive and Distributionally Robust Learning,conclusion,coco-dr improves zerodr accuracy by combating the distribution shifts using continuous contrastive learning and implicit distributionally robust optimization.,ReSolved,https://export.arxiv.org/pdf/2210.15212v2.pdf
1574,253157773,COCO-DR: Combating Distribution Shifts in Zero-Shot Dense Retrieval with Contrastive and Distributionally Robust Learning,conclusion,coco helps models better capture the sequence representations of target corpora in pretraining.,ReSolved,https://export.arxiv.org/pdf/2210.15212v2.pdf
1575,253157773,COCO-DR: Combating Distribution Shifts in Zero-Shot Dense Retrieval with Contrastive and Distributionally Robust Learning,conclusion,implicit dro improves model robustness by reweighting query clusters in fine-tuning.,ReSolved,https://export.arxiv.org/pdf/2210.15212v2.pdf
1576,253080447,Efficiently Tuned Parameters are Task Embeddings,conclusion,"in this paper, we show that efficiently tuned parameters are highly predictive for inter-task transferability and thus can be used as off-the-shelf task embeddings for source task selection in intermediatetask transfer learning.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.334.pdf
1577,253080447,Efficiently Tuned Parameters are Task Embeddings,conclusion,our empirical investigation with three parameter-efficient tuning methods on 22 nlp tasks demonstrates that our approach outperforms prior works on inter-task transferability prediction despite being more efficient.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.334.pdf
1578,249062558,Is a Question Decomposition Unit All We Need?,conclusion,the recent trend of building large lms may not be sustainable to solve evolving benchmarks.,Neutral,https://www.aclanthology.org/2022.emnlp-main.302.pdf
1579,249062558,Is a Question Decomposition Unit All We Need?,conclusion,we believe that modifying data samples can significantly help the model improve performance.,Finding,https://www.aclanthology.org/2022.emnlp-main.302.pdf
1580,249062558,Is a Question Decomposition Unit All We Need?,conclusion,we study the effect of question decomposition (qd) on a diverse set of tasks.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.302.pdf
1581,249062558,Is a Question Decomposition Unit All We Need?,conclusion,we decompose questions manually and significantly improve model performance (24% for gpt3 and 29% for roberta-squad along with a symbolic calculator).,ReSolved,https://www.aclanthology.org/2022.emnlp-main.302.pdf
1582,249062558,Is a Question Decomposition Unit All We Need?,conclusion,our findings indicate that human-in-the-loop question decomposition (hqd) can potentially provide an alternate path to building large lms.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.302.pdf
1583,249062558,Is a Question Decomposition Unit All We Need?,conclusion,our approach provides a viable option to involve people in nlp research.,Neutral,https://www.aclanthology.org/2022.emnlp-main.302.pdf
1584,249062558,Is a Question Decomposition Unit All We Need?,conclusion,we hope our work will encourage the community to develop human-centric solutions that actively involve humans while leveraging nlp resources.,Neutral,https://www.aclanthology.org/2022.emnlp-main.302.pdf
1585,253080620,LittleBird: Efficient Faster & Longer Transformer for Question Answering,conclusion,"we propose littlebird, which is more efficient in terms of memory and computational time than existing transformer models for long sequences, and its effective way to train.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.352.pdf
1586,253080620,LittleBird: Efficient Faster & Longer Transformer for Question Answering,conclusion,"it combines a novel position encoding method, bialibi, and pack & unpack with sliding window attention to achieve high speed and accuracy, particularly in question answering tasks for long documents.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.352.pdf
1587,253080620,LittleBird: Efficient Faster & Longer Transformer for Question Answering,conclusion,the distillation and training method with padding insertion allows the model to be trained by reusing the existing pre-trained language model for short inputs and work well for long inputs even if trained on short inputs.,Neutral,https://www.aclanthology.org/2022.emnlp-main.352.pdf
1588,253080620,LittleBird: Efficient Faster & Longer Transformer for Question Answering,conclusion,"we demonstrated through experiments that the accuracy of question answering improves as the model is fed a longer input, and we achieved state-of-the-art performance in korquad2.0 using littlebird.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.352.pdf
1589,246294995,Reasoning Like Program Executors,conclusion & future work,"we introduce poet, a new pre-training paradigm for boosting reasoning capability of language models via imitating program executors.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.48.pdf
1590,246294995,Reasoning Like Program Executors,conclusion & future work,"experimental results on six datasets demonstrate that poet can significantly boost existing language models on several reasoning skills, including numerical, logical and multi-hop reasoning.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.48.pdf
1591,246294995,Reasoning Like Program Executors,conclusion & future work,our best language model under poet can reach highly competitive performance with previous specialized models.,ReSolved,https://www.aclanthology.org/2022.emnlp-main.48.pdf
1592,246294995,Reasoning Like Program Executors,conclusion & future work,"in the future, we hope our work could inspire more transference of reasoning knowledge from program executors to models.",Neutral,https://www.aclanthology.org/2022.emnlp-main.48.pdf
1593,246294995,Reasoning Like Program Executors,conclusion & future work,"and we will also investigate the causes of the reasoning transfer with more insightful experiments, since we still do not know how the reasoning transfer occurs.",Finding,https://www.aclanthology.org/2022.emnlp-main.48.pdf
1594,248227284,TABi: Type-Aware Bi-Encoders for Open-Domain Entity Retrieval,conclusion,we introduce a method to train bi-encoders on unstructured text and knowledge graph types through a type-enforced contrastive loss.,ReSolved,https://www.aclanthology.org/2022.findings-acl.169.pdf
1595,248227284,TABi: Type-Aware Bi-Encoders for Open-Domain Entity Retrieval,conclusion,"our loss can improve retrieval of rare entities for ambiguous mentions, while maintaining strong overall performance on open-domain nlp tasks.",ReSolved,https://www.aclanthology.org/2022.findings-acl.169.pdf
1596,248227284,TABi: Type-Aware Bi-Encoders for Open-Domain Entity Retrieval,conclusion,we hope our work inspires future work on integrating structured data into pretrained models.,Neutral,https://www.aclanthology.org/2022.findings-acl.169.pdf
1597,248227284,TABi: Type-Aware Bi-Encoders for Open-Domain Entity Retrieval,conclusion,government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright notation thereon.,Neutral,https://www.aclanthology.org/2022.findings-acl.169.pdf
1598,248227284,TABi: Type-Aware Bi-Encoders for Open-Domain Entity Retrieval,conclusion,"any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views, policies, or endorsements, either expressed or implied, of nih, onr, or the u.s. government.",Neutral,https://www.aclanthology.org/2022.findings-acl.169.pdf
1599,221292890,Continual Domain Adaptation for Machine Reading Com-prehension,conclusion,we introduce the continual domain adaptation task for mrc.,ReSolved,https://arxiv.org/pdf/2008.10874v1.pdf
1600,221292890,Continual Domain Adaptation for Machine Reading Com-prehension,conclusion,"so far as we know, this is the first study on the continual learning perspective of mrc.",ReSolved,https://arxiv.org/pdf/2008.10874v1.pdf
1601,221292890,Continual Domain Adaptation for Machine Reading Com-prehension,conclusion,"we build two datasets cda-q and cda-c for the cda task, by re-organizing existing mrc collections into different domains with respect to the question type and passage type.",ReSolved,https://arxiv.org/pdf/2008.10874v1.pdf
1602,221292890,Continual Domain Adaptation for Machine Reading Com-prehension,conclusion,we conduct preliminary experiments showing the existence of catastrophic forgetting (cf) phenomenon of existing mrc models under the cda setting.,ReSolved,https://arxiv.org/pdf/2008.10874v1.pdf
1603,221292890,Continual Domain Adaptation for Machine Reading Com-prehension,conclusion,"further, we propose regularization-based regbertqa and dynamic-architecture progbertqa to tackle the cda for mrc.",ReSolved,https://arxiv.org/pdf/2008.10874v1.pdf
1604,221292890,Continual Domain Adaptation for Machine Reading Com-prehension,conclusion,we conduct extensive experiments to analysis the effectiveness of both methods and validate that the proposed dynamic-architecture based model achieves the best performance.,ReSolved,https://arxiv.org/pdf/2008.10874v1.pdf
1605,3520779,ATTac-2000: An Adaptive Autonomous Bidding Agent,conclusion and future work,tac-2000 was the rst autonomous bidding agent competition.,Neutral,https://arxiv.org/pdf/1106.0678v1.pdf
1606,3520779,ATTac-2000: An Adaptive Autonomous Bidding Agent,conclusion and future work,"while it was a very successful event, some minor improvements would increase its interest from a multiagent learning perspective.",Finding,https://arxiv.org/pdf/1106.0678v1.pdf
1607,252090148,Interactive Question Answering Systems: Literature Review,conclusion,"in conclusion, we have reviewed a substantial collection of interactive question answering systems (iqass)-related literature published during the past decade.",ReSolved,https://export.arxiv.org/pdf/2209.01621v1.pdf
1608,252090148,Interactive Question Answering Systems: Literature Review,conclusion,"we discovered the literature to be diverse, beginning with adopted methodologies for addressing multiple qa tasks and concluding with a vast array of diverse resources (i.e. knowledge source, and datasets) that are typically utilized to create and evaluate question answering systems (qass).",ReSolved,https://export.arxiv.org/pdf/2209.01621v1.pdf
1609,252090148,Interactive Question Answering Systems: Literature Review,conclusion,"despite the fact that the state-of-the-art is defined by several types of qa solutions, we were able to determine the characteristics shared by the suggested systems that constitute a shared framework.",ReSolved,https://export.arxiv.org/pdf/2209.01621v1.pdf
1610,252090148,Interactive Question Answering Systems: Literature Review,conclusion,"to the best of our knowledge, we are the first to present a unified and comprehensive design that emphasizes the fundamental components and functions of iqass.",ReSolved,https://export.arxiv.org/pdf/2209.01621v1.pdf
1611,250264890,Rationale-Augmented Ensembles in Language Models,conclusion,"in this paper, we have presented a unified framework for rationale-augmented ensembles, and found that rationale sampling in the output space is a key component for achieving improved performance in natural language processing tasks.",ReSolved,https://arxiv.org/pdf/2207.00747v1.pdf
1612,250264890,Rationale-Augmented Ensembles in Language Models,conclusion,"by sampling diverse rationales and ensembling the results, we have shown that rational-ensembling methods in the proposed framework can reliably outperform standard prompting and rationale-based few-shot prompting, across a wide range of natural language tasks and alternative language models.",ReSolved,https://arxiv.org/pdf/2207.00747v1.pdf
1613,250264890,Rationale-Augmented Ensembles in Language Models,conclusion,"overall, rationale-augmented ensembling appears to be a reliable way to shift from the paradigm of (input → output) pairs to (input, rationale → output) pairs to achieve more accurate and interpretable natural language processing.",ReSolved,https://arxiv.org/pdf/2207.00747v1.pdf
1614,237605111,BiRdQA: A Bilingual Dataset for Question Answering on Tricky Riddles,conclusion,"in this paper, we introduce birdqa, a large-scale, bilingual multiple-choice question answering dataset to facilitate the development of qa systems capable of solving tricky riddles.",ReSolved,https://arxiv.org/pdf/2109.11087v2.pdf
1615,237605111,BiRdQA: A Bilingual Dataset for Question Answering on Tricky Riddles,conclusion,the huge gap between the human and machine leaves much room for improvement.,Finding,https://arxiv.org/pdf/2109.11087v2.pdf
1616,237605111,BiRdQA: A Bilingual Dataset for Question Answering on Tricky Riddles,conclusion,"in future work, we plan to extend birdqa with riddles in other languages and incorporate figurative language understanding into riddle solving.",Finding,https://arxiv.org/pdf/2109.11087v2.pdf
1617,237605111,BiRdQA: A Bilingual Dataset for Question Answering on Tricky Riddles,conclusion,we hope that birdqa will stir more research for question answering on riddles.,Finding,https://arxiv.org/pdf/2109.11087v2.pdf
1618,250390947,Explicit Graph Reasoning Fusing Knowledge and Contextual Information for Multi-hop Question Answering,conclusion and future work,"in this paper, we apply explicit graph reasoning to extracted knowledge and contextual information for multi-hop reasoning.",ReSolved,https://www.aclanthology.org/2022.dlg4nlp-1.8.pdf
1619,250390947,Explicit Graph Reasoning Fusing Knowledge and Contextual Information for Multi-hop Question Answering,conclusion and future work,"we extract clues at multiple levels of granularity relating entity nodes, and construct a semantic graph from these clues.",Neutral,https://www.aclanthology.org/2022.dlg4nlp-1.8.pdf
1620,250390947,Explicit Graph Reasoning Fusing Knowledge and Contextual Information for Multi-hop Question Answering,conclusion and future work,we then combine a masked attention mechanism and two-stage graph reasoning to perform interpretable inference over the semantic graph.,Neutral,https://www.aclanthology.org/2022.dlg4nlp-1.8.pdf
1621,250390947,Explicit Graph Reasoning Fusing Knowledge and Contextual Information for Multi-hop Question Answering,conclusion and future work,experimental results on hotpotqa dataset show the effectiveness of our model.,ReSolved,https://www.aclanthology.org/2022.dlg4nlp-1.8.pdf
1622,250390947,Explicit Graph Reasoning Fusing Knowledge and Contextual Information for Multi-hop Question Answering,conclusion and future work,"in future work, we hope to extend the range and precision of the entity relations used, and we hope to extend our model to accommodate more complex multi-hop questions with unknown number of hops and non-linear reasoning.",Finding,https://www.aclanthology.org/2022.dlg4nlp-1.8.pdf
1623,248827723,A STEP towards Interpretable Multi-Hop Reasoning: Bridge Phrase Identification and Query Expansion,conclusion,we proposed an unsupervised approach for the identification of bridge phrases in multi-hop question answering.,ReSolved,
1624,248827723,A STEP towards Interpretable Multi-Hop Reasoning: Bridge Phrase Identification and Query Expansion,conclusion,"our method constructs a graph of noun phrases from the question and the available context, and applies the steiner tree algorithm to identify the minimal subgraph that connects all question phrases.",Neutral,
1625,248827723,A STEP towards Interpretable Multi-Hop Reasoning: Bridge Phrase Identification and Query Expansion,conclusion,we extract as bridge phrases nodes in this graph that are not any of the question phrases.,Neutral,
1626,248827723,A STEP towards Interpretable Multi-Hop Reasoning: Bridge Phrase Identification and Query Expansion,conclusion,"our method can be coupled with any downstream qa component, i.e., it can be used as query expansion for evidence retrieval; it can be used to generate enhanced context for answer prediction; and it can be used to generate post-hoc explanations for given answers.",ReSolved,
1627,248827723,A STEP towards Interpretable Multi-Hop Reasoning: Bridge Phrase Identification and Query Expansion,conclusion,"using the hotpotqa dataset, we demonstrate that our method yields improved results in all these scenarios, for multiple types of downstream components.",ReSolved,
1628,248827723,A STEP towards Interpretable Multi-Hop Reasoning: Bridge Phrase Identification and Query Expansion,conclusion,"5. ravi sethi: he is best known as one of three authors of the classic computer science textbook """", also known as the ""dragon book"".",Neutral,
1629,220045477,Benefits of Intermediate Annotations in Reading Comprehension,conclusion,we show that intermediate annotations are a costeffective way to not only boost model performance but also alleviate certain unanticipated biases introduced during the dataset collection.,ReSolved,https://www.aclweb.org/anthology/2020.acl-main.497.pdf
1630,220045477,Benefits of Intermediate Annotations in Reading Comprehension,conclusion,"however, it may be unnecessary to collect these for entire dataset and there is a sweet-spot that works best depending on the task.",Finding,https://www.aclweb.org/anthology/2020.acl-main.497.pdf
1631,220045477,Benefits of Intermediate Annotations in Reading Comprehension,conclusion,we proposed a simple semi-supervision technique to expose the model to these annotations.,ReSolved,https://www.aclweb.org/anthology/2020.acl-main.497.pdf
1632,220045477,Benefits of Intermediate Annotations in Reading Comprehension,conclusion,we believe that in future they can be used more directly to yield better performance gains.,Finding,https://www.aclweb.org/anthology/2020.acl-main.497.pdf
1633,220045477,Benefits of Intermediate Annotations in Reading Comprehension,conclusion,we have also released these annotations for the research community at https: //github.com/ddua/intermediate_annotations.,ReSolved,https://www.aclweb.org/anthology/2020.acl-main.497.pdf
1634,220045477,Benefits of Intermediate Annotations in Reading Comprehension,conclusion,"motteux was also without heirs and bequeathed sandringham, together with another norfolk estate and a property in surrey, to the third son of his close friend, emily lamb, the wife of lord palmerston.",Neutral,https://www.aclweb.org/anthology/2020.acl-main.497.pdf
1635,220045477,Benefits of Intermediate Annotations in Reading Comprehension,conclusion,"at the time of his inheritance in 1843, charles spencer cowper was a bachelor diplomat, resident in paris.",Neutral,https://www.aclweb.org/anthology/2020.acl-main.497.pdf
1636,220045477,Benefits of Intermediate Annotations in Reading Comprehension,conclusion,"on succeeding to motteux's estates, he sold the other properties and based himself at sandringham.",Neutral,https://www.aclweb.org/anthology/2020.acl-main.497.pdf
1637,220045477,Benefits of Intermediate Annotations in Reading Comprehension,conclusion,"he undertook extensions to the hall, employing samuel sanders teulon to add an elaborate porch and conservatory.",Neutral,https://www.aclweb.org/anthology/2020.acl-main.497.pdf
1638,220045477,Benefits of Intermediate Annotations in Reading Comprehension,conclusion,"cowper's style of living was extravagant he and his wife spent much of their time on the continent and within 10 years the estate was mortgaged for £89,000.",Neutral,https://www.aclweb.org/anthology/2020.acl-main.497.pdf
1639,220045477,Benefits of Intermediate Annotations in Reading Comprehension,conclusion,"the death of their only child, mary harriette, from cholera in 1854 led the couple to spend even more time abroad, mainly in paris, and by the early 1860s cowper was keen to sell the estate.",Neutral,https://www.aclweb.org/anthology/2020.acl-main.497.pdf
1640,220045477,Benefits of Intermediate Annotations in Reading Comprehension,conclusion,"figure 9: predicted relevant spans for question answered correctly with annotation (prediction:""charles spencer cowper"") and incorrectly without annotations (prediction:""lord palmerston"") by xlnet on quoref",Neutral,https://www.aclweb.org/anthology/2020.acl-main.497.pdf
1641,248780551,CQG: A Simple and Effective Controlled Generation Framework for Multi-hop Question Generation,conclusion,the mqg task is more challenging and worthy of exploration compared with conventional shallow qg.,Finding,https://www.aclanthology.org/2022.acl-long.475.pdf
1642,248780551,CQG: A Simple and Effective Controlled Generation Framework for Multi-hop Question Generation,conclusion,"to address the complexity control problem of mqg, we propose a simple control framework cqg, which consists of a gat-based key entity extractor and a controlled generated.",ReSolved,https://www.aclanthology.org/2022.acl-long.475.pdf
1643,248780551,CQG: A Simple and Effective Controlled Generation Framework for Multi-hop Question Generation,conclusion,cqg greatly improves the performance and we hope our model will help researchers to study the mqg task.,ReSolved,https://www.aclanthology.org/2022.acl-long.475.pdf
1644,202583433,Multi-step Entity-centric Information Retrieval for Multi-Hop Question Answering,conclusion,we introduce an entity-centric approach to ir that finds relevant evidence required to answer multihop questions from a corpus containing millions of paragraphs leading to significant improvement to an existing qa system.,ReSolved,https://www.aclweb.org/anthology/D19-5816.pdf
1645,207852944,Knowledge Guided Text Retrieval and Reading for Open Domain Question Answering,conclusion,we proposed a general approach for open-domain question answering (qa) that models interactions between paragraphs using structural information from a knowledge base.,ReSolved,https://arxiv.org/pdf/1911.03868v2.pdf
1646,207852944,Knowledge Guided Text Retrieval and Reading for Open Domain Question Answering,conclusion,"unlike standard approaches where a model retrieves and reads a set of passages, we integrate graph structure at every stage to construct, retrieve and read a graph of passages.",ReSolved,https://arxiv.org/pdf/1911.03868v2.pdf
1647,207852944,Knowledge Guided Text Retrieval and Reading for Open Domain Question Answering,conclusion,"our approach consistently outperforms competitive baselines in three open-domain qa datasets, webquestions, natural ques-tions and triviaqa, and we also include a detailed qualitative analysis to illustrate where the cross paragraph reading contributes the most to the overall system performance.",ReSolved,https://arxiv.org/pdf/1911.03868v2.pdf
1648,248405719,A Thorough Examination on Zero-shot Dense Retrieval,conclusion and future work,"in this paper, we thoroughly examine the zeroshot capability of dr models.",ReSolved,https://export.arxiv.org/pdf/2204.12755v2.pdf
1649,248405719,A Thorough Examination on Zero-shot Dense Retrieval,conclusion and future work,we conduct empirical analysis by extensively studying the effect of various factors on the retrieval performance.,ReSolved,https://export.arxiv.org/pdf/2204.12755v2.pdf
1650,248405719,A Thorough Examination on Zero-shot Dense Retrieval,conclusion and future work,"in particular, we find that the factors of vocabulary overlap, query type distribution, and data scale are likely to affect the zero-shot performance of dense retriever.",ReSolved,https://export.arxiv.org/pdf/2204.12755v2.pdf
1651,248405719,A Thorough Examination on Zero-shot Dense Retrieval,conclusion and future work,"besides, the performance between bm25 and dr models varies significantly on different target datasets, where the dataset bias (e.g., a dataset is created based on exact match) is likely to make such comparison unfair.",Neutral,https://export.arxiv.org/pdf/2204.12755v2.pdf
1652,248405719,A Thorough Examination on Zero-shot Dense Retrieval,conclusion and future work,"overall, we find that the zero-shot performance of dense retrieval models still has room to improve and deserves further study.",ReSolved,https://export.arxiv.org/pdf/2204.12755v2.pdf
1653,226262208,IIRC: A Dataset of Incomplete Information Reading Comprehension Questions,conclusion,"we introduced iirc, a new dataset of incompleteinformation reading comprehension questions.",ReSolved,https://arxiv.org/pdf/2011.07127v1.pdf
1654,226262208,IIRC: A Dataset of Incomplete Information Reading Comprehension Questions,conclusion,"these questions require identifying what information is missing from a paragraph in order to answer a question, predicting where to find it, then synthesizing the retrieved information in complex ways.",Neutral,https://arxiv.org/pdf/2011.07127v1.pdf
1655,226262208,IIRC: A Dataset of Incomplete Information Reading Comprehension Questions,conclusion,"our baseline model, built on top of state-ofthe-art models for the most closely related existing datasets, performs quite poorly in this setting, even when given oracle retrieval results, and especially when combined with other reading comprehension datasets.",Finding,https://arxiv.org/pdf/2011.07127v1.pdf
1656,226262208,IIRC: A Dataset of Incomplete Information Reading Comprehension Questions,conclusion,iirc both provides a promising new avenue for studying complex reading and retrieval problems and demonstrates that much more research is needed in this area.,Finding,https://arxiv.org/pdf/2011.07127v1.pdf
1657,219687051,Self-supervised Learning: Generative or Contrastive,conclusion,"this survey comprehensively reviews the existing selfsupervised representation learning approaches in natural language processing (nlp), computer vision (cv), graph learning, and beyond.",ReSolved,https://arxiv.org/pdf/2006.08218v5.pdf
1658,219687051,Self-supervised Learning: Generative or Contrastive,conclusion,self-supervised learning is the present and future of deep learning due to its supreme ability to utilize web-scale unlabeled data to train feature extractors and context generators efficiently.,Neutral,https://arxiv.org/pdf/2006.08218v5.pdf
1659,219687051,Self-supervised Learning: Generative or Contrastive,conclusion,"despite the diversity of algorithms, we categorize all self-supervised methods into three classes: generative, contrastive, and generative contrastive according to their essential training objectives.",ReSolved,https://arxiv.org/pdf/2006.08218v5.pdf
1660,219687051,Self-supervised Learning: Generative or Contrastive,conclusion,we introduce typical and representative methods in each category and sub-categories.,ReSolved,https://arxiv.org/pdf/2006.08218v5.pdf
1661,219687051,Self-supervised Learning: Generative or Contrastive,conclusion,"moreover, we discuss the pros and cons of each category and their unique application scenarios.",ReSolved,https://arxiv.org/pdf/2006.08218v5.pdf
1662,219687051,Self-supervised Learning: Generative or Contrastive,conclusion,"finally, fundamental problems and future directions of self-supervised learning are listed.",Neutral,https://arxiv.org/pdf/2006.08218v5.pdf
1663,226262229,Coarse-to-Fine Query Focused Multi-Document Summarization,conclusions,"in this work, we proposed a coarse-to-fine estimation framework for query focused multi-document summarization.",ReSolved,https://www.aclweb.org/anthology/2020.emnlp-main.296.pdf
1664,226262229,Coarse-to-Fine Query Focused Multi-Document Summarization,conclusions,we explored the potential of leveraging distant supervision signals from question answering to better capture the semantic relations between queries and document segments.,ReSolved,https://www.aclweb.org/anthology/2020.emnlp-main.296.pdf
1665,226262229,Coarse-to-Fine Query Focused Multi-Document Summarization,conclusions,experimental results across datasets show that the proposed model yields results superior to competitive baselines contributing to summaries which are more  gpus with 11gb memory.,ReSolved,https://www.aclweb.org/anthology/2020.emnlp-main.296.pdf
1666,226262229,Coarse-to-Fine Query Focused Multi-Document Summarization,conclusions,"for the answer sentence selection model, bert was fine-tuned with a learning rate of 3 × 10 −6 and a batch size of 16 for 3 epochs .",Neutral,https://www.aclweb.org/anthology/2020.emnlp-main.296.pdf
1667,226262229,Coarse-to-Fine Query Focused Multi-Document Summarization,conclusions,"for span selection, we adopted a learning rate of 3 × 10 −5 and a batch size of 64 for 5 epochs.",Neutral,https://www.aclweb.org/anthology/2020.emnlp-main.296.pdf
1668,226262229,Coarse-to-Fine Query Focused Multi-Document Summarization,conclusions,"during inference, the confidence threshold for the relevance estimator was set to θ = 0.75 (kratzwald and feuerriegel, 2018) for both sentence and passage retrieval.",Neutral,https://www.aclweb.org/anthology/2020.emnlp-main.296.pdf
1669,226262229,Coarse-to-Fine Query Focused Multi-Document Summarization,conclusions,"for the evidence estimator, k qa was tuned on the development set.",Neutral,https://www.aclweb.org/anthology/2020.emnlp-main.296.pdf
1670,226262229,Coarse-to-Fine Query Focused Multi-Document Summarization,conclusions,"we obtained 90 and 110 evidence sentences from the sentence selection and span selection models, respectively.",ReSolved,https://www.aclweb.org/anthology/2020.emnlp-main.296.pdf
1671,226262229,Coarse-to-Fine Query Focused Multi-Document Summarization,conclusions,"for the centrality estimator, the influence of the query was set to φ = 0.15 (wan, 2008;wan and zhang, 2014",Neutral,https://www.aclweb.org/anthology/2020.emnlp-main.296.pdf
1672,235294052,On the Efficacy of Adversarial Data Collection for Question Answering: Results from a Large-Scale Randomized Study,conclusion,"in this paper, we demonstrated that across a variety of models and datasets, training on adversarial data leads to better performance on evaluation sets created in a similar fashion, but tends to yield worse performance on out-of-domain evaluation sets not created adversarially.",ReSolved,https://www.aclanthology.org/2021.acl-long.517.pdf
1673,235294052,On the Efficacy of Adversarial Data Collection for Question Answering: Results from a Large-Scale Randomized Study,conclusion,"additionally, our results suggest that the adc process (regardless of the outcome) might matter more than successfully fooling a model.",ReSolved,https://www.aclanthology.org/2021.acl-long.517.pdf
1674,235294052,On the Efficacy of Adversarial Data Collection for Question Answering: Results from a Large-Scale Randomized Study,conclusion,"we also identify key qualitative differences between data generated via adc and sdc, particularly the kinds of questions created.",ReSolved,https://www.aclanthology.org/2021.acl-long.517.pdf
1675,248572452,ProQA: Structural Prompt-based Pre-training for Unified Question Answering,conclusion,"we introduce proqa, a unified qa paradigm that adopts a single model for solving various qa tasks with the bridge of a structural prompt.",ReSolved,https://www.aclanthology.org/2022.naacl-main.313.pdf
1676,248572452,ProQA: Structural Prompt-based Pre-training for Unified Question Answering,conclusion,"structural prompt simultaneously models the common ability required for various tasks and keeps the speciality of each task, through a structurally designed learnable input schema.",Neutral,https://www.aclanthology.org/2022.naacl-main.313.pdf
1677,248572452,ProQA: Structural Prompt-based Pre-training for Unified Question Answering,conclusion,"we further conduct structural prompt-based pre-training, seeking to empower the model with general qa-centric ability and injects the semantic knowledge of the structural prompt into the pre-training model.",ReSolved,https://www.aclanthology.org/2022.naacl-main.313.pdf
1678,248572452,ProQA: Structural Prompt-based Pre-training for Unified Question Answering,conclusion,experimental results on 11 qa benchmarks demonstrate that proqa can significantly boost performance on all settings.,ReSolved,https://www.aclanthology.org/2022.naacl-main.313.pdf
1679,248572452,ProQA: Structural Prompt-based Pre-training for Unified Question Answering,conclusion,"further analyses show that our method can better mitigate the catastrophic forgetting issue during continual learning, and our method can be adapted to a newly involved task more quickly, by taking the advantages of the structural prompt.",ReSolved,https://www.aclanthology.org/2022.naacl-main.313.pdf
1680,248572452,ProQA: Structural Prompt-based Pre-training for Unified Question Answering,conclusion,"in the future, we hope our analysis could inspire more explorations on the unified qa methods, or the unification of distinct tasks with complex inputs modeling by the structural prompt.",Finding,https://www.aclanthology.org/2022.naacl-main.313.pdf
1681,248572452,ProQA: Structural Prompt-based Pre-training for Unified Question Answering,conclusion,we also hope structural prompt can be further utilized into the unification of more tasks with complex inputs.,Finding,https://www.aclanthology.org/2022.naacl-main.313.pdf
1682,239998631,How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI,limitations of realfp.,"our realfp dataset includes only one explanation program to a given fp whereas in practice, there can be multiple creative decompositions that lead to the correct answer.",Finding,https://www.aclanthology.org/2021.emnlp-main.582.pdf
1683,239998631,How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI,limitations of realfp.,"to encourage models that are capable of capturing this diversity in the output space, it would be interesting to (a) collect alternative solutions similar to say, image captioning datasets where it is the norm to train and evaluate against multiple ground truth candidates and (b) increasing the number of templates in the synthfp dataset, thereby biasing the model towards exploring multiple solutions by pre-training on a richer synthetic dataset.",Finding,https://www.aclanthology.org/2021.emnlp-main.582.pdf
1684,239998631,How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI,limitations of realfp.,"further, the work doesn't include other variants of fps -e.g. binary yes/no questions, comparisons, or fps involving probability and risk quantification.",Finding,https://www.aclanthology.org/2021.emnlp-main.582.pdf
1685,239998631,How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI,limitations of realfp.,"finally, note that our real-world dataset, by virtue of how it is collected, has a high us-centric bias, both in terms of cultural context and vocabulary.",Finding,https://www.aclanthology.org/2021.emnlp-main.582.pdf
1686,239998631,How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI,conclusion,"in this work, we propose fermi problems (fps) as a reasoning challenge for ai systems.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.582.pdf
1687,239998631,How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI,conclusion,"apart from introducing abstraction as a crucial reasoning skill, our work requires the combined application of various reasoning skills including creative decomposition of problems, commonsense reasoning, mathematical reasoning, etc.",Neutral,https://www.aclanthology.org/2021.emnlp-main.582.pdf
1688,239998631,How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI,conclusion,we collect two datasets -realfp with ∼1k real-world questions and syn-thfp with 10k templated questions.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.582.pdf
1689,239998631,How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI,conclusion,"based on these datasets, we propose three concrete tasks of increasing difficulty that encompass the fp challenge.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.582.pdf
1690,239998631,How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI,conclusion,"the baseline models we provide, despite being based on state-of-the-art language models and even with substantial fine-tuning, struggle on our challenge tasks.",Finding,https://www.aclanthology.org/2021.emnlp-main.582.pdf
1691,239998631,How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI,conclusion,"they are, on average, off by two orders of magnitude from the correct estimate and perform only slightly better than predicting a constant number.",Finding,https://www.aclanthology.org/2021.emnlp-main.582.pdf
1692,239998631,How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI,conclusion,we thus hope to establish fermi problems as a hard reasoning challenge that motivates further advances in ai reasoning systems.,Finding,https://www.aclanthology.org/2021.emnlp-main.582.pdf
1693,249062555,Teaching Broad Reasoning Skills via Decomposition-Guided Contexts,conclusions,large language models demonstrate impressive reading comprehension abilities and a wide variety of reasoning skills.,ReSolved,https://arxiv.org/pdf/2205.12496v1.pdf
1694,249062555,Teaching Broad Reasoning Skills via Decomposition-Guided Contexts,conclusions,"despite these abilities and the availability of large scale multihop qa datasets, large lm-based qa models do not reliably learn to use such reasoning skills for answering complex questions.",Finding,https://arxiv.org/pdf/2205.12496v1.pdf
1695,249062555,Teaching Broad Reasoning Skills via Decomposition-Guided Contexts,conclusions,"in this work, we show that the greater control that synthetic contexts offer can be leveraged to create a teaching dataset where models can learn a broad range of reasoning skills in a reliable manner, especially for more complex questions.",ReSolved,https://arxiv.org/pdf/2205.12496v1.pdf
1696,249062555,Teaching Broad Reasoning Skills via Decomposition-Guided Contexts,conclusions,our transfer results on actual qa datasets also add to the line of work that shows synthetic datasets can be used to inject useful skills that transfer over to real natural language tasks.,ReSolved,https://arxiv.org/pdf/2205.12496v1.pdf
1697,249062555,Teaching Broad Reasoning Skills via Decomposition-Guided Contexts,conclusions,"given the artifact issues in real datasets (specifically, in their contexts) and the difficulty in controlling for them via perturbations, leveraging existing multihop questions for their broad reasoning patterns but using synthetic contexts appears to be a viable alternative for carefully constructing teaching datasets, where models can learn the right way to reason.",ReSolved,https://arxiv.org/pdf/2205.12496v1.pdf
1698,215768725,A Simple Yet Strong Pipeline for HotpotQA,conclusion,"our work shows that on the hotpotqa tasks, a simple pipeline model can do as well as or better than more complex solutions, such as graph networks, cross-document attention, or ner.",ReSolved,https://www.aclweb.org/anthology/2020.emnlp-main.711.pdf
1699,215768725,A Simple Yet Strong Pipeline for HotpotQA,conclusion,"powerful pre-trained models allow us to score sentences one at a time, without looking at other paragraphs.",ReSolved,https://www.aclweb.org/anthology/2020.emnlp-main.711.pdf
1700,215768725,A Simple Yet Strong Pipeline for HotpotQA,conclusion,"by operating jointly over these sentences chosen from multiple paragraphs, we arrive at answers and supporting sentences on par with state-of-theart approaches.",Neutral,https://www.aclweb.org/anthology/2020.emnlp-main.711.pdf
1701,215768725,A Simple Yet Strong Pipeline for HotpotQA,conclusion,"this result shows that supporting sentence identification in hotpotqa is itself not a multi-hop problem, and suggests focusing on other multi-hop datasets to demonstrate the value of more complex retrieval techniques.",Finding,https://www.aclweb.org/anthology/2020.emnlp-main.711.pdf
1702,253157979,TASA: Deceiving Question Answering Models by Twin Answer Sentences Attack,conclusion,"we present tasa, an automatic adversarial attack method for qa models.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.821.pdf
1703,253157979,TASA: Deceiving Question Answering Models by Twin Answer Sentences Attack,conclusion,"it generates twin answer sentences, perturbed answer sentence (pas), and distracting answer sentence (das), to construct a new adversarial context in a qa sample.",Neutral,https://www.aclanthology.org/2022.emnlp-main.821.pdf
1704,253157979,TASA: Deceiving Question Answering Models by Twin Answer Sentences Attack,conclusion,it can deceive models and misguide them to an incorrect answer based on their pitfalls that overly rely on matching sensitive keywords during predicting answers.,Neutral,https://www.aclanthology.org/2022.emnlp-main.821.pdf
1705,253157979,TASA: Deceiving Question Answering Models by Twin Answer Sentences Attack,conclusion,"in experiments, tasa achieves remarkable attack performance on five datasets and three victim models with satisfactory sample quality.",ReSolved,https://www.aclanthology.org/2022.emnlp-main.821.pdf
1706,253157979,TASA: Deceiving Question Answering Models by Twin Answer Sentences Attack,conclusion,our additional analysis also proves that it is possible to get more robust qa models via tasa in the future.,Finding,https://www.aclanthology.org/2022.emnlp-main.821.pdf
1707,253157979,TASA: Deceiving Question Answering Models by Twin Answer Sentences Attack,conclusion,"during fine-tuning bert on different qa datasets, we set the maximum input sequence length as 384, using an adam optimizer whose initial learning rate is 6.25e−5 with the batch size 32.",Neutral,https://www.aclanthology.org/2022.emnlp-main.821.pdf
1708,253157979,TASA: Deceiving Question Answering Models by Twin Answer Sentences Attack,conclusion,the epoch number is 3 and the final model after all epochs will be saved as the victim model.,Neutral,https://www.aclanthology.org/2022.emnlp-main.821.pdf
1709,253157979,TASA: Deceiving Question Answering Models by Twin Answer Sentences Attack,conclusion,"spanbert we also use the huggingfancetransformers to implement the model, along with spanbert-large-cased version 5 to initialize the weights.",Neutral,https://www.aclanthology.org/2022.emnlp-main.821.pdf
1710,253157979,TASA: Deceiving Question Answering Models by Twin Answer Sentences Attack,conclusion,it contains 24 layers with a hidden size of 1024.,Neutral,https://www.aclanthology.org/2022.emnlp-main.821.pdf
1711,253157979,TASA: Deceiving Question Answering Models by Twin Answer Sentences Attack,conclusion,a linear layer is added to predict the start and end positions of the answer span.,Neutral,https://www.aclanthology.org/2022.emnlp-main.821.pdf
1712,253384010,NAPG: Non-Autoregressive Program Generation for Hybrid Tabular-Textual Question Answering,conclusion,"hybrid tabular-textual question answering (qa) requires reasoning from heterogeneous information, and the types of reasoning can be categorized into numerical reasoning and span extraction.",Neutral,https://export.arxiv.org/pdf/2211.03462v1.pdf
1713,253384010,NAPG: Non-Autoregressive Program Generation for Hybrid Tabular-Textual Question Answering,conclusion,"in this paper, we present a non-autoregressive program generation (napg) framework for numerical reasoning, which facilitates program generation in parallel.",ReSolved,https://export.arxiv.org/pdf/2211.03462v1.pdf
1714,253384010,NAPG: Non-Autoregressive Program Generation for Hybrid Tabular-Textual Question Answering,conclusion,our framework independently generates complete program tuples containing both the operator and its operands.,ReSolved,https://export.arxiv.org/pdf/2211.03462v1.pdf
1715,253384010,NAPG: Non-Autoregressive Program Generation for Hybrid Tabular-Textual Question Answering,conclusion,"compared to previous autoregressive decoding methods, napg does not suffer from exposure bias, and can significantly boost the program generation speed.",ReSolved,https://export.arxiv.org/pdf/2211.03462v1.pdf
1716,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,"in this paper, we present a novel plug-and-play smoe-dropout strategy for training overparameterized transformers in full-capacity settings without collapse.",ReSolved,https://export.arxiv.org/pdf/2303.01610v1.pdf
1717,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,we design a fixed and randomly initialized router to assign experts and gradually increase their number along with the training.,ReSolved,https://export.arxiv.org/pdf/2303.01610v1.pdf
1718,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,"as a result, our proposal provides an appealing ""self-slimmable"" property to large transformers during inference and downstream fine-tuning, depending on available resources.",ReSolved,https://export.arxiv.org/pdf/2303.01610v1.pdf
1719,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,it implies alleviated representation collapse and delivers an in-situ trade-off between efficiency and performance.,ReSolved,https://export.arxiv.org/pdf/2303.01610v1.pdf
1720,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,"extensive experiments across various combinations of network backbone and dataset, consistently demonstrate the significantly improved performance and training time savings from our algorithm.",ReSolved,https://export.arxiv.org/pdf/2303.01610v1.pdf
1721,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,future work includes the extension of other network architectures and tasks like vision recognition.,Finding,https://export.arxiv.org/pdf/2303.01610v1.pdf
1722,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,"smoe-dropout (k = n 2 ) 82.03 ± 0.26 smoe-dropout (k = n) 82.32 ± 0.14 to evaluate the stability of the improvement obtained by our smoe-dropout, we carry out further experiments of transformer-xl on sst-2.",Neutral,https://export.arxiv.org/pdf/2303.01610v1.pdf
1723,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,"the results are reported in table a4, from which we can observe that our smoe-dropout achieves a statistically significant improvement of 0.93% ∼ 1.17% accuracy gains compared with other smoe-variants and the dense network, where there is no overlap between the error bars (one standard deviation).",ReSolved,https://export.arxiv.org/pdf/2303.01610v1.pdf
1724,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,"table a5 demonstrates that both random routing policy and progressively increasing the number of activated experts are beneficial for alleviating representation collapse and providing ""selfslimmable"" property, yet not as good as combining both.",ReSolved,https://export.arxiv.org/pdf/2303.01610v1.pdf
1725,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,"to be specific, when applying the strategy of progressively enlarging the number of activated experts, the learnable smoes suffer less representation collapse and achieve better performance, i.e., 0.31% higher accuracy.",ReSolved,https://export.arxiv.org/pdf/2303.01610v1.pdf
1726,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,"meanwhile, we find that learnable smoe with curriculum learning has the ""self-slimmable"" property only when activating experts from k = 1 to k",ReSolved,https://export.arxiv.org/pdf/2303.01610v1.pdf
1727,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,"however, the performance starts to degrade if using more experts like k = 16.",Neutral,https://export.arxiv.org/pdf/2303.01610v1.pdf
1728,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,"as for our smoe-dropout with a random routing, it enjoys a better ""self-slimmable"" property from k = 1 to k = 16 (full model capacity), with up to 0.87% higher accuracy on sst-2 across all scenarios, compared to its learnable variants.",Neutral,https://export.arxiv.org/pdf/2303.01610v1.pdf
1729,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,"we conduct a further transfer study of the pre-trained bert networks on a multi-hop questionanswering dataset, hotpotqa yang et al. (2018). and we use exact match (em) accuracy to assess networks' performance.",ReSolved,https://export.arxiv.org/pdf/2303.01610v1.pdf
1730,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,"following the same metric in press et al. (2022), we calculate the compositionality gap, i.e., the gap of em accuracy between multi-hop question answering and its all single-hop sub-questions , of each network.",ReSolved,https://export.arxiv.org/pdf/2303.01610v1.pdf
1731,257353502,SPARSE MOE AS THE NEW DROPOUT: SCALING DENSE AND SELF-SLIMMABLE TRANSFORMERS,conclusion,"as shown in table a6, our smoe-dropout is beneficial for reducing the compositionality gap, which achieves the best performance with up to 0.30% higher em score and 0.30% narrower compositionality gap, compared with the learnable smoe and its dense counterpart.",ReSolved,https://export.arxiv.org/pdf/2303.01610v1.pdf
1732,256105660,Unifying Structure Reasoning and Language Model Pre-training for Complex Reasoning,conclusion,"in this paper, we propose to model the structured knowledge in contexts and perform structure reasoning over them for complex reasoning.",ReSolved,https://export.arxiv.org/pdf/2301.08913v1.pdf
1733,256105660,Unifying Structure Reasoning and Language Model Pre-training for Complex Reasoning,conclusion,"to accomplish this objective, we present a unified framework combining structure reasoning and language modeling.",ReSolved,https://export.arxiv.org/pdf/2301.08913v1.pdf
1734,256105660,Unifying Structure Reasoning and Language Model Pre-training for Complex Reasoning,conclusion,it extracts four types of elementary knowledge structures from contexts to construct structured queries and adopts the box embedding method for explicit structure reasoning along the constructed queries.,ReSolved,https://export.arxiv.org/pdf/2301.08913v1.pdf
1735,256105660,Unifying Structure Reasoning and Language Model Pre-training for Complex Reasoning,conclusion,we utilize the contextual language representations of knowledge for structure reasoning and obtain a structure-embedded language representation.,ReSolved,https://export.arxiv.org/pdf/2301.08913v1.pdf
1736,256105660,Unifying Structure Reasoning and Language Model Pre-training for Complex Reasoning,conclusion,experimental results show the effectiveness of our model on complex reasoning tasks over both language and kgs.,ReSolved,https://export.arxiv.org/pdf/2301.08913v1.pdf
1737,257405222,AugTriever: Unsupervised Dense Retrieval by Scalable Data Augmentation,discussion and conclusion,"in this study, a series of scalable augmentation methods are proposed to produce surrogate queries for training dense retrievers without using any annotated query-document pairs.",ReSolved,https://export.arxiv.org/pdf/2212.08841v2.pdf
1738,257405222,AugTriever: Unsupervised Dense Retrieval by Scalable Data Augmentation,discussion and conclusion,"we achieve state-of-the-art performance on two collections of widely used benchmarks (beir and six odqa datasets), demonstrating that the efficacy of synthetic querydocument pairs for training dense retrievers, greatly bridging the gap between unsupervised dense models and bm25 and inspiring us to rethink the necessity of using real queries.",ReSolved,https://export.arxiv.org/pdf/2212.08841v2.pdf
1739,252367252,ScreenQA: Large-Scale Question-Answer Pairs Over Mobile App Screenshots,conclusion,"in this work, we proposed the screenqa task.",ReSolved,https://export.arxiv.org/pdf/2209.08199v1.pdf
1740,252367252,ScreenQA: Large-Scale Question-Answer Pairs Over Mobile App Screenshots,conclusion,"we annotated a large-scale screenqa dataset, which contains more than 80,000 question-answer pairs.",ReSolved,https://export.arxiv.org/pdf/2209.08199v1.pdf
1741,252367252,ScreenQA: Large-Scale Question-Answer Pairs Over Mobile App Screenshots,conclusion,"compared to other vision-language multimodal problems, such as document image understanding and visual question answering, screenqa poses its unique challenges: rich in text, diverse in apps, and blended with icons and symbols.",ReSolved,https://export.arxiv.org/pdf/2209.08199v1.pdf
1742,252367252,ScreenQA: Large-Scale Question-Answer Pairs Over Mobile App Screenshots,conclusion,"we hope to use the screenqa task and the dataset to encourage the community to look into this screen content understanding problem, as it enables new technologies and new user experiences.",Finding,https://export.arxiv.org/pdf/2209.08199v1.pdf
1743,252367252,ScreenQA: Large-Scale Question-Answer Pairs Over Mobile App Screenshots,conclusion,figure 4: data annotation interfaces for question and answer collection.,Neutral,https://export.arxiv.org/pdf/2209.08199v1.pdf
1744,252367252,ScreenQA: Large-Scale Question-Answer Pairs Over Mobile App Screenshots,conclusion,"a) question annotation was performed in a sequential manner, the later and non-overlapping annotators can see all previous questions to diversify question framing and avoid duplication.",ReSolved,https://export.arxiv.org/pdf/2209.08199v1.pdf
1745,252367252,ScreenQA: Large-Scale Question-Answer Pairs Over Mobile App Screenshots,conclusion,we also used the sequential process to provide more feedback and training to the annotators for quality improvement.,ReSolved,https://export.arxiv.org/pdf/2209.08199v1.pdf
1746,252367252,ScreenQA: Large-Scale Question-Answer Pairs Over Mobile App Screenshots,conclusion,b) the answer annotators were tasked to determine if the question is valid and if the question is answerable from the screen context.,Neutral,https://export.arxiv.org/pdf/2209.08199v1.pdf
1747,252367252,ScreenQA: Large-Scale Question-Answer Pairs Over Mobile App Screenshots,conclusion,"if both are positive, the annotators need to answer the questions by 1) selecting or drawing the bounding boxes of ui elements, 2) fill the text for each selected/drawn bounding box on right right, and 3) ranking them appropriately.",Neutral,https://export.arxiv.org/pdf/2209.08199v1.pdf
1748,252367252,ScreenQA: Large-Scale Question-Answer Pairs Over Mobile App Screenshots,conclusion,the annotators were also tasked to review and make necessary corrections if the question has grammatical errors or typos.,Neutral,https://export.arxiv.org/pdf/2209.08199v1.pdf
1749,252367252,ScreenQA: Large-Scale Question-Answer Pairs Over Mobile App Screenshots,conclusion,"a) the two question annotation passes were capped at five and three questions, respectively, resulting in the maximum eight questions in total.",Neutral,https://export.arxiv.org/pdf/2209.08199v1.pdf
1750,252367252,ScreenQA: Large-Scale Question-Answer Pairs Over Mobile App Screenshots,conclusion,"b) the cases when a single bounding box forms a sufficient answer amount to 92% of the questions, hence removed from the chart for the clarity of the long tail.",Neutral,https://export.arxiv.org/pdf/2209.08199v1.pdf
1751,252367252,ScreenQA: Large-Scale Question-Answer Pairs Over Mobile App Screenshots,conclusion,"anything beyond 11 bounding boxes is less than 0.05%, accumulatively less than 0.1%.",Neutral,https://export.arxiv.org/pdf/2209.08199v1.pdf
1752,233297028,Question Decomposition with Dependency Graphs,conclusion,"in this work, we propose to represent qdmr structures with a dependency graph over the input tokens, and propose a graph parser and a seq2seq model that uses graph supervision as an auxiliary loss.",ReSolved,https://arxiv.org/pdf/2104.08647v1.pdf
1753,233297028,Question Decomposition with Dependency Graphs,conclusion,"we show that a graph parser is 16x faster than a seq2seq model, and that it exhibits better sample coplexity.",ReSolved,https://arxiv.org/pdf/2104.08647v1.pdf
1754,233297028,Question Decomposition with Dependency Graphs,conclusion,"moreover, using graphs as auxiliary supervision improves out-of-domain generalization and leads to better performance on questions that represent a long sequence of computational steps.",ReSolved,https://arxiv.org/pdf/2104.08647v1.pdf
1755,233297028,Question Decomposition with Dependency Graphs,conclusion,"last, we propose a new evaluation metric for qdmr parsing and show it better corresponds to human intuitions.",ReSolved,https://arxiv.org/pdf/2104.08647v1.pdf
1756,212657414,TYDI QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages,conclusion,"confidently making progress on multilingual models requires challenging, trustworthy evaluations.",Neutral,https://arxiv.org/pdf/2003.05002v1.pdf
1757,212657414,TYDI QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages,conclusion,"we have argued that question answering is well-suited for this purpose and that by targeting a typologically diverse set of languages, progress on the tydi qa dataset is more likely to generalize on the breadth of linguistic phenomena found throughout the world's languages.",Finding,https://arxiv.org/pdf/2003.05002v1.pdf
1758,212657414,TYDI QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages,conclusion,"by avoiding data collection procedures reliant on translation and multilingual modeling, we greatly mitigate the risk of sampling bias.",ReSolved,https://arxiv.org/pdf/2003.05002v1.pdf
1759,212657414,TYDI QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages,conclusion,we look forward to the many ways the research community finds to improve the quality of multilingual models.,Neutral,https://arxiv.org/pdf/2003.05002v1.pdf
1760,212657414,TYDI QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages,conclusion,"because we believe mt may be a fruitful research direction for tydi qa, we do not release any automatic translations.",ReSolved,https://arxiv.org/pdf/2003.05002v1.pdf
1761,212657414,TYDI QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages,conclusion,"in the past, this seems to have stymied innovation around translation as applied to multilingual datasets.",Neutral,https://arxiv.org/pdf/2003.05002v1.pdf
1762,212657414,TYDI QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages,conclusion,we will happily share our annotation protocol on request.,Neutral,https://arxiv.org/pdf/2003.05002v1.pdf
1763,222125277,Under review AUTOREGRESSIVE ENTITY RETRIEVAL,conclusions,"in this work, we propose genre, a novel paradigm to addresses entity retrieval: generate entity names autoregressively.",ReSolved,https://arxiv.org/pdf/2010.00904v1.pdf
1764,222125277,Under review AUTOREGRESSIVE ENTITY RETRIEVAL,conclusions,"entity names have several properties that might help (even humans) retrieving them, including a compositional structure and a predictable interaction with the context.",Neutral,https://arxiv.org/pdf/2010.00904v1.pdf
1765,222125277,Under review AUTOREGRESSIVE ENTITY RETRIEVAL,conclusions,"the autoregressive formulation allows us to directly capture some of these properties, leading to several advantages with respect to current solutions, including an efficient way to cross encode men-tion context and entity candidates, a much smaller memory footprint, and the ability to compute an exact softmax without the need to subsample negative data.",ReSolved,https://arxiv.org/pdf/2010.00904v1.pdf
1766,222125277,Under review AUTOREGRESSIVE ENTITY RETRIEVAL,conclusions,"we empirically show that these characteristics, combined with constrained decoding strategies, led to state-of-the-art performance on a plethora of entity retrieval datasets, spanning entity disambiguation, end-to-end entity linking, and page-level document retrieval, while resulting in systems with a remarkably contained memory footprint, a space reduction by a factor of twenty on average.",ReSolved,https://arxiv.org/pdf/2010.00904v1.pdf
1767,222125277,Under review AUTOREGRESSIVE ENTITY RETRIEVAL,conclusions,we additionally demonstrate that new entities can be effectively considered in our system by simply appending their unambiguous name to the candidate set.,ReSolved,https://arxiv.org/pdf/2010.00904v1.pdf
1768,237498988,Connecting Attributions and QA Model Behavior on Realistic Counterfactuals,discussion and limitations,we show that feature attributions can reveal known dataset biases and reasoning shortcuts in hotpotqa without having to perform a detailed manual analysis.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.447.pdf
1769,237498988,Connecting Attributions and QA Model Behavior on Realistic Counterfactuals,discussion and limitations,this confirms the suitability of our attribution methods for at least this use case: model designers can look at them in a semi-automated way and determine how robust the model is going to be when faced with counterfactuals.our analysis also highlights the limitations of current explanation techniques.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.447.pdf
1770,237498988,Connecting Attributions and QA Model Behavior on Realistic Counterfactuals,discussion and limitations,"we experimented with other counterfactuals by permuting the order of the paragraphs in the context, which often gave rise to different predictions.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.447.pdf
1771,237498988,Connecting Attributions and QA Model Behavior on Realistic Counterfactuals,discussion and limitations,"we believe the model prediction was in these cases impacted by biases in positional embeddings (e.g., the answer tends to occur in the first retrieved paragraph), which cannot be indicated by current attribution methods. we believe this is a useful avenue for future investigation.",Finding,https://www.aclanthology.org/2021.emnlp-main.447.pdf
1772,237498988,Connecting Attributions and QA Model Behavior on Realistic Counterfactuals,discussion and limitations,"by first thinking about what kind of counterfactuals and what kind of behaviours we want to explain, we can motivate the development of new explanation techniques to serve these needs.",Finding,https://www.aclanthology.org/2021.emnlp-main.447.pdf
1773,237498988,Connecting Attributions and QA Model Behavior on Realistic Counterfactuals,conclusion,we have presented a new methodology using explanations to understand model behavior on realistic counterfactuals.,ReSolved,https://www.aclanthology.org/2021.emnlp-main.447.pdf
1774,237498988,Connecting Attributions and QA Model Behavior on Realistic Counterfactuals,conclusion,"we show explanations can indeed be connected to model behavior, and therefore we can compare explanations to understand which ones truly give us actionable insights about what our models are doing.",ReSolved,https://www.aclanthology.org/2021.emnlp-main.447.pdf
1775,237592852,Combining Lexical and Dense Retrieval for Computationally Efficient Multi-hop Question Answering,conclusion,"in this work, we provided insights on the performance of state-of-the-art dense retrieval for multihop questions.",ReSolved,https://www.aclanthology.org/2021.sustainlp-1.7.pdf
1776,237592852,Combining Lexical and Dense Retrieval for Computationally Efficient Multi-hop Question Answering,conclusion,"we showed that rerank+dpr 2 (our hybrid model) outperforms mdr (the state-of-theart multi-hop dense retrieval model) in the low re-source setting, and it is competitive with mdr in the setting where mdr uses considerably more computational resources.",ReSolved,https://www.aclanthology.org/2021.sustainlp-1.7.pdf
1777,237592852,Combining Lexical and Dense Retrieval for Computationally Efficient Multi-hop Question Answering,conclusion,"finally, we highlighted that fully dense retrieval models get harmed when using limited computational resources.",ReSolved,https://www.aclanthology.org/2021.sustainlp-1.7.pdf
1778,237592852,Combining Lexical and Dense Retrieval for Computationally Efficient Multi-hop Question Answering,conclusion,"for future work, we plan to build on our insights to improve the performance of multi-hop models by combining the strengths of lexical and dense retrieval.",Finding,https://www.aclanthology.org/2021.sustainlp-1.7.pdf
1779,237592852,Combining Lexical and Dense Retrieval for Computationally Efficient Multi-hop Question Answering,conclusion,"also, we aim to develop less computationally expensive multi-hop retrieval models.",Finding,https://www.aclanthology.org/2021.sustainlp-1.7.pdf
1780,247447492,What Makes Reading Comprehension Questions Difficult?,conclusion,"to make an nlu benchmark useful, it has to consist of examples that are linguistically diverse and difficult enough to discriminate among state-ofthe-art models.",Neutral,https://www.aclanthology.org/2022.acl-long.479.pdf
1781,247447492,What Makes Reading Comprehension Questions Difficult?,conclusion,we crowdsource multiple-choice reading comprehension questions for passages extracted from seven different sources and analyze the effects of passage source on question difficulty and diversity.,ReSolved,https://www.aclanthology.org/2022.acl-long.479.pdf
1782,247447492,What Makes Reading Comprehension Questions Difficult?,conclusion,"although we expect that the difficulty of a passage affects the difficulty of questions about that passage, the collected questions do not show any strong correlation between the human-machine performance gap and passage source, length, or readability measures.",ReSolved,https://www.aclanthology.org/2022.acl-long.479.pdf
1783,247447492,What Makes Reading Comprehension Questions Difficult?,conclusion,our manual annotation of comprehension types reveals that questions requiring numerical or logical reasoning are relatively difficult.,ReSolved,https://www.aclanthology.org/2022.acl-long.479.pdf
1784,247447492,What Makes Reading Comprehension Questions Difficult?,conclusion,we also find several trends between passage sources and comprehension types.,ReSolved,https://www.aclanthology.org/2022.acl-long.479.pdf
1785,257766470,"Natural Language Reasoning, A Survey",limitations,we introduce both limitations of the current research and intrinsic in plms.,Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1786,257766470,"Natural Language Reasoning, A Survey",limitations,"firstly, there are gaps in defeasible reasoning and reasoning path evaluation. research gap on defeasible reasoning.",Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1787,257766470,"Natural Language Reasoning, A Survey",limitations,"while defeasible reasoning is widely used in our daily life, this topic is still under-explored in nlp.",Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1788,257766470,"Natural Language Reasoning, A Survey",limitations,"[4] found that it is more challenging for chatgpt to perform abductive reasoning and inductive reasoning than deduction, among which induction is the much more difficult one.",Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1789,257766470,"Natural Language Reasoning, A Survey",limitations,lack of effective ways to evaluate reasoning paths.,Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1790,257766470,"Natural Language Reasoning, A Survey",limitations,it is still challenging to automatically evaluate generated reasoning paths without ground truth.,Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1791,257766470,"Natural Language Reasoning, A Survey",limitations,"evaluating reasoning paths might become increasingly important to build explainable and reliable ai systems, especially when more people contact and use chatgpt-like products nowadays.secondly, there are also limitations intrinsic to plms.• soft deduction can produce invalid conclusions.",Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1792,257766470,"Natural Language Reasoning, A Survey",limitations,"transformers can only predict conclusions with probability, irrespective of whether the conclusion of deductive reasoning is necessarily true in nature, which might prevent it from precise reasoning.",Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1793,257766470,"Natural Language Reasoning, A Survey",limitations,this characteristic can result in a sub-optimal solution to deductive problems (including arithmetic reasoning and symbolic reasoning).,Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1794,257766470,"Natural Language Reasoning, A Survey",limitations,"for example, while chatgpt is impressive on reasoning tasks, it still fails to achieve perfect performance on the simplest one-step deductive inference task [4].• biases on content.",Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1795,257766470,"Natural Language Reasoning, A Survey",limitations,plms make their prediction based on context.,Neutral,https://export.arxiv.org/pdf/2303.14725v2.pdf
1796,257766470,"Natural Language Reasoning, A Survey",limitations,"while llms have made huge progress in reasoning, [32] found that llms are biased by content like humans when performing deduction.",Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1797,257766470,"Natural Language Reasoning, A Survey",limitations,"for example, they perform worse in abstract or counterfactual situations than the realistic ones.",Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1798,257766470,"Natural Language Reasoning, A Survey",limitations,"such biases will hinder them from actual reasoning and lead to wrong answers, degrading downstream performance.",Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1799,257766470,"Natural Language Reasoning, A Survey",limitations,"more severely, it might cause harmful societal influences due to some social biases such as gender, which also exist in gpt4",Finding,https://export.arxiv.org/pdf/2303.14725v2.pdf
1800,251594672,CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks,conclusion,"in this paper, we have proposed corpusbrain, a novel pre-trained generative retrieval model to encode all information about the corpus into its parameters.",ReSolved,https://export.arxiv.org/pdf/2208.07652v1.pdf
1801,251594672,CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks,conclusion,"to train such a strong generative model, we delicately devised a set of pre-training tasks to emphasize different aspects of semantics between queries and documents.",ReSolved,https://export.arxiv.org/pdf/2208.07652v1.pdf
1802,251594672,CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks,conclusion,the key idea is to sample a context from one document as a pseudo query and generate the document identifiers of source or destination documents based on hyperlinks.,Neutral,https://export.arxiv.org/pdf/2208.07652v1.pdf
1803,251594672,CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks,conclusion,corpusbrain just needs to pre-train one model and could be then adapted to improve a diversity of downstream kilt tasks without the need of constructing additional index.,ReSolved,https://export.arxiv.org/pdf/2208.07652v1.pdf
1804,251594672,CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks,conclusion,"through experiments on the kilt benchmark in terms of the retrieval task, corpusbrain achieved significant improvements over strong baseline approaches.",ReSolved,https://export.arxiv.org/pdf/2208.07652v1.pdf
1805,251594672,CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks,conclusion,we also showed that corpusbrain can achieve strong performance under both the zero-and low-resource settings.,ReSolved,https://export.arxiv.org/pdf/2208.07652v1.pdf
1806,257038341,Large-scale Multi-Modal Pre-trained Models: A Comprehensive Survey,conclusion,we give a comprehensive review of large-scale multi-modal pre-trained models (mm-ptms) in this paper.,ReSolved,https://export.arxiv.org/pdf/2302.10035v1.pdf
1807,257038341,Large-scale Multi-Modal Pre-trained Models: A Comprehensive Survey,conclusion,"firstly, we introduce the background of mm-ptms, with a focus on conventional deep learning, and pre-training in nlp, cv, and speech.",ReSolved,https://export.arxiv.org/pdf/2302.10035v1.pdf
1808,257038341,Large-scale Multi-Modal Pre-trained Models: A Comprehensive Survey,conclusion,"then, the task definition, key challenges, and benefits of mm-ptms are discussed.",ReSolved,https://export.arxiv.org/pdf/2302.10035v1.pdf
1809,257038341,Large-scale Multi-Modal Pre-trained Models: A Comprehensive Survey,conclusion,"after that, we dive into the reviews of mm-ptms and discuss the pre-training data, objectives, networks, knowledge enhanced pre-training, etc.",ReSolved,https://export.arxiv.org/pdf/2302.10035v1.pdf
1810,257038341,Large-scale Multi-Modal Pre-trained Models: A Comprehensive Survey,conclusion,"we review the downstream tasks including generative, classification, and regression tasks, and also give an overview of model parameters of mm-ptms and hardware for the pre-training.",ReSolved,https://export.arxiv.org/pdf/2302.10035v1.pdf
1811,257038341,Large-scale Multi-Modal Pre-trained Models: A Comprehensive Survey,conclusion,experimental results of several representative tasks are also discussed and visualized.,ReSolved,https://export.arxiv.org/pdf/2302.10035v1.pdf
1812,257038341,Large-scale Multi-Modal Pre-trained Models: A Comprehensive Survey,conclusion,"finally, we point out some research directions that are worth to be focused on.",ReSolved,https://export.arxiv.org/pdf/2302.10035v1.pdf
1813,257038341,Large-scale Multi-Modal Pre-trained Models: A Comprehensive Survey,conclusion,we summarize this paper and hope our survey can provide some useful insights for the mm-ptms.,ReSolved,https://export.arxiv.org/pdf/2302.10035v1.pdf
1814,226955938,Unsupervised Explanation Generation for Machine Reading Comprehension,conclusion,"in this paper, we aim to improve the explainability for the machine reading comprehension task, which is different from most of the previous works that were only striving for better objective evaluation scores.",ReSolved,https://arxiv.org/pdf/2011.06737v1.pdf
1815,226955938,Unsupervised Explanation Generation for Machine Reading Comprehension,conclusion,"to achieve this goal, we propose a novel mechanism called recursive dynamic gating (rdg) to gradually refine the amount of the input information in each layer of the pre-trained language model.",ReSolved,https://arxiv.org/pdf/2011.06737v1.pdf
1816,226955938,Unsupervised Explanation Generation for Machine Reading Comprehension,conclusion,"also, we propose an attention smoothing technique that will increase the accuracy of the rdg mechanism.",ReSolved,https://arxiv.org/pdf/2011.06737v1.pdf
1817,226955938,Unsupervised Explanation Generation for Machine Reading Comprehension,conclusion,"experimental results on three multiple-choice machine reading comprehension datasets show that the proposed rdg mechanism could not only improve the objective evaluation scores, but also show an advantage over the traditional attention mechanism in explainability.",ReSolved,https://arxiv.org/pdf/2011.06737v1.pdf
1818,224803601,OPEN QUESTION ANSWERING OVER TABLES AND TEXT,conclusion,we focus on the problem of performing open question answering over tables and text in this paper.,ReSolved,https://arxiv.org/pdf/2010.10439v1.pdf
1819,224803601,OPEN QUESTION ANSWERING OVER TABLES AND TEXT,conclusion,one interesting question we would like to ask in the future is: can we extend open question answering system to more modalities?,Finding,https://arxiv.org/pdf/2010.10439v1.pdf
1820,224803601,OPEN QUESTION ANSWERING OVER TABLES AND TEXT,conclusion,"some questions can be better answered by images and other resources, but the task can be drastically more challenging by including more modalities, as we have learned from this paper.",Finding,https://arxiv.org/pdf/2010.10439v1.pdf
1821,224803601,OPEN QUESTION ANSWERING OVER TABLES AND TEXT,conclusion,"finally, we believe the techniques we proposed might be useful for other open-qa setting, especially the comparisons between iterative retriever and fusion retriever.",Finding,https://arxiv.org/pdf/2010.10439v1.pdf
1822,253708231,CITADEL: Conditional Token Interaction via Dynamic Lexical Routing for Efficient and Effective Multi-Vector Retrieval,conclusion,"this paper proposes a novel multi-vector retrieval method that achieves state-of-the-art performance on several benchmark datasets while being 40× faster than colbert-v2 and 17× faster than the most efficient multi-vector retrieval library to date, plaid.",ReSolved,https://export.arxiv.org/pdf/2211.10411v1.pdf
1823,253708231,CITADEL: Conditional Token Interaction via Dynamic Lexical Routing for Efficient and Effective Multi-Vector Retrieval,conclusion,"by jointly optimizing for the token index size and load balancing, our new dynamic lexical routing scheme greatly reduces the redundancy in all-to-all token interaction of colbert while bridging the word-mismatch problem in coil.",ReSolved,https://export.arxiv.org/pdf/2211.10411v1.pdf
1824,253708231,CITADEL: Conditional Token Interaction via Dynamic Lexical Routing for Efficient and Effective Multi-Vector Retrieval,conclusion,experiments on both in-domain and out-of-domain datasets demonstrate the effectiveness and efficiency of our model.,ReSolved,https://export.arxiv.org/pdf/2211.10411v1.pdf
1825,258823156,Inference-time Re-ranker Relevance Feedback for Neural Information Retrieval,conclusion and future work,we demonstrate that query representations can be improved using feedback from a cross-encoder reranker at inference time for better performance of dual-encoder retrieval.,ReSolved,https://export.arxiv.org/pdf/2305.11744v1.pdf
1826,258823156,Inference-time Re-ranker Relevance Feedback for Neural Information Retrieval,conclusion and future work,this work proposes for distillation using relevance feedback from the re-ranker as a better and faster alternative to the traditional strategy of re-ranking a larger pool of candidates for improving recall.,ReSolved,https://export.arxiv.org/pdf/2305.11744v1.pdf
1827,258823156,Inference-time Re-ranker Relevance Feedback for Neural Information Retrieval,conclusion and future work,"our proposed distillation process is lightweight and im-proves retrieval accuracy across different domains, languages and modalities over a state-of-the-art retrieve-and-rerank pipeline with comparable latency.",ReSolved,https://export.arxiv.org/pdf/2305.11744v1.pdf
1828,258823156,Inference-time Re-ranker Relevance Feedback for Neural Information Retrieval,conclusion and future work,future work will explore relevance feedback for token-level query representations as well as disentangling term importance scores from query representations for better interpretability.,Finding,https://export.arxiv.org/pdf/2305.11744v1.pdf
1829,252819220,KHANQ: A Dataset for Generating Deep Questions in Education,conclusions and future works,"in this paper, we propose khanq, a dataset for generating in-depth educational questions.",ReSolved,https://www.aclanthology.org/2022.coling-1.518.pdf
1830,252819220,KHANQ: A Dataset for Generating Deep Questions in Education,conclusions and future works,"each sample in khanq is carefully annotated as context, prompt, and question to form a clean dataset.",ReSolved,https://www.aclanthology.org/2022.coling-1.518.pdf
1831,252819220,KHANQ: A Dataset for Generating Deep Questions in Education,conclusions and future works,we evaluate the performance of state-of-the-art question generation models on khanq.,ReSolved,https://www.aclanthology.org/2022.coling-1.518.pdf
1832,252819220,KHANQ: A Dataset for Generating Deep Questions in Education,conclusions and future works,"we find that although it is feasible for the model to generate fluent and complex questions, the ability to understand and reason over the context and the prompt is still far from reaching the human level.",Finding,https://www.aclanthology.org/2022.coling-1.518.pdf
1833,196170479,ELI5: Long Form Question Answering,conclusion,we introduce the first large-scale long form question answering dataset of open-ended queries with explanatory multi-sentence answers.,ReSolved,https://arxiv.org/pdf/1907.09190v1.pdf
1834,196170479,ELI5: Long Form Question Answering,conclusion,we show that abstractive models generate coherent answers and are competitive with extractive models in human evaluation.,ReSolved,https://arxiv.org/pdf/1907.09190v1.pdf
1835,196170479,ELI5: Long Form Question Answering,conclusion,"proposed models are far from human performance, in part due to the inability to exploit the long full web text.",Finding,https://arxiv.org/pdf/1907.09190v1.pdf
1836,196170479,ELI5: Long Form Question Answering,conclusion,"we hope eli5 will inspire future work in all aspects of long-form qa, from the information extraction problem of obtaining information from long, multi-document input to generating more coherent and accurate paragraph-length answers.",Finding,https://arxiv.org/pdf/1907.09190v1.pdf
1837,128345225,PullNet: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text,conclusions,pullnet is a novel integrated qa framework for (1) learning what to retrieve from a kb and/or corpus and (2) reasoning with this heterogeneous data to find the best answer.,ReSolved,https://www.aclweb.org/anthology/D19-1242.pdf
1838,128345225,PullNet: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text,conclusions,"unlike prior work, pullnet uses an iterative process to construct a question-specific subgraph that contains information relevant to the question.",Neutral,https://www.aclweb.org/anthology/D19-1242.pdf
1839,128345225,PullNet: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text,conclusions,"in each iteration, a graph cnn is used to identify subgraph nodes that should be expanded using ""pull"" operations on the corpus and/or kb.",Neutral,https://www.aclweb.org/anthology/D19-1242.pdf
1840,128345225,PullNet: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text,conclusions,this iterative process makes it possible to retrieve a small graph that contains just the information relevant to a multi-hop question.,ReSolved,https://www.aclweb.org/anthology/D19-1242.pdf
1841,258841405,"HOP, UNION, GENERATE: Explainable Multi-hop Reasoning without Rationale Supervision",conclusion,"we present hug, a probabilistic, principled approach for explainable multi-hop reasoning without rationale supervision.",ReSolved,https://export.arxiv.org/pdf/2305.14237v1.pdf
1842,258841405,"HOP, UNION, GENERATE: Explainable Multi-hop Reasoning without Rationale Supervision",conclusion,hug explicitly models multi-hop reasoning by considering the dependency between documents and between sentences within a document.,ReSolved,https://export.arxiv.org/pdf/2305.14237v1.pdf
1843,258841405,"HOP, UNION, GENERATE: Explainable Multi-hop Reasoning without Rationale Supervision",conclusion,experimental results demonstrate that hug outperforms other state-of-the-art methods that do not rely on rationale labels.,ReSolved,https://export.arxiv.org/pdf/2305.14237v1.pdf
1844,208201969,Assessing the Benchmarking Capacity of Machine Reading Comprehension Datasets,conclusion,existing analysis work in mrc is largely concerned with evaluating the capabilities of systems.,Neutral,https://ojs.aaai.org/index.php/AAAI/article/download/6422/6278
1845,208201969,Assessing the Benchmarking Capacity of Machine Reading Comprehension Datasets,conclusion,"by contrast, in this work, we proposed an analysis methodology for the bench-marking capacity of datasets.",ReSolved,https://ojs.aaai.org/index.php/AAAI/article/download/6422/6278
1846,208201969,Assessing the Benchmarking Capacity of Machine Reading Comprehension Datasets,conclusion,"our methodology consists of input-ablation tests, in which each ablation method is associated with a skill requisite for mrc.",Neutral,https://ojs.aaai.org/index.php/AAAI/article/download/6422/6278
1847,208201969,Assessing the Benchmarking Capacity of Machine Reading Comprehension Datasets,conclusion,we exemplified 12 skills and analyzed 10 datasets.,ReSolved,https://ojs.aaai.org/index.php/AAAI/article/download/6422/6278
1848,208201969,Assessing the Benchmarking Capacity of Machine Reading Comprehension Datasets,conclusion,"the experimental results suggest that for benchmarking sophisticated nlu, datasets should be more carefully designed to ensure that questions correctly evaluate the intended skills.",Finding,https://ojs.aaai.org/index.php/AAAI/article/download/6422/6278
1849,208201969,Assessing the Benchmarking Capacity of Machine Reading Comprehension Datasets,conclusion,"in future work, we will develop a skill-oriented method for crowdsourcing questions.",Finding,https://ojs.aaai.org/index.php/AAAI/article/download/6422/6278
1850,198229624,SpanBERT: Improving Pre-training by Representing and Predicting Spans,conclusion,"we presented a new method for span-based pretraining which extends bert by (1) masking contiguous random spans, rather than random tokens, and (2) training the span boundary representations to predict the entire content of the masked span, without relying on the individual token representations within it.",ReSolved,https://www.aclweb.org/anthology/2020.tacl-1.5.pdf
1851,198229624,SpanBERT: Improving Pre-training by Representing and Predicting Spans,conclusion,"together, our pretraining process yields models that outperform all bert baselines on a variety of tasks, and reach substantially better performance on span selection tasks in particular.",ReSolved,https://www.aclweb.org/anthology/2020.tacl-1.5.pdf
1852,230770437,SF-QA: Simple and Fair Evaluation Library for Open-domain Question Answering,conclusion,"in conclusion, this paper presents sf-qa, a novel evaluation framework to make open-domain qa research simple and fair.",ReSolved,https://www.aclweb.org/anthology/2021.eacl-demos.2.pdf
1853,230770437,SF-QA: Simple and Fair Evaluation Library for Open-domain Question Answering,conclusion,"this framework fixes the gap among researchers from different fields, and make the open-domain qa more accessible.",ReSolved,https://www.aclweb.org/anthology/2021.eacl-demos.2.pdf
1854,230770437,SF-QA: Simple and Fair Evaluation Library for Open-domain Question Answering,conclusion,we show the robustness of this framework by successfully reproducing several existing models in opendomain qa research.,ReSolved,https://www.aclweb.org/anthology/2021.eacl-demos.2.pdf
1855,230770437,SF-QA: Simple and Fair Evaluation Library for Open-domain Question Answering,conclusion,we hope that sf-qa can make the open-domain qa research more accessible and make the evaluation easier.,Neutral,https://www.aclweb.org/anthology/2021.eacl-demos.2.pdf
1856,230770437,SF-QA: Simple and Fair Evaluation Library for Open-domain Question Answering,conclusion,"we expect to further improve our framework by including more models in both ranker and reader side, and encourage community contributions to the project as well.",Finding,https://www.aclweb.org/anthology/2021.eacl-demos.2.pdf
1857,234470046,Encoding Explanatory Knowledge for Zero-shot Science Question Answering,conclusion,"in this paper, we proposed a neural encoding mechanism for explanatory knowledge acquisition and transfer, n-xkt.",ReSolved,https://www.aclanthology.org/2021.iwcs-1.5.pdf
1858,234470046,Encoding Explanatory Knowledge for Zero-shot Science Question Answering,conclusion,we evaluated the impact of the encoding mechanism on downstream science qa.,ReSolved,https://www.aclanthology.org/2021.iwcs-1.5.pdf
1859,234470046,Encoding Explanatory Knowledge for Zero-shot Science Question Answering,conclusion,the proposed model delivers better generalisation and accuracy for qa tasks that require multi-hop and explanatory inference.,ReSolved,https://www.aclanthology.org/2021.iwcs-1.5.pdf
1860,234470046,Encoding Explanatory Knowledge for Zero-shot Science Question Answering,conclusion,"the proposed encoding mechanism can be used to deliver zero-shot inference capabilities, providing comparable performance when compared to supervised models on qa.",ReSolved,https://www.aclanthology.org/2021.iwcs-1.5.pdf
1861,234470046,Encoding Explanatory Knowledge for Zero-shot Science Question Answering,conclusion,these results supports the hypothesis that pretraining tasks targeting abstract and explanatory knowledge acquisition can constitute and impor-,ReSolved,https://www.aclanthology.org/2021.iwcs-1.5.pdf
1862,251320151,Evaluating Interpolation and Extrapolation Performance of Neural Retrieval Models,conclusions,"in this paper, we propose to separately evaluate interpolation and extrapolation capabilities of neural retrieval models.",ReSolved,https://export.arxiv.org/pdf/2204.11447v2.pdf
1863,251320151,Evaluating Interpolation and Extrapolation Performance of Neural Retrieval Models,conclusions,"considering the dynamics of queries in web search, we define them based on whether the training and test queries are similar or not.",Neutral,https://export.arxiv.org/pdf/2204.11447v2.pdf
1864,251320151,Evaluating Interpolation and Extrapolation Performance of Neural Retrieval Models,conclusions,"based on the definition, we investigate the bias in popular benchmarks, design associated evaluation methods, and revisit existing neural ranking models.",ReSolved,https://export.arxiv.org/pdf/2204.11447v2.pdf
1865,251320151,Evaluating Interpolation and Extrapolation Performance of Neural Retrieval Models,conclusions,we observe that the popular benchmarks are biased towards interpolation and thus may not reflect how models extrapolate.,ReSolved,https://export.arxiv.org/pdf/2204.11447v2.pdf
1866,202541222,Large Scale Question Answering using Tourism Data,conclusion,"in the spirit of defining a question answering challenge that is closer to a real-world qa setting, we introduce the novel task of identifying the correct entity answer to a given user question based on a collection of unstructured reviews describing entities.",ReSolved,https://arxiv.org/pdf/1909.03527v2.pdf
1867,202541222,Large Scale Question Answering using Tourism Data,conclusion,"we harvest a dataset of over 48,000 qa pairs, which enables end to end training of models.",ReSolved,https://arxiv.org/pdf/1909.03527v2.pdf
1868,252907386,Can language representation models think in bets?,conclusion and future work,"modern lrms, based on transformer neural networks, have rapidly exceeded the previous state-of-theart on a range of natural language understanding tasks, including question answering, text summarization and information extraction [104][105][106].",Neutral,https://export.arxiv.org/pdf/2210.07519v1.pdf
1869,252907386,Can language representation models think in bets?,conclusion and future work,"in this article, we addressed the question of whether such lrms can be adapted for (approximately) rational decision-making and preference elicitation.",ReSolved,https://export.arxiv.org/pdf/2210.07519v1.pdf
1870,252907386,Can language representation models think in bets?,conclusion and future work,"in the cognitive science literature, such decision-making is often evaluated using bets.",Neutral,https://export.arxiv.org/pdf/2210.07519v1.pdf
1871,252907386,Can language representation models think in bets?,conclusion and future work,"given the near human-like performance of lrms on language-based problems, we formulated a set of rqs to specifically test whether: (i) lrms have a distinct preference for high-value items over lowvalue items, especially when the items were not seen during training, and after stratifying by the format of the questions, (ii) lrms can make, or be taught to make, (approximately rational) bets in a generalizable manner, including when an lrm has been fine-tuned on one 'modality' of bet but is evaluated on another modality.",ReSolved,https://export.arxiv.org/pdf/2210.07519v1.pdf
1872,247594506,FaiRR: Faithful and Robust Deductive Reasoning over Natural Language,conclusion,"in this paper, we proposed fairr, a faithful and robust deductive reasoning model based on three modular components: rule selection, fact selection, and knowledge composition.",ReSolved,https://www.aclanthology.org/2022.acl-long.77.pdf
1873,247594506,FaiRR: Faithful and Robust Deductive Reasoning over Natural Language,conclusion,fairr ensures causality from proof generation to entailment prediction by design.,ReSolved,https://www.aclanthology.org/2022.acl-long.77.pdf
1874,247594506,FaiRR: Faithful and Robust Deductive Reasoning over Natural Language,conclusion,we established the effectiveness of our approach through experiments on testing robustness to language variations and demonstrating the interpretability of the errors made by our model.,ReSolved,https://www.aclanthology.org/2022.acl-long.77.pdf
1875,247594506,FaiRR: Faithful and Robust Deductive Reasoning over Natural Language,conclusion,we also show that fairr is faster and more precise at deductive reasoning than prior baselines.,ReSolved,https://www.aclanthology.org/2022.acl-long.77.pdf
1876,254854129,Visconde: Multi-document QA with GPT-3 and Neural Reranking,conclusion,this paper describes a system for multi-document question answering that uses a passage reranker to retrieve documents and large language models to reason over them and compose an answer.,ReSolved,https://export.arxiv.org/pdf/2212.09656v1.pdf
1877,254854129,Visconde: Multi-document QA with GPT-3 and Neural Reranking,conclusion,"our system rivals state-of-the-art supervised models in three datasets: iirc, qasper, and strategyqa.",ReSolved,https://export.arxiv.org/pdf/2212.09656v1.pdf
1878,254854129,Visconde: Multi-document QA with GPT-3 and Neural Reranking,conclusion,"our results suggest that using gpt-3 as a reader is close to human-level performance as long as relevant passages are provided, while current retrievers are the main bottleneck.",ReSolved,https://export.arxiv.org/pdf/2212.09656v1.pdf
1879,254854129,Visconde: Multi-document QA with GPT-3 and Neural Reranking,conclusion,we also show that inducing the model to give explanations before answering a question improves effectiveness.,ReSolved,https://export.arxiv.org/pdf/2212.09656v1.pdf
1880,233296201,Generative Context Pair Selection for Multi-hop Question Answering,conclusion,we have presented a generative formulation of context pair selection in multi-hop question answering models.,ReSolved,https://arxiv.org/pdf/2104.08744v1.pdf
1881,233296201,Generative Context Pair Selection for Multi-hop Question Answering,conclusion,"by encouraging the context selection model to explain the entire question, it is less susceptible to bias, performing substantially better on adversarial data than existing methods that use discriminative selection.",ReSolved,https://arxiv.org/pdf/2104.08744v1.pdf
1882,233296201,Generative Context Pair Selection for Multi-hop Question Answering,conclusion,our proposed model is simple to implement and can be used with any existing (or future) answering model; we will release code to support this integration.,Neutral,https://arxiv.org/pdf/2104.08744v1.pdf
1883,233296201,Generative Context Pair Selection for Multi-hop Question Answering,conclusion,"since context pair selection scales quadratically with the number of contexts, it is not ideal for scenarios that involve a large number of possible contexts.",Finding,https://arxiv.org/pdf/2104.08744v1.pdf
1884,233296201,Generative Context Pair Selection for Multi-hop Question Answering,conclusion,"however, it allows for deeper inter-document interaction as compared to other approaches that use summarized document representations.",Finding,https://arxiv.org/pdf/2104.08744v1.pdf
1885,233296201,Generative Context Pair Selection for Multi-hop Question Answering,conclusion,"with more reasoning steps, selecting relevant documents given only the question becomes challenging, increasing the need for inter-document interaction.",Neutral,https://arxiv.org/pdf/2104.08744v1.pdf
1886,233296201,Generative Context Pair Selection for Multi-hop Question Answering,conclusion,this paper focuses on biases found in question answering models that make its reasoning capabilities brittle.,ReSolved,https://arxiv.org/pdf/2104.08744v1.pdf
1887,233296201,Generative Context Pair Selection for Multi-hop Question Answering,conclusion,it uses an existing method of testing model performance on adversarial held-out set as an evaluation metric.,ReSolved,https://arxiv.org/pdf/2104.08744v1.pdf
1888,233296201,Generative Context Pair Selection for Multi-hop Question Answering,conclusion,this work does not deal with any social impacts of biases in natural language processing systems.,Finding,https://arxiv.org/pdf/2104.08744v1.pdf
1889,247188085,Read before Generate! Faithful Long Form Question Answering with Machine Reading,conclusion,we propose a new end-to-end framework rbg that jointly models answer generation and machine reading to tackle the faithfulness issue in lfqa.,ReSolved,https://www.aclanthology.org/2022.findings-acl.61.pdf
1890,247188085,Read before Generate! Faithful Long Form Question Answering with Machine Reading,conclusion,"experiments on two lfqa datasets, eli5 and ms marco, demonstrate the effectiveness of our method in comparison with strong baselines on automatic and human evaluation metrics.",ReSolved,https://www.aclanthology.org/2022.findings-acl.61.pdf
1891,247188085,Read before Generate! Faithful Long Form Question Answering with Machine Reading,conclusion,"the detailed analysis further proves the competency of our method in generating fluent, relevant, and more faithful answers.",ReSolved,https://www.aclanthology.org/2022.findings-acl.61.pdf
1892,247188085,Read before Generate! Faithful Long Form Question Answering with Machine Reading,conclusion,"we also propose to evaluate the factual correctness of lfqa model by answering questions of extractive qa tasks (e.g., natural questions), which may be helpful to evaluate the faithfulness of lfqa model efficiently.",Neutral,https://www.aclanthology.org/2022.findings-acl.61.pdf
1893,211126663,Transformers as Soft Reasoners over Language,conclusion,"just as mccarthy advocated 60 years ago for machines reasoning (""taking advice"") in logic, we have shown (in a restricted setting) that machines can by trained to reason over language.",Neutral,https://arxiv.org/pdf/2002.05867v2.pdf
1894,211126663,Transformers as Soft Reasoners over Language,conclusion,"while we have assumed a particular semantics of inference, the methodology we have used is general: characterize the desired behavior in a formal way, synthesize examples, generate linguistic equivalents, and train a model.",Neutral,https://arxiv.org/pdf/2002.05867v2.pdf
1895,211126663,Transformers as Soft Reasoners over Language,conclusion,"the result, at least within our experiments, appears to be both nat-ural and robust, in a way distinct from working with the original formalization.",ReSolved,https://arxiv.org/pdf/2002.05867v2.pdf
1896,258865693,Revisiting Parallel Context Windows: A Frustratingly Simple Alternative and Chain-of-Thought Deterioration,conclusion,we raise concerns about the use of parallelintegrated methods to address context length restriction: (1) pcw is functionally equal with a simple weighted sum ensemble on label distribution among context windows; (2) pcw degrades the multi-step reasoning capabilities of llms in complex tasks requiring knowledge understanding.,Finding,https://export.arxiv.org/pdf/2305.15262v1.pdf
1897,258865693,Revisiting Parallel Context Windows: A Frustratingly Simple Alternative and Chain-of-Thought Deterioration,conclusion,"despite the fact that parallel-integrated methods sometimes show better classification performance when the label space is large, they merely brute-force ensemble each window's context, consequently weakening logical reasoning and knowledge comprehension.",Finding,https://export.arxiv.org/pdf/2305.15262v1.pdf
1898,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,conclusion,"this paper presented a unified web-augmented framework for a wide range of knowledge-intensive tasks, called uniweb.",ReSolved,https://export.arxiv.org/pdf/2305.10998v2.pdf
1899,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,conclusion,we convert 16 tasks into a text-to-text generation task for training.,ReSolved,https://export.arxiv.org/pdf/2305.10998v2.pdf
1900,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,conclusion,we propose a search engine assisted learning method to selectively retrieve documents from the web through google search.,ReSolved,https://export.arxiv.org/pdf/2305.10998v2.pdf
1901,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,conclusion,"furthermore, to reduce the discrepancy between the encoded and retrieved knowledge, we design a pre-training task, i.e., continual knowledge learning, to integrate the retrieved knowledge into llms.",ReSolved,https://export.arxiv.org/pdf/2305.10998v2.pdf
1902,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,conclusion,experiments on 16 tasks show the effectiveness of our web-augmented model compared to previous retrieval-augmented models.,ReSolved,https://export.arxiv.org/pdf/2305.10998v2.pdf
1903,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,conclusion,"in future work, we will investigate the effect of web content in detail and consider applying our model to more types of downstream tasks.",Finding,https://export.arxiv.org/pdf/2305.10998v2.pdf
1904,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"for web-augmented models including our work, the deterioration of search results from search engine highlights the importance of deriving an effective method to interact with the huge web.search engines are often perceived as black-box and non-transparent for end users.",Neutral,https://export.arxiv.org/pdf/2305.10998v2.pdf
1905,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"therefore, many works proposed ""leaning to search"" to decompose complex questions into simpler queries, which may improve the performance of web-based models (nakano et al., 2021;komeili et al., 2021).",Neutral,https://export.arxiv.org/pdf/2305.10998v2.pdf
1906,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"in our model, we used a commercial search engine as the retriever to work with the whole web as a knowledge source.",ReSolved,https://export.arxiv.org/pdf/2305.10998v2.pdf
1907,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"since the web is not curated and well-structured like wikipedia, we may encounter unexpected safety issues, including misinformation and harmful contents.",Finding,https://export.arxiv.org/pdf/2305.10998v2.pdf
1908,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"while we have relied on the security control of the search engine, more attention should be paid to better understand the risks and provide effective ways to mitigate them.",Finding,https://export.arxiv.org/pdf/2305.10998v2.pdf
1909,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,we hope our simple approach and strong results could encourage more future work by the community to tackle these questions.,Neutral,https://export.arxiv.org/pdf/2305.10998v2.pdf
1910,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"to encourage the community to investigate the question and ensure reproducibility, after the reviewing process, we will release the search urls used in our experiments.as for the potential concern, since we use the search engine to access real-time information, we do not have a tight control over retrieved results as traditional end-to-end retrieval (guu et al., 2020;lewis et al., 2020b).",Finding,https://export.arxiv.org/pdf/2305.10998v2.pdf
1911,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"not only the changes of search engine logic, but also the newly published information, might create discrepancies over the course of time.",Finding,https://export.arxiv.org/pdf/2305.10998v2.pdf
1912,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,this is also an issue we have to tackle to build a stable web-based solution for llms.,Finding,https://export.arxiv.org/pdf/2305.10998v2.pdf
1913,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,commonsense reasoning is intended to utilize commonsense knowledge to reason about certain aspects of the given text .,Finding,https://export.arxiv.org/pdf/2305.10998v2.pdf
1914,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"therefore, we consider the given text as input and the prediction as output.• natural language inference is the task of determining whether the given ""hypothesis"" logically follows from the ""premise"" (storks et al., 2019).it acquires deep knowledge about the relationship between hypothesis and premise.",Neutral,https://export.arxiv.org/pdf/2305.10998v2.pdf
1915,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"we consider the premise as input and the hypothesis as output.for each category, we choose several representative tasks to construct our pretraining corpus.",Neutral,https://export.arxiv.org/pdf/2305.10998v2.pdf
1916,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,the detailed information of these included tasks is listed in table 6.,Neutral,https://export.arxiv.org/pdf/2305.10998v2.pdf
1917,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"to mitigate the huge disparity between dataset sizes, we follow  to use the temperature-scaled mixing strategy with a rate of t = 2 for setting the proportion of data coming from each task.",ReSolved,https://export.arxiv.org/pdf/2305.10998v2.pdf
1918,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"during pretraining, for each task example, we use bm25 to retrieve top-10 passages from ccnet as our external knowledge.",Neutral,https://export.arxiv.org/pdf/2305.10998v2.pdf
1919,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,the input texts are concatenated with the retrieved passages using manually-written prompts.,Neutral,https://export.arxiv.org/pdf/2305.10998v2.pdf
1920,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"the final input is constructed in the following format: the ""option"" string is applied only when the input text is provided with several candidate answers.",Neutral,https://export.arxiv.org/pdf/2305.10998v2.pdf
1921,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"the blanks ""[passage n ]"" and ""[option n ]"" is filled with the retrieved passages and candidate answers.",Neutral,https://export.arxiv.org/pdf/2305.10998v2.pdf
1922,258762384,Beijing Key Laboratory of Big Data Management and Analysis Methods,limitations,"the blank ""[task instruction]"" aims to indicate the task for our model, which is task-specific and detailed in table 7.",Neutral,https://export.arxiv.org/pdf/2305.10998v2.pdf